#!/usr/bin/env python3
# coding: utf-8
"""
diagnose/analyze_tm_correlation.py

T-Må› å­ç›¸å…³æ€§åˆ†æè„šæœ¬ï¼ˆP1.3ï¼‰

ç›®æ ‡ï¼š
- å®è¯åˆ†æTå’ŒMå› å­çš„å®é™…ç›¸å…³æ€§
- å†³å®šæ˜¯å¦éœ€è¦æ­£äº¤åŒ–æˆ–é‡æ–°è®¾è®¡Må› å­
- ä¸ºP2.2æä¾›æ•°æ®æ”¯æ’‘

å†³ç­–é€»è¾‘ï¼š
- å¦‚æœ avg_corr(T, M) < 0.5ï¼šä¿æŒç°çŠ¶ï¼Œæ— éœ€æ­£äº¤åŒ–
- å¦‚æœ 0.5 â‰¤ avg_corr < 0.7ï¼šé™ä½Mæƒé‡ï¼ˆ17% â†’ 10%ï¼‰
- å¦‚æœ avg_corr â‰¥ 0.7ï¼šéœ€è¦æ­£äº¤åŒ–æˆ–é‡æ–°è®¾è®¡Må› å­ï¼ˆæ–¹æ¡ˆCï¼šçŸ­çª—å£ç‰ˆæœ¬ï¼‰

ä½œè€…ï¼šClaude (Sonnet 4.5)
æ—¥æœŸï¼š2025-11-05
ç‰ˆæœ¬ï¼šP1.3
"""

import sys
import json
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple
from datetime import datetime, timedelta


def load_factor_history(symbol: str, factor_name: str, days: int = 30, use_realtime: bool = False) -> List[float]:
    """
    åŠ è½½å†å²å› å­æ•°æ®

    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·
        factor_name: å› å­åç§°ï¼ˆ'T' æˆ– 'M'ï¼‰
        days: å¤©æ•°
        use_realtime: æ˜¯å¦ä½¿ç”¨å®æ—¶è®¡ç®—ï¼ˆè°ƒç”¨analyze_symbolï¼‰

    æ³¨æ„ï¼š
    - use_realtime=False: ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆé»˜è®¤ï¼Œç”¨äºæµ‹è¯•ï¼‰
    - use_realtime=True: è°ƒç”¨analyze_symbolå®æ—¶è®¡ç®—ï¼ˆæ…¢ï¼Œä½†ä½¿ç”¨çœŸå®æ•°æ®ï¼‰
    - ç”Ÿäº§ç¯å¢ƒå»ºè®®ï¼šä»æ—¥å¿—æ–‡ä»¶æˆ–æ—¶åºæ•°æ®åº“è¯»å–å†å²å› å­å€¼

    å®é™…ç”Ÿäº§å®ç°å»ºè®®ï¼š
    1. ä»Redis/InfluxDBç­‰æ—¶åºæ•°æ®åº“è¯»å–å†å²å› å­å€¼
    2. ä»ç³»ç»Ÿæ—¥å¿—æ–‡ä»¶ä¸­è§£æå› å­å€¼
    3. ä»ä¸“é—¨çš„å› å­å­˜å‚¨è¡¨ä¸­æŸ¥è¯¢
    """

    if use_realtime:
        # å®æ—¶è®¡ç®—é€‰é¡¹ï¼šè°ƒç”¨analyze_symbolè·å–å½“å‰å› å­å€¼
        # æ³¨æ„ï¼šè¿™åªèƒ½è·å–å½“å‰å¿«ç…§ï¼Œæ— æ³•è·å–å†å²åºåˆ—
        # å¦‚éœ€å†å²åºåˆ—ï¼Œéœ€è¦å®ç°ä¸“é—¨çš„å­˜å‚¨æœºåˆ¶
        try:
            from ats_core.pipeline.analyze_symbol import analyze_symbol
            result = analyze_symbol(symbol)
            if result.get('success') and factor_name in result:
                # åªèƒ½è·å–å•ä¸ªç‚¹ï¼Œæ— æ³•æ„å»ºå†å²åºåˆ—
                # è¿”å›é‡å¤å€¼ä½œä¸ºå ä½ï¼ˆå®é™…åº”è¯¥æœ‰å†å²å­˜å‚¨ï¼‰
                current_value = result[factor_name]
                print(f"  [å®æ—¶] {symbol} å½“å‰{factor_name}={current_value}")
                print(f"  [è­¦å‘Š] å®æ—¶æ¨¡å¼åªèƒ½è·å–å½“å‰å€¼ï¼Œå†å²åºåˆ—ä»ä¸ºæ¨¡æ‹Ÿæ•°æ®")
                # ç”Ÿæˆæ¨¡æ‹Ÿå†å²ï¼Œä½†æœ€æ–°å€¼ä½¿ç”¨çœŸå®å€¼
                history = _generate_simulated_history(symbol, factor_name, days)
                history[-1] = current_value  # æœ€åä¸€ä¸ªç‚¹ä½¿ç”¨çœŸå®å€¼
                return history
        except Exception as e:
            print(f"  [é”™è¯¯] å®æ—¶è®¡ç®—å¤±è´¥: {e}ï¼Œé™çº§åˆ°æ¨¡æ‹Ÿæ•°æ®")

    # æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
    print(f"  [æ¨¡æ‹Ÿ] {symbol} {factor_name}å› å­ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    return _generate_simulated_history(symbol, factor_name, days)


def _generate_simulated_history(symbol: str, factor_name: str, days: int) -> List[float]:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿå†å²æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰

    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·
        factor_name: å› å­åç§°
        days: å¤©æ•°

    Returns:
        æ¨¡æ‹Ÿçš„å†å²å› å­å€¼åˆ—è¡¨
    """
    # æ¨¡æ‹Ÿæ•°æ®ï¼šç”Ÿæˆç›¸å…³æ€§çº¦0.6çš„Tå’ŒM
    np.random.seed(hash(symbol) % 2**32)
    n = days * 24  # å‡è®¾æ¯å°æ—¶ä¸€ä¸ªæ•°æ®ç‚¹

    if factor_name == 'T':
        # Tå› å­ï¼šè¶‹åŠ¿ï¼ŒèŒƒå›´[-100, +100]
        base_trend = np.cumsum(np.random.randn(n)) * 2
        T = np.clip(base_trend, -100, 100)
        return list(T)
    elif factor_name == 'M':
        # Må› å­ï¼šåŠ¨é‡ï¼Œä¸Tæœ‰ä¸€å®šç›¸å…³ä½†ä¸å®Œå…¨ä¸€è‡´
        T = _generate_simulated_history(symbol, 'T', days)
        noise = np.random.randn(len(T)) * 30
        M = 0.6 * np.array(T) + 0.4 * noise  # æ¨¡æ‹Ÿ0.6å·¦å³çš„ç›¸å…³æ€§
        M = np.clip(M, -100, 100)
        return list(M)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å› å­: {factor_name}")


def analyze_symbol_tm_correlation(
    symbol: str,
    days: int = 30
) -> Dict:
    """
    åˆ†æå•ä¸ªå¸ç§çš„T-Mç›¸å…³æ€§

    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·
        days: åˆ†æå¤©æ•°

    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    try:
        # åŠ è½½Tå’ŒMå› å­å†å²æ•°æ®
        T_history = load_factor_history(symbol, 'T', days=days)
        M_history = load_factor_history(symbol, 'M', days=days)

        if len(T_history) < 10 or len(M_history) < 10:
            return {
                'symbol': symbol,
                'error': 'æ•°æ®ä¸è¶³',
                'data_points': min(len(T_history), len(M_history))
            }

        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(T_history), len(M_history))
        T_array = np.array(T_history[-min_len:])
        M_array = np.array(M_history[-min_len:])

        # è®¡ç®—ç›¸å…³ç³»æ•°
        correlation = float(np.corrcoef(T_array, M_array)[0, 1])

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        T_mean = float(np.mean(T_array))
        T_std = float(np.std(T_array))
        M_mean = float(np.mean(M_array))
        M_std = float(np.std(M_array))

        # è®¡ç®—ä¿¡æ¯é‡å åº¦ï¼ˆç»å¯¹ç›¸å…³ç³»æ•°ï¼‰
        info_overlap = abs(correlation)

        return {
            'symbol': symbol,
            'correlation': round(correlation, 4),
            'info_overlap': round(info_overlap, 4),
            'T_stats': {
                'mean': round(T_mean, 2),
                'std': round(T_std, 2),
                'range': [round(float(np.min(T_array)), 2), round(float(np.max(T_array)), 2)]
            },
            'M_stats': {
                'mean': round(M_mean, 2),
                'std': round(M_std, 2),
                'range': [round(float(np.min(M_array)), 2), round(float(np.max(M_array)), 2)]
            },
            'data_points': min_len,
            'analysis_period_days': days
        }

    except Exception as e:
        return {
            'symbol': symbol,
            'error': str(e)
        }


def analyze_tm_correlation_batch(
    symbol_list: List[str],
    days: int = 30
) -> Tuple[pd.DataFrame, Dict]:
    """
    æ‰¹é‡åˆ†æT-Mç›¸å…³æ€§

    Args:
        symbol_list: äº¤æ˜“å¯¹åˆ—è¡¨
        days: åˆ†æå¤©æ•°

    Returns:
        (results_df, recommendation)
    """
    print(f"\n{'='*60}")
    print(f"T-Må› å­ç›¸å…³æ€§åˆ†æ")
    print(f"{'='*60}")
    print(f"åˆ†æå¸ç§æ•°: {len(symbol_list)}")
    print(f"åˆ†æå‘¨æœŸ: æœ€è¿‘{days}å¤©")
    print(f"{'='*60}\n")

    results = []
    for i, symbol in enumerate(symbol_list, 1):
        print(f"[{i}/{len(symbol_list)}] åˆ†æ {symbol}...")
        result = analyze_symbol_tm_correlation(symbol, days=days)
        results.append(result)

    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(results)

    # è¿‡æ»¤é”™è¯¯æ•°æ®
    valid_df = df[~df['error'].notna()].copy() if 'error' in df.columns else df.copy()

    if len(valid_df) == 0:
        print("\nâŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return df, {'error': 'æ²¡æœ‰æœ‰æ•ˆæ•°æ®'}

    # ç»Ÿè®¡åˆ†æ
    avg_correlation = valid_df['correlation'].mean()
    median_correlation = valid_df['correlation'].median()
    std_correlation = valid_df['correlation'].std()
    abs_avg_correlation = valid_df['info_overlap'].mean()

    # ç›¸å…³æ€§åˆ†å¸ƒ
    high_corr_count = len(valid_df[valid_df['info_overlap'] > 0.7])
    medium_corr_count = len(valid_df[(valid_df['info_overlap'] >= 0.5) & (valid_df['info_overlap'] <= 0.7)])
    low_corr_count = len(valid_df[valid_df['info_overlap'] < 0.5])

    # ç”Ÿæˆå»ºè®®
    if abs_avg_correlation < 0.5:
        recommendation_text = "ä¿æŒç°çŠ¶ï¼Œæ— éœ€æ­£äº¤åŒ–"
        action = "no_action"
        reason = "å¹³å‡ä¿¡æ¯é‡å åº¦<50%ï¼ŒTå’ŒMå› å­ä¿æŒç‹¬ç«‹æ€§"
    elif abs_avg_correlation < 0.7:
        recommendation_text = "é™ä½Må› å­æƒé‡ï¼š17% â†’ 10%"
        action = "reduce_weight"
        reason = "ä¸­åº¦ç›¸å…³ï¼Œé€šè¿‡é™ä½æƒé‡å‡å°‘ä¿¡æ¯é‡å¤"
    else:
        recommendation_text = "éœ€è¦æ­£äº¤åŒ–æˆ–é‡æ–°è®¾è®¡Må› å­ï¼ˆæ–¹æ¡ˆCï¼šçŸ­çª—å£ç‰ˆæœ¬ï¼‰"
        action = "orthogonalize"
        reason = "é«˜åº¦ç›¸å…³ï¼Œå­˜åœ¨æ˜¾è‘—ä¿¡æ¯é‡å "

    recommendation = {
        'recommendation': recommendation_text,
        'action': action,
        'reason': reason,
        'statistics': {
            'avg_correlation': round(avg_correlation, 4),
            'median_correlation': round(median_correlation, 4),
            'std_correlation': round(std_correlation, 4),
            'avg_info_overlap': round(abs_avg_correlation, 4),
            'valid_samples': len(valid_df),
            'total_samples': len(symbol_list)
        },
        'distribution': {
            'high_corr_count': high_corr_count,
            'medium_corr_count': medium_corr_count,
            'low_corr_count': low_corr_count,
            'high_corr_ratio': round(high_corr_count / len(valid_df), 3) if len(valid_df) > 0 else 0
        },
        'top_correlated_symbols': valid_df.nlargest(5, 'info_overlap')[['symbol', 'correlation', 'info_overlap']].to_dict('records') if len(valid_df) >= 5 else []
    }

    return df, recommendation


def print_recommendation(recommendation: Dict):
    """
    æ‰“å°æ¨èç»“æœ

    Args:
        recommendation: æ¨èå­—å…¸
    """
    print(f"\n{'='*60}")
    print("åˆ†æç»“æœ")
    print(f"{'='*60}\n")

    stats = recommendation['statistics']
    dist = recommendation['distribution']

    print(f"æœ‰æ•ˆæ ·æœ¬: {stats['valid_samples']}/{stats['total_samples']}")
    print(f"å¹³å‡ç›¸å…³ç³»æ•°: {stats['avg_correlation']:+.4f}")
    print(f"ä¸­ä½æ•°ç›¸å…³ç³»æ•°: {stats['median_correlation']:+.4f}")
    print(f"æ ‡å‡†å·®: {stats['std_correlation']:.4f}")
    print(f"å¹³å‡ä¿¡æ¯é‡å åº¦: {stats['avg_info_overlap']:.1%}")

    print(f"\nç›¸å…³æ€§åˆ†å¸ƒ:")
    print(f"  é«˜åº¦ç›¸å…³ (>0.7): {dist['high_corr_count']} ({dist['high_corr_ratio']:.1%})")
    print(f"  ä¸­åº¦ç›¸å…³ (0.5-0.7): {dist['medium_corr_count']}")
    print(f"  ä½åº¦ç›¸å…³ (<0.5): {dist['low_corr_count']}")

    print(f"\nğŸ“Š æ¨è: {recommendation['recommendation']}")
    print(f"ç†ç”±: {recommendation['reason']}")

    if recommendation['action'] == 'no_action':
        print(f"\nâœ… Tå’ŒMå› å­ä¿æŒå½“å‰è®¾è®¡")
        print(f"   æƒé‡ç»´æŒï¼šT=24%, M=17%")
    elif recommendation['action'] == 'reduce_weight':
        print(f"\nâš ï¸ å»ºè®®è°ƒæ•´Må› å­æƒé‡")
        print(f"   å½“å‰ï¼šT=24%, M=17%")
        print(f"   å»ºè®®ï¼šT=24%, M=10%ï¼Œç©ºä½™7%åˆ†é…ç»™å…¶ä»–å› å­ï¼ˆå¦‚Cæˆ–Oï¼‰")
    else:  # orthogonalize
        print(f"\nğŸ”´ å»ºè®®é‡æ–°è®¾è®¡Må› å­")
        print(f"   æ–¹æ¡ˆAï¼šå»æ‰slopeï¼Œåªä¿ç•™åŠ é€Ÿåº¦")
        print(f"   æ–¹æ¡ˆBï¼šæ”¹ç”¨RSI+MACD")
        print(f"   æ–¹æ¡ˆCï¼šä¿ç•™slopeä½†ä½¿ç”¨æ›´çŸ­çª—å£ï¼ˆEMA3/5 vs Tçš„EMA20ï¼‰ã€æ¨èã€‘")

    # æ‰“å°topç›¸å…³å¸ç§
    if recommendation.get('top_correlated_symbols'):
        print(f"\nTop 5 é«˜ç›¸å…³å¸ç§:")
        for i, item in enumerate(recommendation['top_correlated_symbols'], 1):
            print(f"  {i}. {item['symbol']:12s}: corr={item['correlation']:+.3f}, overlap={item['info_overlap']:.1%}")

    print(f"\n{'='*60}\n")


def main():
    """
    ä¸»å‡½æ•°
    """
    # é»˜è®¤æµ‹è¯•å¸ç§åˆ—è¡¨ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”ä»ç³»ç»Ÿé…ç½®è¯»å–ï¼‰
    default_symbols = [
        'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'ADAUSDT',
        'DOGEUSDT', 'MATICUSDT', 'DOTUSDT', 'AVAXUSDT', 'LINKUSDT',
        'UNIUSDT', 'ATOMUSDT', 'LTCUSDT', 'ETCUSDT', 'XRPUSDT'
    ]

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        symbols_input = sys.argv[1]
        if symbols_input.endswith('.json'):
            # ä»JSONæ–‡ä»¶è¯»å–
            with open(symbols_input, 'r') as f:
                symbol_list = json.load(f)
        else:
            # ä»å‘½ä»¤è¡Œè¯»å–ï¼ˆé€—å·åˆ†éš”ï¼‰
            symbol_list = symbols_input.split(',')
    else:
        symbol_list = default_symbols
        print(f"ä½¿ç”¨é»˜è®¤å¸ç§åˆ—è¡¨({len(symbol_list)}ä¸ª)")

    # åˆ†æå¤©æ•°
    days = int(sys.argv[2]) if len(sys.argv) > 2 else 30

    # æ‰§è¡Œåˆ†æ
    df, recommendation = analyze_tm_correlation_batch(symbol_list, days=days)

    # ä¿å­˜ç»“æœ
    output_file = f'tm_correlation_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
    df.to_csv(output_file, index=False)
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # ä¿å­˜æ¨èåˆ°JSON
    recommendation_file = output_file.replace('.csv', '_recommendation.json')
    with open(recommendation_file, 'w', encoding='utf-8') as f:
        json.dump(recommendation, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ æ¨èç»“æœå·²ä¿å­˜åˆ°: {recommendation_file}")

    # æ‰“å°æ¨è
    print_recommendation(recommendation)

    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
