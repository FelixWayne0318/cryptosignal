#!/usr/bin/env python3
"""
ä¾èµ–æ ‘åˆ†æå·¥å…·
ä»æŒ‡å®šçš„å…¥å£æ–‡ä»¶é€’å½’åˆ†ææ‰€æœ‰å†…éƒ¨å¯¼å…¥ä¾èµ–
"""

import ast
import json
import sys
from pathlib import Path
from collections import defaultdict, deque
from typing import Set, Dict, List, Tuple


class DependencyAnalyzer:
    """ä¾èµ–åˆ†æå™¨"""

    def __init__(self, project_root: Path):
        self.project_root = project_root.resolve()
        self.dependency_tree = {}
        self.visited = set()
        self.all_project_files = set()

        # é¡¹ç›®å†…éƒ¨çš„åŒ…å‰ç¼€
        self.internal_prefixes = ['ats_core', 'scripts', 'config', 'tests']

        # æ ‡å‡†åº“æ¨¡å—ï¼ˆéƒ¨åˆ†å¸¸è§çš„ï¼Œç”¨äºè¿‡æ»¤ï¼‰
        self.stdlib_modules = {
            'os', 'sys', 'asyncio', 'argparse', 'signal', 'json', 'pathlib',
            'datetime', 'time', 'logging', 'traceback', 'collections',
            'typing', 'dataclasses', 'enum', 'functools', 'itertools',
            're', 'math', 'random', 'io', 'contextlib', 'copy', 'pickle',
            'urllib', 'http', 'hashlib', 'hmac', 'base64', 'uuid',
            'threading', 'multiprocessing', 'subprocess', 'shutil', 'tempfile',
            'warnings', 'abc', 'inspect', 'importlib'
        }

        # å·²çŸ¥çš„ç¬¬ä¸‰æ–¹åº“
        self.third_party_modules = {
            'requests', 'pandas', 'numpy', 'matplotlib', 'seaborn',
            'aiohttp', 'websockets', 'ccxt', 'binance', 'ta', 'talib',
            'scipy', 'sklearn', 'joblib', 'pytz', 'tqdm'
        }

    def is_internal_module(self, module_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé¡¹ç›®å†…éƒ¨æ¨¡å—"""
        if not module_name:
            return False

        # æ£€æŸ¥æ˜¯å¦ä»¥å†…éƒ¨åŒ…å‰ç¼€å¼€å¤´
        for prefix in self.internal_prefixes:
            if module_name.startswith(prefix):
                return True

        return False

    def is_stdlib_or_third_party(self, module_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡å‡†åº“æˆ–ç¬¬ä¸‰æ–¹åº“"""
        if not module_name:
            return False

        # è·å–é¡¶å±‚æ¨¡å—å
        top_level = module_name.split('.')[0]

        # æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡å‡†åº“æˆ–å·²çŸ¥ç¬¬ä¸‰æ–¹åº“
        if top_level in self.stdlib_modules or top_level in self.third_party_modules:
            return True

        return False

    def module_to_path(self, module_name: str) -> Path:
        """å°†æ¨¡å—åè½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„"""
        # ä¾‹å¦‚: ats_core.pipeline.batch_scan -> ats_core/pipeline/batch_scan.py
        parts = module_name.split('.')

        # å°è¯•ä½œä¸ºæ–‡ä»¶
        file_path = self.project_root / '/'.join(parts)
        if file_path.with_suffix('.py').exists():
            return file_path.with_suffix('.py')

        # å°è¯•ä½œä¸ºåŒ…ï¼ˆ__init__.pyï¼‰
        init_path = file_path / '__init__.py'
        if init_path.exists():
            return init_path

        return None

    def path_to_module(self, file_path: Path) -> str:
        """å°†æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºæ¨¡å—å"""
        try:
            rel_path = file_path.relative_to(self.project_root)

            # ç§»é™¤ .py åç¼€
            if rel_path.name == '__init__.py':
                # __init__.py -> ä½¿ç”¨çˆ¶ç›®å½•ä½œä¸ºæ¨¡å—å
                parts = rel_path.parent.parts
            else:
                # æ™®é€šæ–‡ä»¶ -> ç§»é™¤ .py
                parts = rel_path.with_suffix('').parts

            return '/'.join(parts)
        except ValueError:
            # æ–‡ä»¶ä¸åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹
            return str(file_path)

    def extract_imports(self, file_path: Path) -> List[str]:
        """ä»Pythonæ–‡ä»¶ä¸­æå–æ‰€æœ‰importè¯­å¥"""
        imports = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content, filename=str(file_path))

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    # import xxx
                    for alias in node.names:
                        imports.append(alias.name)

                elif isinstance(node, ast.ImportFrom):
                    # from xxx import yyy
                    if node.module:
                        imports.append(node.module)

        except SyntaxError as e:
            print(f"âš ï¸  è¯­æ³•é”™è¯¯ {file_path}: {e}", file=sys.stderr)
        except Exception as e:
            print(f"âš ï¸  è§£æå¤±è´¥ {file_path}: {e}", file=sys.stderr)

        return imports

    def analyze_file(self, file_path: Path, depth: int = 0) -> None:
        """é€’å½’åˆ†ææ–‡ä»¶çš„ä¾èµ–å…³ç³»"""
        # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„çš„æ¨¡å—å
        module_name = self.path_to_module(file_path)

        # æ£€æŸ¥æ˜¯å¦å·²è®¿é—®
        if module_name in self.visited:
            return

        self.visited.add(module_name)

        # æå–å¯¼å…¥
        raw_imports = self.extract_imports(file_path)

        # è¿‡æ»¤å‡ºé¡¹ç›®å†…éƒ¨çš„å¯¼å…¥
        internal_imports = []
        for imp in raw_imports:
            if self.is_internal_module(imp) and not self.is_stdlib_or_third_party(imp):
                # è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„
                imp_path = self.module_to_path(imp)
                if imp_path and imp_path.exists():
                    imp_module = self.path_to_module(imp_path)
                    internal_imports.append(imp_module)

        # è®°å½•åˆ°ä¾èµ–æ ‘
        self.dependency_tree[module_name] = {
            'imports': sorted(internal_imports),
            'depth': depth
        }

        # é€’å½’åˆ†æå¯¼å…¥çš„æ¨¡å—
        for imp_module in internal_imports:
            imp_path = self.project_root / imp_module.replace('/', '/')
            if imp_module.endswith('__init__'):
                imp_path = self.project_root / imp_module.replace('__init__', '__init__.py')
            else:
                imp_path = self.project_root / (imp_module + '.py')

            if imp_path.exists():
                self.analyze_file(imp_path, depth + 1)

    def analyze_from_entry(self, entry_file: Path) -> Dict:
        """ä»å…¥å£æ–‡ä»¶å¼€å§‹åˆ†æä¾èµ–æ ‘"""
        print(f"ğŸ” å¼€å§‹åˆ†æä¾èµ–æ ‘...")
        print(f"   å…¥å£æ–‡ä»¶: {entry_file}")
        print(f"   é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print()

        # åˆ†æå…¥å£æ–‡ä»¶
        self.analyze_file(entry_file, depth=0)

        print(f"âœ… åˆ†æå®Œæˆ")
        print(f"   å·²åˆ†ææ–‡ä»¶æ•°: {len(self.dependency_tree)}")
        print()

        return self.dependency_tree

    def get_all_python_files(self) -> Set[str]:
        """è·å–é¡¹ç›®ä¸­æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = set()

        # æ‰«æé¡¹ç›®å†…éƒ¨ç›®å½•
        for prefix in self.internal_prefixes:
            prefix_path = self.project_root / prefix
            if prefix_path.exists() and prefix_path.is_dir():
                for py_file in prefix_path.rglob('*.py'):
                    # æ’é™¤ __pycache__ ç­‰
                    if '__pycache__' not in str(py_file):
                        module_name = self.path_to_module(py_file)
                        python_files.add(module_name)

        return python_files

    def generate_report(self, entry_file: Path) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        # è·å–æ‰€æœ‰é¡¹ç›®æ–‡ä»¶
        all_files = self.get_all_python_files()
        used_files = set(self.dependency_tree.keys())

        # è®¡ç®—ä½¿ç”¨ç‡
        total_count = len(all_files)
        used_count = len(used_files)
        usage_rate = (used_count / total_count * 100) if total_count > 0 else 0

        report = {
            'dependency_tree': self.dependency_tree,
            'statistics': {
                'entry_file': self.path_to_module(entry_file),
                'total_python_files': total_count,
                'used_files': used_count,
                'usage_rate': round(usage_rate, 2),
                'all_files': sorted(all_files),
                'used_files_list': sorted(used_files),
                'unused_files': sorted(all_files - used_files)
            }
        }

        return report


def main():
    """ä¸»å‡½æ•°"""
    # é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(__file__).parent

    # å…¥å£æ–‡ä»¶
    entry_file = project_root / 'scripts' / 'realtime_signal_scanner.py'

    if not entry_file.exists():
        print(f"âŒ å…¥å£æ–‡ä»¶ä¸å­˜åœ¨: {entry_file}")
        sys.exit(1)

    # åˆ›å»ºåˆ†æå™¨
    analyzer = DependencyAnalyzer(project_root)

    # åˆ†æä¾èµ–æ ‘
    analyzer.analyze_from_entry(entry_file)

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_report(entry_file)

    # ä¿å­˜ä¸ºJSON
    output_file = project_root / 'dependency_tree.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"ğŸ“„ ä¾èµ–æ ‘å·²ä¿å­˜: {output_file}")
    print()

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    stats = report['statistics']
    print("=" * 60)
    print("ğŸ“Š ä¾èµ–åˆ†æç»Ÿè®¡")
    print("=" * 60)
    print(f"å…¥å£æ–‡ä»¶: {stats['entry_file']}")
    print(f"æ‰€æœ‰Pythonæ–‡ä»¶æ€»æ•°: {stats['total_python_files']}")
    print(f"å®é™…è¢«ä½¿ç”¨çš„æ–‡ä»¶æ•°: {stats['used_files']}")
    print(f"ä½¿ç”¨ç‡: {stats['usage_rate']:.2f}%")
    print()

    print("âœ… æ‰€æœ‰è¢«ä½¿ç”¨çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰è·¯å¾„æ’åºï¼‰:")
    print("-" * 60)
    for i, file in enumerate(stats['used_files_list'], 1):
        depth = report['dependency_tree'][file]['depth']
        imports_count = len(report['dependency_tree'][file]['imports'])
        print(f"{i:3d}. {file:60s} (depth={depth}, imports={imports_count})")
    print()

    if stats['unused_files']:
        print(f"âŒ æœªè¢«ä½¿ç”¨çš„æ–‡ä»¶ ({len(stats['unused_files'])}ä¸ª):")
        print("-" * 60)
        for i, file in enumerate(stats['unused_files'], 1):
            print(f"{i:3d}. {file}")
        print()

    print("=" * 60)


if __name__ == '__main__':
    main()
