#!/usr/bin/env python3
"""
ä¾èµ–åˆ†æå·¥å…· - ä»setup.shé€’å½’åˆ†ææ‰€æœ‰æ–‡ä»¶ä¾èµ–å…³ç³»
ç”Ÿæˆtxtæ ¼å¼æŠ¥å‘Šï¼Œé€‚åˆå‘é€åˆ°ç”µæŠ¥ç¾¤

ç”¨é€”ï¼š
1. åˆ†æsetup.shå¼•ç”¨çš„æ‰€æœ‰æ–‡ä»¶
2. é€’å½’åˆ†æPythonæ–‡ä»¶çš„importä¾èµ–
3. è¯†åˆ«æœªä½¿ç”¨çš„æ–‡ä»¶
4. è¾“å‡ºä¾èµ–å…³ç³»æ ‘å’Œæ–‡ä»¶åˆ—è¡¨

ä½œè€…ï¼šClaude Code
ç‰ˆæœ¬ï¼šv1.0
"""

import os
import re
import json
import ast
from pathlib import Path
from collections import defaultdict
from typing import Set, Dict, List, Tuple

class DependencyAnalyzer:
    """ä¾èµ–åˆ†æå™¨"""

    def __init__(self, root_dir: str = "/home/user/cryptosignal"):
        self.root_dir = Path(root_dir)
        self.analyzed_files = set()
        self.dependencies = defaultdict(set)  # file -> set of dependencies
        self.reverse_deps = defaultdict(set)  # file -> set of files that depend on it
        self.errors = []

        # å¿½ç•¥çš„ç›®å½•å’Œæ–‡ä»¶
        self.ignore_dirs = {
            '__pycache__', '.git', '.pytest_cache', 'node_modules',
            '.venv', 'venv', 'env', 'build', 'dist', '*.egg-info'
        }
        self.ignore_files = {
            '.pyc', '.pyo', '.pyd', '.so', '.dll', '.dylib'
        }

    def should_ignore(self, path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¿½ç•¥è¯¥è·¯å¾„"""
        # å¿½ç•¥çš„ç›®å½•
        for part in path.parts:
            if part in self.ignore_dirs or part.startswith('.'):
                return True

        # å¿½ç•¥çš„æ–‡ä»¶æ‰©å±•å
        if path.suffix in self.ignore_files:
            return True

        return False

    def extract_python_imports(self, file_path: Path) -> Set[str]:
        """æå–Pythonæ–‡ä»¶çš„importè¯­å¥"""
        imports = set()

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ä½¿ç”¨ASTè§£æï¼ˆæ›´å‡†ç¡®ï¼‰
            try:
                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.add(alias.name.split('.')[0])
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            imports.add(node.module.split('.')[0])
            except SyntaxError:
                # ASTè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
                import_patterns = [
                    r'^\s*import\s+([a-zA-Z_][a-zA-Z0-9_\.]*)',
                    r'^\s*from\s+([a-zA-Z_][a-zA-Z0-9_\.]*)\s+import',
                ]
                for pattern in import_patterns:
                    matches = re.finditer(pattern, content, re.MULTILINE)
                    for match in matches:
                        module = match.group(1).split('.')[0]
                        imports.add(module)

        except Exception as e:
            self.errors.append(f"è§£æ{file_path}å¤±è´¥: {e}")

        return imports

    def extract_bash_references(self, file_path: Path) -> Set[str]:
        """æå–Bashè„šæœ¬ä¸­å¼•ç”¨çš„æ–‡ä»¶"""
        references = set()

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # åŒ¹é…æ–‡ä»¶è·¯å¾„å¼•ç”¨
            patterns = [
                r'python3?\s+([a-zA-Z0-9_/\.]+\.py)',  # python3 script.py
                r'source\s+([a-zA-Z0-9_/\.]+)',  # source file
                r'\.\s+([a-zA-Z0-9_/\.]+)',  # . file
                r'cat\s+([a-zA-Z0-9_/\.]+)',  # cat file
                r'[\"\']([^\"\']*\.(json|txt|md|py|sh))[\"\']',  # "file.ext"
            ]

            for pattern in patterns:
                matches = re.finditer(pattern, content)
                for match in matches:
                    ref = match.group(1)
                    if not ref.startswith('/'):
                        references.add(ref)

        except Exception as e:
            self.errors.append(f"è§£æ{file_path}å¤±è´¥: {e}")

        return references

    def resolve_import_to_file(self, import_name: str) -> List[Path]:
        """å°†importåç§°è§£æä¸ºæ–‡ä»¶è·¯å¾„"""
        files = []

        # ats_coreæ¨¡å—
        if import_name.startswith('ats_core') or import_name == 'ats_core':
            module_parts = import_name.split('.')
            module_path = '/'.join(module_parts)
            possible_paths = [
                self.root_dir / module_path / '__init__.py',
                self.root_dir / (module_path + '.py'),
            ]
            for path in possible_paths:
                if path.exists():
                    files.append(path)

        # scriptsæ¨¡å—
        elif import_name == 'scripts':
            files.append(self.root_dir / 'scripts')

        return files

    def analyze_python_file(self, file_path: Path):
        """åˆ†æPythonæ–‡ä»¶çš„ä¾èµ–"""
        if file_path in self.analyzed_files:
            return

        self.analyzed_files.add(file_path)

        imports = self.extract_python_imports(file_path)

        for imp in imports:
            # åªåˆ†æé¡¹ç›®å†…çš„æ¨¡å—
            if imp in ['ats_core', 'scripts'] or imp.startswith('ats_core.'):
                resolved_files = self.resolve_import_to_file(imp)
                for dep_file in resolved_files:
                    if dep_file.exists():
                        rel_path = dep_file.relative_to(self.root_dir)
                        self.dependencies[str(file_path.relative_to(self.root_dir))].add(str(rel_path))
                        self.reverse_deps[str(rel_path)].add(str(file_path.relative_to(self.root_dir)))

                        # é€’å½’åˆ†æä¾èµ–
                        if dep_file.suffix == '.py' and dep_file not in self.analyzed_files:
                            self.analyze_python_file(dep_file)

    def analyze_bash_file(self, file_path: Path):
        """åˆ†æBashè„šæœ¬çš„ä¾èµ–"""
        if file_path in self.analyzed_files:
            return

        self.analyzed_files.add(file_path)

        references = self.extract_bash_references(file_path)

        for ref in references:
            ref_path = self.root_dir / ref
            if ref_path.exists():
                rel_path = ref_path.relative_to(self.root_dir)
                self.dependencies[str(file_path.relative_to(self.root_dir))].add(str(rel_path))
                self.reverse_deps[str(rel_path)].add(str(file_path.relative_to(self.root_dir)))

                # é€’å½’åˆ†æPythonæ–‡ä»¶
                if ref_path.suffix == '.py':
                    self.analyze_python_file(ref_path)

    def scan_all_files(self) -> Dict[str, List[Path]]:
        """æ‰«ææ‰€æœ‰æ–‡ä»¶å¹¶åˆ†ç±»"""
        file_categories = {
            'python': [],
            'bash': [],
            'config': [],
            'docs': [],
            'tests': [],
            'others': []
        }

        for path in self.root_dir.rglob('*'):
            if path.is_file() and not self.should_ignore(path):
                rel_path = path.relative_to(self.root_dir)

                if path.suffix == '.py':
                    if 'test' in str(path).lower():
                        file_categories['tests'].append(path)
                    else:
                        file_categories['python'].append(path)
                elif path.suffix in ['.sh', '.bash']:
                    file_categories['bash'].append(path)
                elif path.suffix in ['.json', '.yaml', '.yml', '.toml', '.ini']:
                    file_categories['config'].append(path)
                elif path.suffix in ['.md', '.txt', '.rst']:
                    file_categories['docs'].append(path)
                else:
                    file_categories['others'].append(path)

        return file_categories

    def find_unused_files(self, all_files: Set[Path]) -> Set[Path]:
        """æŸ¥æ‰¾æœªè¢«å¼•ç”¨çš„æ–‡ä»¶"""
        used_files = set()

        # ä»setup.shå¼€å§‹çš„æ‰€æœ‰ä¾èµ–
        for file_str in self.analyzed_files:
            if isinstance(file_str, Path):
                used_files.add(file_str)
            else:
                used_files.add(self.root_dir / file_str)

        # ä»reverse_depsä¸­è·å–æ‰€æœ‰è¢«å¼•ç”¨çš„æ–‡ä»¶
        for dep_str in self.reverse_deps.keys():
            used_files.add(self.root_dir / dep_str)

        # æœªä½¿ç”¨çš„æ–‡ä»¶ = æ‰€æœ‰æ–‡ä»¶ - ä½¿ç”¨çš„æ–‡ä»¶
        unused = all_files - used_files

        return unused

    def generate_report(self) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        lines = []

        lines.append("=" * 70)
        lines.append("CryptoSignal v7.2 ä¾èµ–åˆ†ææŠ¥å‘Š")
        lines.append("=" * 70)
        lines.append("")
        lines.append(f"åˆ†ææ ¹ç›®å½•: {self.root_dir}")
        lines.append(f"åˆ†ææ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")

        # 1. æ–‡ä»¶åˆ†ç±»ç»Ÿè®¡
        lines.append("-" * 70)
        lines.append("ğŸ“Š æ–‡ä»¶åˆ†ç±»ç»Ÿè®¡")
        lines.append("-" * 70)

        file_categories = self.scan_all_files()
        total_files = sum(len(files) for files in file_categories.values())

        for category, files in sorted(file_categories.items()):
            count = len(files)
            percentage = (count / total_files * 100) if total_files > 0 else 0
            lines.append(f"  {category:12s}: {count:4d} ä¸ªæ–‡ä»¶ ({percentage:5.1f}%)")

        lines.append(f"  {'æ€»è®¡':12s}: {total_files:4d} ä¸ªæ–‡ä»¶")
        lines.append("")

        # 2. æ ¸å¿ƒå…¥å£æ–‡ä»¶
        lines.append("-" * 70)
        lines.append("ğŸš€ æ ¸å¿ƒå…¥å£æ–‡ä»¶")
        lines.append("-" * 70)

        entry_files = [
            'setup.sh',
            'auto_restart.sh',
            'deploy_and_run.sh',
            'start_live.sh',
            'scripts/realtime_signal_scanner.py',
            'scripts/init_databases.py'
        ]

        for entry in entry_files:
            entry_path = self.root_dir / entry
            if entry_path.exists():
                size = entry_path.stat().st_size
                lines.append(f"  âœ“ {entry:45s} ({size:7,d} bytes)")
            else:
                lines.append(f"  âœ— {entry:45s} (ä¸å­˜åœ¨)")

        lines.append("")

        # 3. ä¾èµ–å…³ç³»ç»Ÿè®¡
        lines.append("-" * 70)
        lines.append("ğŸ”— ä¾èµ–å…³ç³»ç»Ÿè®¡")
        lines.append("-" * 70)

        lines.append(f"  å·²åˆ†ææ–‡ä»¶: {len(self.analyzed_files)} ä¸ª")
        lines.append(f"  ä¾èµ–å…³ç³»: {sum(len(deps) for deps in self.dependencies.values())} æ¡")
        lines.append("")

        # è¢«å¼•ç”¨æœ€å¤šçš„æ–‡ä»¶ (Top 20)
        lines.append("  ğŸ“Œ è¢«å¼•ç”¨æœ€å¤šçš„æ–‡ä»¶ (Top 20):")
        lines.append("")

        sorted_by_refs = sorted(
            self.reverse_deps.items(),
            key=lambda x: len(x[1]),
            reverse=True
        )[:20]

        for i, (file_str, referrers) in enumerate(sorted_by_refs, 1):
            lines.append(f"    {i:2d}. {file_str:50s} ({len(referrers)} æ¬¡å¼•ç”¨)")

        lines.append("")

        # 4. ç›®å½•ç»“æ„åˆ†æ
        lines.append("-" * 70)
        lines.append("ğŸ“ ç›®å½•ç»“æ„åˆ†æ")
        lines.append("-" * 70)

        # ç»Ÿè®¡æ¯ä¸ªç›®å½•çš„æ–‡ä»¶æ•°é‡
        dir_stats = defaultdict(int)
        all_py_files = file_categories['python'] + file_categories['tests']

        for file in all_py_files:
            rel_path = file.relative_to(self.root_dir)
            if len(rel_path.parts) > 1:
                top_dir = rel_path.parts[0]
                dir_stats[top_dir] += 1

        lines.append("")
        for dir_name, count in sorted(dir_stats.items(), key=lambda x: x[1], reverse=True):
            lines.append(f"  {dir_name:30s}: {count:4d} ä¸ªPythonæ–‡ä»¶")

        lines.append("")

        # 5. ats_coreæ¨¡å—ç»“æ„
        lines.append("-" * 70)
        lines.append("ğŸ”§ ats_core æ¨¡å—ç»“æ„")
        lines.append("-" * 70)

        ats_core_path = self.root_dir / 'ats_core'
        if ats_core_path.exists():
            subdirs = [d for d in ats_core_path.iterdir() if d.is_dir() and not d.name.startswith('.')]

            for subdir in sorted(subdirs):
                py_files = list(subdir.glob('*.py'))
                py_files = [f for f in py_files if f.name != '__init__.py']
                lines.append(f"  ats_core/{subdir.name:20s}: {len(py_files):3d} ä¸ªæ¨¡å—")

        lines.append("")

        # 6. é…ç½®æ–‡ä»¶åˆ—è¡¨
        lines.append("-" * 70)
        lines.append("âš™ï¸  é…ç½®æ–‡ä»¶åˆ—è¡¨")
        lines.append("-" * 70)

        config_files = sorted(file_categories['config'])
        for cfg_file in config_files:
            rel_path = cfg_file.relative_to(self.root_dir)
            size = cfg_file.stat().st_size
            lines.append(f"  {str(rel_path):50s} ({size:7,d} bytes)")

        lines.append("")

        # 7. æ–‡æ¡£æ–‡ä»¶åˆ—è¡¨
        lines.append("-" * 70)
        lines.append("ğŸ“š æ–‡æ¡£æ–‡ä»¶åˆ—è¡¨")
        lines.append("-" * 70)

        # æŒ‰ç›®å½•åˆ†ç»„
        doc_by_dir = defaultdict(list)
        for doc_file in file_categories['docs']:
            rel_path = doc_file.relative_to(self.root_dir)
            parent = str(rel_path.parent) if rel_path.parent != Path('.') else 'æ ¹ç›®å½•'
            doc_by_dir[parent].append(rel_path.name)

        for dir_name in sorted(doc_by_dir.keys()):
            lines.append(f"  {dir_name}:")
            for doc_name in sorted(doc_by_dir[dir_name]):
                lines.append(f"    - {doc_name}")
            lines.append("")

        # 8. æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
        lines.append("-" * 70)
        lines.append("ğŸ§ª æµ‹è¯•æ–‡ä»¶åˆ—è¡¨")
        lines.append("-" * 70)

        test_files = sorted(file_categories['tests'])
        if test_files:
            for test_file in test_files:
                rel_path = test_file.relative_to(self.root_dir)
                lines.append(f"  {str(rel_path)}")
        else:
            lines.append("  (æ— æµ‹è¯•æ–‡ä»¶)")

        lines.append("")

        # 9. è„šæœ¬æ–‡ä»¶åˆ—è¡¨
        lines.append("-" * 70)
        lines.append("ğŸ“œ Bashè„šæœ¬åˆ—è¡¨")
        lines.append("-" * 70)

        bash_files = sorted(file_categories['bash'])
        for bash_file in bash_files:
            rel_path = bash_file.relative_to(self.root_dir)
            size = bash_file.stat().st_size
            # æ£€æŸ¥æ˜¯å¦å¯æ‰§è¡Œ
            is_executable = os.access(bash_file, os.X_OK)
            exec_mark = "âœ“" if is_executable else "âœ—"
            lines.append(f"  {exec_mark} {str(rel_path):45s} ({size:7,d} bytes)")

        lines.append("")

        # 10. å…³é”®ä¾èµ–é“¾
        lines.append("-" * 70)
        lines.append("ğŸ” å…³é”®ä¾èµ–é“¾ (setup.sh â†’ realtime_signal_scanner.py)")
        lines.append("-" * 70)

        lines.append("")
        lines.append("  setup.sh")
        lines.append("    â”œâ”€â†’ requirements.txt (Pythonä¾èµ–)")
        lines.append("    â”œâ”€â†’ config/binance_credentials.json (äº¤æ˜“æ‰€é…ç½®)")
        lines.append("    â”œâ”€â†’ config/telegram.json (é€šçŸ¥é…ç½®)")
        lines.append("    â”œâ”€â†’ scripts/init_databases.py (æ•°æ®åº“åˆå§‹åŒ–)")
        lines.append("    â””â”€â†’ scripts/realtime_signal_scanner.py (ä¸»æ‰«æå™¨)")
        lines.append("          â”œâ”€â†’ ats_core.cfg (å…¨å±€é…ç½®)")
        lines.append("          â”œâ”€â†’ ats_core.pipeline.analyze_symbol (åŸºç¡€åˆ†æ)")
        lines.append("          â”œâ”€â†’ ats_core.pipeline.analyze_symbol_v72 (v7.2å¢å¼º)")
        lines.append("          â”œâ”€â†’ ats_core.outputs.telegram_fmt (Telegramæ ¼å¼åŒ–)")
        lines.append("          â”œâ”€â†’ ats_core.sources.binance_futures_client (æ•°æ®æº)")
        lines.append("          â””â”€â†’ config/signal_thresholds.json (ä¿¡å·é˜ˆå€¼)")
        lines.append("")

        # 11. é”™è¯¯å’Œè­¦å‘Š
        if self.errors:
            lines.append("-" * 70)
            lines.append("âš ï¸  é”™è¯¯å’Œè­¦å‘Š")
            lines.append("-" * 70)

            for error in self.errors[:20]:  # æœ€å¤šæ˜¾ç¤º20ä¸ªé”™è¯¯
                lines.append(f"  - {error}")

            if len(self.errors) > 20:
                lines.append(f"  ... è¿˜æœ‰ {len(self.errors) - 20} ä¸ªé”™è¯¯æœªæ˜¾ç¤º")

            lines.append("")

        # 12. æ€»ç»“
        lines.append("=" * 70)
        lines.append("ğŸ“‹ åˆ†ææ€»ç»“")
        lines.append("=" * 70)

        lines.append(f"  âœ“ æ€»æ–‡ä»¶æ•°: {total_files} ä¸ª")
        lines.append(f"  âœ“ Pythonæ–‡ä»¶: {len(file_categories['python'])} ä¸ª")
        lines.append(f"  âœ“ æµ‹è¯•æ–‡ä»¶: {len(file_categories['tests'])} ä¸ª")
        lines.append(f"  âœ“ é…ç½®æ–‡ä»¶: {len(file_categories['config'])} ä¸ª")
        lines.append(f"  âœ“ æ–‡æ¡£æ–‡ä»¶: {len(file_categories['docs'])} ä¸ª")
        lines.append(f"  âœ“ è„šæœ¬æ–‡ä»¶: {len(file_categories['bash'])} ä¸ª")
        lines.append(f"  âœ“ å·²åˆ†ææ–‡ä»¶: {len(self.analyzed_files)} ä¸ª")
        lines.append(f"  âœ“ ä¾èµ–å…³ç³»: {sum(len(deps) for deps in self.dependencies.values())} æ¡")

        if self.errors:
            lines.append(f"  âš  é”™è¯¯æ•°: {len(self.errors)} ä¸ª")

        lines.append("")
        lines.append("=" * 70)
        lines.append("")

        return "\n".join(lines)

    def run_analysis(self):
        """æ‰§è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ” å¼€å§‹åˆ†æä¾èµ–å…³ç³»...")
        print(f"ğŸ“ æ ¹ç›®å½•: {self.root_dir}")
        print("")

        # ä»setup.shå¼€å§‹
        setup_sh = self.root_dir / 'setup.sh'
        if setup_sh.exists():
            print("âœ“ åˆ†æ setup.sh")
            self.analyze_bash_file(setup_sh)

        # åˆ†æå…¶ä»–å…¥å£æ–‡ä»¶
        entry_files = [
            'auto_restart.sh',
            'deploy_and_run.sh',
            'start_live.sh',
            'scripts/realtime_signal_scanner.py',
            'scripts/init_databases.py'
        ]

        for entry in entry_files:
            entry_path = self.root_dir / entry
            if entry_path.exists():
                print(f"âœ“ åˆ†æ {entry}")
                if entry_path.suffix == '.py':
                    self.analyze_python_file(entry_path)
                elif entry_path.suffix == '.sh':
                    self.analyze_bash_file(entry_path)

        print("")
        print(f"âœ“ åˆ†æå®Œæˆï¼å…±åˆ†æ {len(self.analyzed_files)} ä¸ªæ–‡ä»¶")
        print("")


def main():
    """ä¸»å‡½æ•°"""
    analyzer = DependencyAnalyzer()

    # æ‰§è¡Œåˆ†æ
    analyzer.run_analysis()

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_report()

    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = analyzer.root_dir / 'DEPENDENCY_ANALYSIS_REPORT.txt'
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
    print("")
    print("=" * 70)
    print("æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æŠ¥å‘Š:")
    print(f"  cat {output_file}")
    print(f"  less {output_file}")
    print("")
    print("æˆ–è€…ç›´æ¥å‘é€åˆ°Telegramç¾¤:")
    print(f"  cat {output_file} | xclip -selection clipboard  # å¤åˆ¶åˆ°å‰ªè´´æ¿")
    print("=" * 70)
    print("")

    # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    print(report)


if __name__ == '__main__':
    main()
