# coding: utf-8
"""
å¸ç§åˆ—è¡¨åŠ¨æ€åˆ·æ–°æ¨¡å—ï¼ˆv7.4.0æ–¹æ¡ˆBï¼‰

è®¾è®¡åŸåˆ™ï¼š
- é›¶ç¡¬ç¼–ç ï¼šæ‰€æœ‰å‚æ•°ä»configè¯»å–
- åŒç¼“å†²ï¼šä¸å½±å“å½“å‰æ‰«æ
- ä¿å®ˆå®¹é”™ï¼šå¤±è´¥æ—¶ä¿æŒæ—§åˆ—è¡¨
- å®Œæ•´è¿½æº¯ï¼šè®°å½•æ‰€æœ‰å˜åŒ–å†å²
"""

import time
import asyncio
from datetime import datetime, timezone
from typing import List, Dict, Tuple
from ats_core.logging import log, warn, error

TZ_UTC = timezone.utc


async def refresh_symbols_list(scanner, client, kline_cache, symbols_active: List[str], refresh_config: dict) -> Tuple[bool, List[str]]:
    """
    åŠ¨æ€åˆ·æ–°å¸ç§åˆ—è¡¨ï¼ˆç‹¬ç«‹å‡½æ•°ç‰ˆæœ¬ï¼‰

    Args:
        scanner: OptimizedBatchScannerå®ä¾‹
        client: Binanceå®¢æˆ·ç«¯
        kline_cache: Kçº¿ç¼“å­˜
        symbols_active: å½“å‰æ´»è·ƒå¸ç§åˆ—è¡¨
        refresh_config: åˆ·æ–°é…ç½®å­—å…¸

    Returns:
        Tuple[bool, List[str]]: (æ˜¯å¦æˆåŠŸ, æ–°å¸ç§åˆ—è¡¨)
    """
    log("\n" + "=" * 60)
    log("ğŸ”„ å¼€å§‹åˆ·æ–°å¸ç§åˆ—è¡¨ï¼ˆv7.4.0æ–¹æ¡ˆBï¼‰")
    log("=" * 60)

    refresh_start = time.time()

    try:
        # Step 1: è·å–æœ€æ–°äº¤æ˜“å¯¹åˆ—è¡¨
        log("\n1ï¸âƒ£  è·å–æœ€æ–°å¸å®‰USDTåˆçº¦åˆ—è¡¨...")
        exchange_info = await client.get_exchange_info()

        all_symbols = [
            s["symbol"] for s in exchange_info.get("symbols", [])
            if s["symbol"].endswith("USDT")
            and s["status"] == "TRADING"
            and s["contractType"] == "PERPETUAL"
        ]
        log(f"   æ€»è®¡: {len(all_symbols)} ä¸ªUSDTæ°¸ç»­åˆçº¦")

        # è·å–24hè¡Œæƒ…æ•°æ®
        ticker_24h = await client.get_ticker_24h()

        ticker_map = {}
        for ticker in ticker_24h:
            symbol = ticker.get('symbol', '')
            if symbol in all_symbols:
                ticker_map[symbol] = {
                    'volume': float(ticker.get('quoteVolume', 0)),
                    'change_pct': float(ticker.get('priceChangePercent', 0))
                }

        # æµåŠ¨æ€§è¿‡æ»¤
        MIN_VOLUME = 3_000_000
        filtered_symbols = [
            s for s in all_symbols
            if ticker_map.get(s, {}).get('volume', 0) >= MIN_VOLUME
        ]
        log(f"   æµåŠ¨æ€§è¿‡æ»¤å: {len(filtered_symbols)} ä¸ªå¸ç§ï¼ˆ24hæˆäº¤é¢>3M USDTï¼‰")

        # æŒ‰æµåŠ¨æ€§æ’åº
        new_symbols = sorted(
            filtered_symbols,
            key=lambda s: ticker_map.get(s, {}).get('volume', 0),
            reverse=True
        )

        # Step 2: æ¯”å¯¹å˜åŒ–
        log("\n2ï¸âƒ£  æ¯”å¯¹å¸ç§åˆ—è¡¨å˜åŒ–...")
        old_set = set(symbols_active)
        new_set = set(new_symbols)

        added_symbols = list(new_set - old_set)
        removed_symbols = list(old_set - new_set)

        log(f"   æ–°å¢å¸ç§: {len(added_symbols)} ä¸ª")
        if added_symbols:
            log(f"      {', '.join(added_symbols[:10])}{'...' if len(added_symbols) > 10 else ''}")

        log(f"   ç§»é™¤å¸ç§: {len(removed_symbols)} ä¸ª")
        if removed_symbols:
            log(f"      {', '.join(removed_symbols[:10])}{'...' if len(removed_symbols) > 10 else ''}")

        if not added_symbols and not removed_symbols:
            log("   âœ… å¸ç§åˆ—è¡¨æ— å˜åŒ–")
            return True, symbols_active

        # Step 3: æ–°å¸ç§Kçº¿æ•°æ®åˆå§‹åŒ–å’ŒéªŒè¯
        log("\n3ï¸âƒ£  åˆå§‹åŒ–æ–°å¸ç§Kçº¿æ•°æ®...")
        new_coin_cfg = refresh_config.get('new_coin_detection', {})
        min_kline_reqs = new_coin_cfg.get('min_kline_requirements', {})

        min_15m = min_kline_reqs.get('15m_min_bars', 20)
        min_1h = min_kline_reqs.get('1h_min_bars', 24)
        min_4h = min_kline_reqs.get('4h_min_bars', 7)
        min_1d = min_kline_reqs.get('1d_min_bars', 3)

        validated_new_symbols = []

        if added_symbols:
            try:
                await kline_cache.initialize_batch(
                    symbols=added_symbols,
                    intervals=['15m', '1h', '4h', '1d'],
                    client=client
                )

                for symbol in added_symbols:
                    k15m = kline_cache.get_klines(symbol, '15m', 100)
                    k1h = kline_cache.get_klines(symbol, '1h', 100)
                    k4h = kline_cache.get_klines(symbol, '4h', 50)
                    k1d = kline_cache.get_klines(symbol, '1d', 10)

                    bars_15m = len(k15m) if k15m else 0
                    bars_1h = len(k1h) if k1h else 0
                    bars_4h = len(k4h) if k4h else 0
                    bars_1d = len(k1d) if k1d else 0

                    if (bars_15m >= min_15m and bars_1h >= min_1h and
                        bars_4h >= min_4h and bars_1d >= min_1d):
                        validated_new_symbols.append(symbol)
                        log(f"   âœ… {symbol}: Kçº¿æ•°æ®å……è¶³ (15m={bars_15m}, 1h={bars_1h}, 4h={bars_4h}, 1d={bars_1d})")
                    else:
                        log(f"   âš ï¸  {symbol}: Kçº¿æ•°æ®ä¸è¶³")

                log(f"   éªŒè¯å®Œæˆ: {len(validated_new_symbols)}/{len(added_symbols)} ä¸ªæ–°å¸ç§æ•°æ®å……è¶³")

            except Exception as e:
                error(f"   âŒ æ–°å¸ç§Kçº¿åˆå§‹åŒ–å¤±è´¥: {e}")
                validated_new_symbols = []

        # Step 4: æ„å»ºæ–°åˆ—è¡¨
        log("\n4ï¸âƒ£  æ„å»ºæ–°å¸ç§åˆ—è¡¨...")
        symbols_pending = [s for s in symbols_active if s not in removed_symbols]
        symbols_pending.extend(validated_new_symbols)

        # æŒ‰æµåŠ¨æ€§é‡æ–°æ’åº
        symbols_pending = sorted(
            symbols_pending,
            key=lambda s: ticker_map.get(s, {}).get('volume', 0),
            reverse=True
        )

        log(f"   æ—§åˆ—è¡¨: {len(symbols_active)} ä¸ªå¸ç§")
        log(f"   æ–°åˆ—è¡¨: {len(symbols_pending)} ä¸ªå¸ç§")

        # Step 5: è®°å½•å˜åŒ–å†å²
        log("\n5ï¸âƒ£  è®°å½•å¸ç§å˜åŒ–å†å²...")
        _log_symbol_changes(
            timestamp=time.time(),
            total_symbols=len(symbols_pending),
            added=validated_new_symbols,
            removed=removed_symbols,
            ticker_map=ticker_map,
            refresh_config=refresh_config
        )

        refresh_elapsed = time.time() - refresh_start
        log("\n" + "=" * 60)
        log("âœ… å¸ç§åˆ—è¡¨åˆ·æ–°å®Œæˆï¼")
        log("=" * 60)
        log(f"   è€—æ—¶: {refresh_elapsed:.1f}ç§’")
        log(f"   æ–°å¢: {len(validated_new_symbols)} ä¸ªå¸ç§")
        log(f"   ç§»é™¤: {len(removed_symbols)} ä¸ªå¸ç§")
        log(f"   å½“å‰: {len(symbols_pending)} ä¸ªå¸ç§")
        log("=" * 60)

        return True, symbols_pending

    except Exception as e:
        error(f"âŒ å¸ç§åˆ—è¡¨åˆ·æ–°å¤±è´¥: {e}")
        return False, symbols_active


def _log_symbol_changes(timestamp: float, total_symbols: int,
                       added: list, removed: list, ticker_map: dict,
                       refresh_config: dict):
    """è®°å½•å¸ç§å˜åŒ–å†å²åˆ°jsonlæ–‡ä»¶"""
    persistence_cfg = refresh_config.get('persistence', {})
    if not persistence_cfg.get('enabled', True):
        return

    try:
        import json
        from pathlib import Path

        log_file = persistence_cfg.get('log_file', 'data/symbol_list_history.jsonl')
        log_path = Path(__file__).parent.parent.parent / log_file

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        log_path.parent.mkdir(parents=True, exist_ok=True)

        # æ„å»ºè®°å½•
        record = {
            'timestamp': timestamp,
            'datetime_utc': datetime.fromtimestamp(timestamp, tz=TZ_UTC).isoformat(),
            'total_symbols': total_symbols,
            'added_symbols': added,
            'removed_symbols': removed,
            'added_count': len(added),
            'removed_count': len(removed)
        }

        # è¿½åŠ åˆ°jsonlæ–‡ä»¶
        with open(log_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(record, ensure_ascii=False) + '\n')

        log(f"   âœ… å˜åŒ–å†å²å·²è®°å½•: {log_path}")

    except Exception as e:
        warn(f"   âš ï¸  è®°å½•å˜åŒ–å†å²å¤±è´¥: {e}")
