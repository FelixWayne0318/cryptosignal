# coding: utf-8
"""
ä¼˜åŒ–çš„æ‰¹é‡æ‰«æå™¨ï¼ˆv7.3.2-Full - MarketContextå…¨å±€ä¼˜åŒ–ï¼‰

æ€§èƒ½ä¼˜åŒ–:
- é¦–æ¬¡æ‰«æï¼š~2åˆ†é’Ÿï¼ˆé¢„çƒ­Kçº¿ç¼“å­˜ï¼‰
- åç»­æ‰«æï¼š~5ç§’ï¼ˆ100ä¸ªå¸ç§ï¼‰âœ…
- APIè°ƒç”¨ï¼š0æ¬¡/scan âœ…
- æ•°æ®æ–°é²œåº¦ï¼šå®æ—¶æ›´æ–° âœ…

v7.3.2-Full æ–°ç‰¹æ€§:
- MarketContextå…¨å±€ç®¡ç†ï¼šBTCè¶‹åŠ¿è®¡ç®—1æ¬¡/æ‰«æï¼ˆvs 400æ¬¡é‡å¤è®¡ç®—ï¼‰
- Iå› å­vetoé£æ§ï¼šé«˜Betaå¸ç§é€†BTCå¼ºè¶‹åŠ¿è‡ªåŠ¨æ‹¦æˆª
- æ€§èƒ½æå‡ï¼š~400xï¼ˆBTCè¶‹åŠ¿è®¡ç®—éƒ¨åˆ†ï¼‰

å¯¹æ¯”å½“å‰æ–¹æ¡ˆ:
- æ‰«æé€Ÿåº¦ï¼š17å€æå‡ï¼ˆ85ç§’ â†’ 5ç§’ï¼‰
- APIå‹åŠ›ï¼š-100%ï¼ˆ400æ¬¡ â†’ 0æ¬¡ï¼‰
"""

import asyncio
import time
from typing import List, Dict, Optional, Any
from datetime import datetime, timedelta, timezone
from ats_core.execution.binance_futures_client import get_binance_client
from ats_core.data.realtime_kline_cache import get_kline_cache
from ats_core.pipeline.analyze_symbol import analyze_symbol_with_preloaded_klines
from ats_core.logging import log, warn, error
from ats_core.analysis.scan_statistics import get_global_stats, reset_global_stats
from ats_core.config.threshold_config import get_thresholds

# UTCæ—¶åŒºï¼ˆç»Ÿä¸€ä½¿ç”¨UTCï¼Œä¸Binance APIä¿æŒä¸€è‡´ï¼‰
TZ_UTC = timezone.utc


class OptimizedBatchScanner:
    """
    ä¼˜åŒ–çš„æ‰¹é‡æ‰«æå™¨ï¼ˆä½¿ç”¨WebSocket Kçº¿ç¼“å­˜ï¼‰

    ç‰¹æ€§:
    - WebSocketå®æ—¶Kçº¿ç¼“å­˜
    - é›¶APIè°ƒç”¨æ‰«æ
    - 17å€é€Ÿåº¦æå‡
    """

    def __init__(self):
        """åˆå§‹åŒ–æ‰«æå™¨"""
        self.client = None
        self.kline_cache = get_kline_cache()
        self.initialized = False
        self.symbols = []  # ä¿å­˜åˆå§‹åŒ–æ—¶çš„å¸ç§åˆ—è¡¨

        # v6.6å› å­ç³»ç»Ÿï¼šé¢„åŠ è½½çš„å¸‚åœºæ•°æ®ç¼“å­˜
        self.orderbook_cache = {}      # {symbol: orderbook_dict} - Lè°ƒåˆ¶å™¨
        self.mark_price_cache = {}     # {symbol: mark_price} - Bå› å­
        self.funding_rate_cache = {}   # {symbol: funding_rate} - Bå› å­
        self.spot_price_cache = {}     # {symbol: spot_price} - Bå› å­
        # v6.6: liquidation_cacheå·²ç§»é™¤ï¼ˆQå› å­åºŸå¼ƒï¼‰
        self.oi_cache = {}             # {symbol: oi_data_list} - Oå› å­ï¼ˆæŒä»“é‡å†å²ï¼‰
        self.btc_klines = []           # BTC Kçº¿æ•°æ® - Iè°ƒåˆ¶å™¨
        self.eth_klines = []           # ETH Kçº¿æ•°æ® - Iè°ƒåˆ¶å™¨

        # v7.2+: åŠ è½½æ‰«æè¾“å‡ºé…ç½®
        self.output_config = self._load_output_config()

        # v7.3.4ä¿®å¤ï¼šåŠ è½½ä¿¡å·é˜ˆå€¼é…ç½®ï¼ˆé¿å…ç¡¬ç¼–ç ï¼‰
        self.threshold_config = get_thresholds()

        log("âœ… ä¼˜åŒ–æ‰¹é‡æ‰«æå™¨åˆ›å»ºæˆåŠŸ")

    def _load_output_config(self) -> dict:
        """
        åŠ è½½æ‰«æè¾“å‡ºé…ç½®

        Returns:
            dict: è¾“å‡ºé…ç½®å­—å…¸
        """
        import json
        from pathlib import Path

        config_path = Path(__file__).parent.parent.parent / 'config' / 'scan_output.json'

        # é»˜è®¤é…ç½®ï¼ˆå½“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼‰
        default_config = {
            "output_detail_level": {
                "mode": "full",  # full=æ‰€æœ‰å¸ç§, limited=å‰Nä¸ª, minimal=ä»…æ±‡æ€»
                "limited_count": 10
            },
            "factor_output": {
                "show_all_factors": True,
                "show_core_factors": True,
                "show_modulators": True,
                "show_gates": True,
                "show_prime_breakdown": True
            },
            "diagnostic_output": {
                "show_f_factor_details": True,
                "show_i_factor_details": True,
                "show_intermediate_values": True,
                "alert_on_saturation": True,
                "saturation_threshold": 98
            },
            "performance": {
                "show_slow_coins": True,
                "slow_threshold_sec": 5.0,
                "show_progress_interval": 20
            },
            "rejection_output": {
                "show_rejection_reasons": True,
                "max_reasons_per_coin": 2
            }
        }

        try:
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    log(f"âœ… åŠ è½½æ‰«æè¾“å‡ºé…ç½®: {config_path}")
                    return config
            else:
                warn(f"âš ï¸  æ‰«æè¾“å‡ºé…ç½®ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {config_path}")
                return default_config
        except Exception as e:
            warn(f"âš ï¸  åŠ è½½æ‰«æè¾“å‡ºé…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return default_config

    async def initialize(self, enable_websocket: bool = False):
        """
        åˆå§‹åŒ–ï¼ˆä»…ä¸€æ¬¡ï¼Œçº¦1-2åˆ†é’Ÿï¼‰

        Args:
            enable_websocket: æ˜¯å¦å¯ç”¨WebSocketå®æ—¶æ›´æ–°ï¼ˆé»˜è®¤Falseï¼Œæ¨èç¦ç”¨ï¼‰
                - Falseï¼ˆæ¨èï¼‰: RESTå®šæ—¶æ›´æ–°æ¨¡å¼ï¼Œç¨³å®šé«˜æ•ˆ
                  * 1h/4h Kçº¿æ¯å°æ—¶æ‰æ›´æ–°ä¸€æ¬¡ï¼Œä¸éœ€è¦å®æ—¶è®¢é˜…
                  * é¿å…280ä¸ªWebSocketè¿æ¥å’Œé¢‘ç¹é‡è¿é—®é¢˜
                  * æ€§èƒ½æ›´å¥½ï¼Œç¨³å®šæ€§æ›´é«˜
                - True: WebSocketå®æ—¶æ¨¡å¼ï¼ˆä¸æ¨èï¼‰
                  * 280ä¸ªè¿æ¥ï¼Œæ¥è¿‘300ä¸Šé™
                  * ç½‘ç»œæ³¢åŠ¨æ—¶é¢‘ç¹é‡è¿
                  * å®é™…æ”¶ç›Šå¾ˆå°ï¼ˆ1h Kçº¿æ¯å°æ—¶æ‰æ›´æ–°ï¼‰

        æ­¥éª¤:
        1. åˆå§‹åŒ–Binanceå®¢æˆ·ç«¯
        2. è·å–å€™é€‰å¸ç§åˆ—è¡¨
        3. æ‰¹é‡åˆå§‹åŒ–Kçº¿ç¼“å­˜ï¼ˆRESTï¼‰
        4. å¯åŠ¨WebSocketå®æ—¶æ›´æ–°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ç¦ç”¨ï¼‰
        5. é¢„åŠ è½½10ç»´å› å­æ•°æ®ï¼ˆè®¢å•ç°¿ã€OIç­‰ï¼‰
        """
        if self.initialized:
            log("âš ï¸  å·²åˆå§‹åŒ–ï¼Œè·³è¿‡")
            return

        log("\n" + "=" * 60)
        log("ğŸš€ åˆå§‹åŒ–ä¼˜åŒ–æ‰¹é‡æ‰«æå™¨...")
        log("=" * 60)

        init_start = time.time()

        # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
        log("\n1ï¸âƒ£  åˆå§‹åŒ–Binanceå®¢æˆ·ç«¯...")
        self.client = get_binance_client()
        await self.client.initialize()

        # 2. è·å–é«˜æµåŠ¨æ€§USDTåˆçº¦å¸ç§ï¼ˆå…¨å¸‚åœºæ‰«æï¼Œv6.8ä¼˜åŒ–ï¼‰
        log("\n2ï¸âƒ£  è·å–å¸å®‰USDTåˆçº¦å¸ç§ï¼ˆå…¨å¸‚åœºæ‰«æï¼‰...")

        # è·å–äº¤æ˜“æ‰€ä¿¡æ¯
        exchange_info = await self.client.get_exchange_info()

        # ç­›é€‰USDTæ°¸ç»­åˆçº¦
        all_symbols = [
            s["symbol"] for s in exchange_info.get("symbols", [])
            if s["symbol"].endswith("USDT")
            and s["status"] == "TRADING"
            and s["contractType"] == "PERPETUAL"
        ]
        log(f"   æ€»è®¡: {len(all_symbols)} ä¸ªUSDTæ°¸ç»­åˆçº¦")

        # è·å–24hè¡Œæƒ…æ•°æ®ï¼ˆç”¨äºæ³¢åŠ¨ç‡+æµåŠ¨æ€§ç»¼åˆç­›é€‰ï¼‰
        log("   è·å–24hè¡Œæƒ…æ•°æ®...")
        ticker_24h = await self.client.get_ticker_24h()

        # æ„å»ºè¡Œæƒ…å­—å…¸ï¼ˆæˆäº¤é¢ + æ³¢åŠ¨ç‡ï¼‰
        ticker_map = {}
        for ticker in ticker_24h:
            symbol = ticker.get('symbol', '')
            if symbol in all_symbols:
                ticker_map[symbol] = {
                    'volume': float(ticker.get('quoteVolume', 0)),  # USDTæˆäº¤é¢
                    'change_pct': float(ticker.get('priceChangePercent', 0))  # 24hæ¶¨è·Œå¹…
                }

        # è¿‡æ»¤æ‰æµåŠ¨æ€§å¤ªä½çš„ï¼ˆ<3M USDT/24hï¼‰
        MIN_VOLUME = 3_000_000
        filtered_symbols = [
            s for s in all_symbols
            if ticker_map.get(s, {}).get('volume', 0) >= MIN_VOLUME
        ]
        log(f"   æµåŠ¨æ€§è¿‡æ»¤å: {len(filtered_symbols)} ä¸ªå¸ç§ï¼ˆ24hæˆäº¤é¢>3M USDTï¼‰")

        # å…¨å¸‚åœºæ‰«æï¼šåˆ†ææ‰€æœ‰æµåŠ¨æ€§åˆæ ¼çš„å¸ç§
        # è®¾è®¡åŸç†ï¼šä¸é¢„å…ˆæŒ‰æ³¢åŠ¨ç‡ç­›é€‰ï¼Œé¿å…æ¼æ‰"è“„åŠ¿å¾…å‘"çš„å¸
        # ç³»ç»Ÿæœ‰4é“è´¨é‡é—¨æ§›ï¼ˆDataQual/EV/Execution/Probabilityï¼‰ä¼šè‡ªåŠ¨è¿‡æ»¤ä½è´¨é‡ä¿¡å·

        # æŒ‰æµåŠ¨æ€§æ’åºï¼ˆä¿è¯æ‰«æé¡ºåºç¨³å®šï¼‰
        symbols = sorted(
            filtered_symbols,
            key=lambda s: ticker_map.get(s, {}).get('volume', 0),
            reverse=True
        )

        log(f"   âœ… å…¨å¸‚åœºæ‰«æ: {len(symbols)} ä¸ªå¸ç§ï¼ˆä¸é™æ³¢åŠ¨ç‡ï¼Œå‘ç°è“„åŠ¿æ½œåŠ›è‚¡ï¼‰")

        # éªŒè¯æ˜¯å¦æˆåŠŸè·å–åˆ°å¸ç§
        if not symbols:
            raise RuntimeError(
                "âŒ æ— æ³•è·å–äº¤æ˜“å¸ç§åˆ—è¡¨ï¼å¯èƒ½åŸå› ï¼š\n"
                "   1. ç½‘ç»œè¿æ¥é—®é¢˜ï¼ˆDNSè§£æå¤±è´¥ã€é˜²ç«å¢™é˜»æ­¢ç­‰ï¼‰\n"
                "   2. Binance APIæœåŠ¡å¼‚å¸¸\n"
                "   3. æ‰€æœ‰å¸ç§æµåŠ¨æ€§ä¸è¶³ï¼ˆ<3M USDT/24hï¼‰\n"
                "   è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å¹¶é‡è¯•ã€‚"
            )

        # æ˜¾ç¤ºæµåŠ¨æ€§TOP 5
        log(f"   æµåŠ¨æ€§TOP 5: {', '.join(symbols[:5])}")

        # ç»Ÿè®¡å¤šç©ºåˆ†å¸ƒï¼ˆ24hæ¶¨è·Œæƒ…å†µï¼‰
        up_count = sum(1 for s in symbols if ticker_map.get(s, {}).get('change_pct', 0) > 0)
        down_count = len(symbols) - up_count
        flat_count = len(symbols) - up_count - down_count
        log(f"   å¤šç©ºåˆ†å¸ƒ: ä¸Šæ¶¨{up_count}ä¸ª / ä¸‹è·Œ{down_count}ä¸ª / æ¨ªç›˜{flat_count}ä¸ª")

        # æ˜¾ç¤ºæˆäº¤é¢èŒƒå›´
        top_volume = ticker_map.get(symbols[0], {}).get('volume', 0)
        last_volume = ticker_map.get(symbols[-1], {}).get('volume', 0)
        log(f"   æˆäº¤é¢èŒƒå›´: {top_volume/1e6:.1f}M ~ {last_volume/1e6:.1f}M USDT")

        # ä¿å­˜åˆå§‹åŒ–çš„å¸ç§åˆ—è¡¨
        self.symbols = symbols

        # 3. æ‰¹é‡åˆå§‹åŒ–Kçº¿ç¼“å­˜ï¼ˆRESTï¼Œä¸€æ¬¡æ€§ï¼‰
        log(f"\n3ï¸âƒ£  æ‰¹é‡åˆå§‹åŒ–Kçº¿ç¼“å­˜ï¼ˆè¿™æ˜¯ä¸€æ¬¡æ€§æ“ä½œï¼‰...")
        await self.kline_cache.initialize_batch(
            symbols=symbols,
            intervals=['1h', '4h', '15m', '1d'],  # MTFéœ€è¦ï¼š15m/1h/4h/1d
            client=self.client
        )

        # 4. WebSocketå®æ—¶æ›´æ–°ï¼ˆé»˜è®¤ç¦ç”¨ï¼Œæ¨èä½¿ç”¨RESTå®šæ—¶æ›´æ–°ï¼‰
        if enable_websocket:
            # v2.0åˆè§„ï¼šWebSocketæ¨¡å¼è¿åDATA_LAYER.md Â§ 2è§„èŒƒï¼ˆè¿æ¥æ•°â‰¤5ï¼‰
            # å½“å‰å®ç°ä¼šåˆ›å»º ~200å¸ç§ Ã— 4å‘¨æœŸ = ~800ä¸ªè¿æ¥ï¼Œä¸¥é‡è¶…é™
            # å¿…é¡»å…ˆå®ç°ç»„åˆæµæ¶æ„ï¼ˆCombined Streamï¼‰æ‰èƒ½å¯ç”¨WebSocket
            raise NotImplementedError(
                "âŒ WebSocketæ¨¡å¼éœ€ä¿®å¤ä¸ºç»„åˆæµæ¶æ„ï¼ˆâ‰¤5è¿æ¥ï¼‰\n"
                "   å½“å‰å®ç°: 800ä¸ªç‹¬ç«‹è¿æ¥ï¼ˆè¿åè§„èŒƒï¼‰\n"
                "   è§„èŒƒè¦æ±‚: â‰¤5ä¸ªç»„åˆæµè¿æ¥ï¼ˆDATA_LAYER.md Â§ 2ï¼‰\n"
                "   è§£å†³æ–¹æ¡ˆ: å®ç°Binance Combined Streamæ¶æ„\n"
                "   æ¨èæ¨¡å¼: ä½¿ç”¨enable_websocket=Falseï¼ˆRESTå®šæ—¶æ›´æ–°ï¼‰"
            )
        else:
            log(f"\n4ï¸âƒ£  âœ… WebSocketå·²ç¦ç”¨ï¼ˆæ¨èæ¨¡å¼ï¼Œv2.0åˆè§„ï¼‰")
            log(f"   åŸå› :")
            log(f"   - 1h/4h Kçº¿æ¯å°æ—¶æ‰æ›´æ–°ä¸€æ¬¡ï¼Œä¸éœ€è¦å®æ—¶è®¢é˜…")
            log(f"   - WebSocketè¿æ¥ä¸ç¨³å®šï¼Œé¢‘ç¹é‡è¿å½±å“æ€§èƒ½")
            log(f"   - RESTæ‰¹é‡è·å–æ›´å¿«æ›´ç¨³å®šï¼ˆ50ç§’ vs 5åˆ†é’Ÿï¼‰")
            log(f"   åç»­: ä½¿ç”¨RESTæ‰¹é‡è·å–ï¼ŒKçº¿æ•°æ®å·²åœ¨æ­¥éª¤3ä¸­åˆå§‹åŒ–")

        # 5. é¢„åŠ è½½10ç»´å› å­ç³»ç»Ÿæ‰€éœ€çš„å¸‚åœºæ•°æ®
        log(f"\n5ï¸âƒ£  é¢„åŠ è½½10ç»´å› å­ç³»ç»Ÿæ•°æ®ï¼ˆè®¢å•ç°¿ã€èµ„é‡‘è´¹ç‡ã€ç°è´§ä»·æ ¼ï¼‰...")
        data_start = time.time()

        # å¯¼å…¥æ–°å¢çš„æ‰¹é‡æ•°æ®è·å–å‡½æ•°
        from ats_core.sources.binance import (
            get_all_spot_prices,
            get_all_premium_index,
            get_orderbook_snapshot
        )

        # 5.1 æ‰¹é‡è·å–ç°è´§ä»·æ ¼ï¼ˆ1æ¬¡APIè°ƒç”¨ï¼‰
        log("   5.1 æ‰¹é‡è·å–ç°è´§ä»·æ ¼...")
        try:
            all_spot_prices = get_all_spot_prices()
            self.spot_price_cache = {
                symbol: all_spot_prices.get(symbol, 0)
                for symbol in symbols
            }
            found_count = sum(1 for v in self.spot_price_cache.values() if v > 0)
            log(f"       âœ… è·å– {found_count}/{len(symbols)} ä¸ªå¸ç§çš„ç°è´§ä»·æ ¼")
        except Exception as e:
            warn(f"       âš ï¸  ç°è´§ä»·æ ¼è·å–å¤±è´¥: {e}")
            self.spot_price_cache = {}

        # 5.2 æ‰¹é‡è·å–æ ‡è®°ä»·æ ¼å’Œèµ„é‡‘è´¹ç‡ï¼ˆ1æ¬¡APIè°ƒç”¨ï¼‰
        log("   5.2 æ‰¹é‡è·å–æ ‡è®°ä»·æ ¼å’Œèµ„é‡‘è´¹ç‡...")
        try:
            all_premium = get_all_premium_index()
            for item in all_premium:
                symbol = item.get('symbol', '')
                if symbol in symbols:
                    self.mark_price_cache[symbol] = float(item.get('markPrice', 0))
                    self.funding_rate_cache[symbol] = float(item.get('lastFundingRate', 0))
            log(f"       âœ… è·å– {len(self.mark_price_cache)} ä¸ªå¸ç§çš„æ ‡è®°ä»·æ ¼å’Œèµ„é‡‘è´¹ç‡")
        except Exception as e:
            warn(f"       âš ï¸  æ ‡è®°ä»·æ ¼/èµ„é‡‘è´¹ç‡è·å–å¤±è´¥: {e}")
            self.mark_price_cache = {}
            self.funding_rate_cache = {}

        # 5.3 æ‰¹é‡è·å–è®¢å•ç°¿å¿«ç…§ï¼ˆå¹¶å‘è·å–ï¼Œçº¦140æ¬¡APIè°ƒç”¨ï¼‰
        log("   5.3 æ‰¹é‡è·å–è®¢å•ç°¿æ·±åº¦ï¼ˆ100æ¡£ï¼Œä»·æ ¼å¸¦æ³•ï¼‰...")
        log("       ğŸš€ ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼Œé¢„è®¡20-30ç§’")

        orderbook_success = 0
        orderbook_failed = 0

        # ğŸ”§ FIX: ä½¿ç”¨å¹¶å‘è·å–ï¼Œå¤§å¹…æå‡é€Ÿåº¦
        async def fetch_one_orderbook(symbol: str):
            """å¼‚æ­¥è·å–å•ä¸ªè®¢å•ç°¿"""
            try:
                # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥å‡½æ•°ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                loop = asyncio.get_event_loop()
                # æ³¨ï¼šä½¿ç”¨è¶³å¤Ÿæ·±åº¦ä¾›ä»·æ ¼å¸¦æ³•åˆ†æ
                orderbook = await loop.run_in_executor(
                    None,  # ä½¿ç”¨é»˜è®¤çº¿ç¨‹æ± 
                    lambda: get_orderbook_snapshot(symbol, limit=100)
                )
                return symbol, orderbook, None
            except Exception as e:
                return symbol, None, e

        # åˆ†æ‰¹å¹¶å‘è·å–ï¼ˆé¿å…é€Ÿç‡é™åˆ¶ï¼‰
        batch_size = 20  # æ¯æ‰¹20ä¸ªå¹¶å‘è¯·æ±‚
        for i in range(0, len(symbols), batch_size):
            batch = symbols[i:i+batch_size]

            # å¹¶å‘è·å–è¿™ä¸€æ‰¹çš„æ‰€æœ‰è®¢å•ç°¿
            tasks = [fetch_one_orderbook(symbol) for symbol in batch]
            results = await asyncio.gather(*tasks)

            # å¤„ç†ç»“æœ
            for symbol, orderbook, error in results:
                if error is None and orderbook:
                    self.orderbook_cache[symbol] = orderbook
                    orderbook_success += 1
                else:
                    orderbook_failed += 1
                    # è®°å½•å‰5ä¸ªå¤±è´¥çš„è¯¦ç»†ä¿¡æ¯
                    if orderbook_failed <= 5:
                        warn(f"       è·å–{symbol}è®¢å•ç°¿å¤±è´¥: {error}")

            # æ‰¹é—´å»¶è¿Ÿï¼ˆé¿å…é€Ÿç‡é™åˆ¶ï¼‰
            if i + batch_size < len(symbols):
                await asyncio.sleep(0.5)  # å‡å°‘å»¶è¿Ÿï¼Œå› ä¸ºå¹¶å‘äº†

            # è¿›åº¦æ˜¾ç¤º
            progress = min(i + batch_size, len(symbols))
            if progress % 40 == 0 or progress >= len(symbols):
                log(f"       è¿›åº¦: {progress}/{len(symbols)} ({progress/len(symbols)*100:.0f}%)")

        log(f"       âœ… æˆåŠŸ: {orderbook_success}, å¤±è´¥: {orderbook_failed}")

        # v6.6: ç§»é™¤èšåˆæˆäº¤æ•°æ®è·å–ï¼ˆQå› å­å·²åºŸå¼ƒï¼‰
        # åŸv6.5ä»£ç ï¼š5.4 æ‰¹é‡è·å–èšåˆæˆäº¤æ•°æ®
        # log("   5.4 æ‰¹é‡è·å–èšåˆæˆäº¤æ•°æ®ï¼ˆQå› å­ï¼‰...")
        # log("       ğŸš€ ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼Œé¢„è®¡10-15ç§’")
        # from ats_core.sources.binance import get_agg_trades
        # [å·²ç§»é™¤çº¦50è¡Œä»£ç ]

        # 5.5 æ‰¹é‡è·å–æŒä»“é‡å†å²æ•°æ®ï¼ˆOå› å­ - æœ€å¤§æ€§èƒ½ç“¶é¢ˆä¼˜åŒ–ï¼‰
        log("   5.5 æ‰¹é‡è·å–æŒä»“é‡å†å²æ•°æ®ï¼ˆOå› å­ï¼‰...")
        log("       ğŸš€ ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼Œé¢„è®¡60-80ç§’ï¼ˆåŸéœ€700ç§’ï¼ï¼‰")
        from ats_core.sources.binance_safe import batch_get_open_interest_hist

        oi_start = time.time()
        try:
            # æ‰¹é‡å¼‚æ­¥è·å–æ‰€æœ‰å¸ç§çš„OIæ•°æ®
            self.oi_cache = await batch_get_open_interest_hist(
                symbols=symbols,
                period='1h',
                limit=300,
                batch_size=20
            )
            oi_elapsed = time.time() - oi_start
            oi_success = sum(1 for oi_data in self.oi_cache.values() if oi_data)
            log(f"       âœ… æˆåŠŸ: {oi_success}/{len(symbols)}, è€—æ—¶: {oi_elapsed:.1f}ç§’")
            log(f"       ğŸš€ æ€§èƒ½æå‡: {700/oi_elapsed:.1f}xï¼ˆä»700ç§’é™è‡³{oi_elapsed:.0f}ç§’ï¼‰")
        except Exception as e:
            warn(f"       âš ï¸  æ‰¹é‡è·å–OIå¤±è´¥: {e}")
            self.oi_cache = {}

        # 5.6 è·å–BTCå’ŒETH Kçº¿æ•°æ®ï¼ˆIå› å­ï¼‰
        log("   5.6 è·å–BTCå’ŒETH Kçº¿æ•°æ®ï¼ˆIå› å­ï¼‰...")
        from ats_core.sources.binance import get_klines

        try:
            # è·å–BTC 1å°æ—¶Kçº¿ï¼ˆæœ€è¿‘48å°æ—¶ï¼Œç”¨äºè®¡ç®—ç›¸å…³æ€§ï¼‰
            self.btc_klines = get_klines('BTCUSDT', '1h', 48)
            log(f"       âœ… è·å–BTC Kçº¿: {len(self.btc_klines)}æ ¹")
        except Exception as e:
            warn(f"       âš ï¸  BTC Kçº¿è·å–å¤±è´¥: {e}")
            self.btc_klines = []

        try:
            # è·å–ETH 1å°æ—¶Kçº¿ï¼ˆæœ€è¿‘48å°æ—¶ï¼‰
            self.eth_klines = get_klines('ETHUSDT', '1h', 48)
            log(f"       âœ… è·å–ETH Kçº¿: {len(self.eth_klines)}æ ¹")
        except Exception as e:
            warn(f"       âš ï¸  ETH Kçº¿è·å–å¤±è´¥: {e}")
            self.eth_klines = []

        data_elapsed = time.time() - data_start
        log(f"   æ•°æ®é¢„åŠ è½½å®Œæˆï¼Œè€—æ—¶: {data_elapsed:.1f}ç§’")

        self.initialized = True

        init_elapsed = time.time() - init_start

        log("\n" + "=" * 60)
        log("âœ… ä¼˜åŒ–æ‰¹é‡æ‰«æå™¨åˆå§‹åŒ–å®Œæˆï¼")
        log("=" * 60)
        log(f"   æ€»è€—æ—¶: {init_elapsed:.0f}ç§’ ({init_elapsed/60:.1f}åˆ†é’Ÿ)")
        log(f"   åç»­æ‰«æå°†æå¿«ï¼ˆçº¦5ç§’ï¼‰")
        log("=" * 60)

    def _get_market_context(self) -> Dict[str, Any]:
        """
        è·å–å¸‚åœºä¸Šä¸‹æ–‡ï¼ˆv7.3.2-Fullç»Ÿä¸€ç®¡ç†ï¼‰

        åŠŸèƒ½ï¼š
        1. è®¡ç®—BTCè¶‹åŠ¿ï¼ˆT_BTCï¼‰- 1æ¬¡è®¡ç®— vs 400æ¬¡/æ‰«æ
        2. å°è£…BTC/ETH Kçº¿æ•°æ®
        3. è¿”å›ç»Ÿä¸€çš„market_metaå­—å…¸ä¾›analyze_symbolä½¿ç”¨

        æ€§èƒ½ä¼˜åŒ–ï¼š
        - æ—§æ–¹æ¡ˆï¼šæ¯ä¸ªå¸ç§éƒ½è®¡ç®—ä¸€æ¬¡BTCè¶‹åŠ¿ï¼ˆ400æ¬¡é‡å¤è®¡ç®—ï¼‰
        - æ–°æ–¹æ¡ˆï¼šå…¨å±€è®¡ç®—1æ¬¡BTCè¶‹åŠ¿ï¼ˆ1æ¬¡è®¡ç®—ï¼Œ400æ¬¡å¤ç”¨ï¼‰
        - æ€§èƒ½æå‡ï¼š~400xï¼ˆBTCè¶‹åŠ¿è®¡ç®—éƒ¨åˆ†ï¼‰

        Returns:
            dict: {
                'btc_klines': List,     # BTC Kçº¿æ•°æ®
                'eth_klines': List,     # ETH Kçº¿æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼‰
                'btc_trend': float,     # T_BTCè¶‹åŠ¿å€¼ [-100, +100]
                'btc_trend_meta': dict  # BTCè¶‹åŠ¿è®¡ç®—å…ƒæ•°æ®
            }
        """
        market_meta = {
            'btc_klines': self.btc_klines,
            'eth_klines': self.eth_klines,
            'btc_trend': 0,  # é»˜è®¤ä¸­æ€§
            'btc_trend_meta': {}
        }

        # v7.3.2-Full: è®¡ç®—BTCè¶‹åŠ¿ï¼ˆT_BTCï¼‰
        if self.btc_klines and len(self.btc_klines) >= 96:
            try:
                from ats_core.factors_v2.trend import score_trend

                # æå–BTCæ”¶ç›˜ä»·åºåˆ—
                def _to_f(x):
                    """å®‰å…¨ç±»å‹è½¬æ¢"""
                    try:
                        return float(x) if x is not None else 0.0
                    except (ValueError, TypeError):
                        return 0.0

                btc_closes = [_to_f(k[4]) for k in self.btc_klines]  # Kçº¿æ ¼å¼: [ts, o, h, l, c, v, ...]

                # è®¡ç®—BTCè¶‹åŠ¿ï¼ˆä½¿ç”¨ä¸analyze_symbolç›¸åŒçš„é€»è¾‘ï¼‰
                T_BTC, T_meta = score_trend(
                    closes=btc_closes,
                    highs=[_to_f(k[2]) for k in self.btc_klines],
                    lows=[_to_f(k[3]) for k in self.btc_klines],
                    params={}  # ä½¿ç”¨é»˜è®¤å‚æ•°
                )

                market_meta['btc_trend'] = T_BTC
                market_meta['btc_trend_meta'] = T_meta

                log(f"   MarketContext: T_BTC={T_BTC:.1f} (BTCè¶‹åŠ¿å·²è®¡ç®—)")

            except Exception as e:
                warn(f"   âš ï¸  BTCè¶‹åŠ¿è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼0: {e}")
                market_meta['btc_trend'] = 0
                market_meta['btc_trend_meta'] = {'error': str(e)}
        else:
            btc_count = len(self.btc_klines) if self.btc_klines else 0
            warn(f"   âš ï¸  BTC Kçº¿æ•°æ®ä¸è¶³ï¼ˆ{btc_count}<96ï¼‰ï¼ŒT_BTCè®¾ä¸º0")
            market_meta['btc_trend_meta'] = {
                'status': 'insufficient_data',
                'btc_klines_count': btc_count
            }

        return market_meta

    async def scan(
        self,
        min_score: int = 35,  # v6.3: é™ä½é˜ˆå€¼ä»70åˆ°35ï¼ˆä¸“å®¶å»ºè®® #4ï¼‰
        max_symbols: Optional[int] = None,
        on_signal_found: Optional[callable] = None,
        verbose: bool = False
    ) -> Dict:
        """
        æ‰¹é‡æ‰«æï¼ˆè¶…å¿«é€Ÿï¼Œçº¦5ç§’ï¼‰

        Args:
            min_score: æœ€ä½ä¿¡å·åˆ†æ•°ï¼ˆv6.3: é»˜è®¤35ï¼Œé€‚é…æ”¾å®½åçš„è¯„åˆ†ç³»ç»Ÿï¼‰
            max_symbols: æœ€å¤§æ‰«æå¸ç§æ•°ï¼ˆNone=å…¨éƒ¨ï¼Œç”¨äºæµ‹è¯•ï¼‰
            on_signal_found: å‘ç°ä¿¡å·æ—¶çš„å›è°ƒå‡½æ•°ï¼ˆå®æ—¶å¤„ç†ä¿¡å·ï¼‰
                            async def callback(signal_dict) -> None
            verbose: æ˜¯å¦æ˜¾ç¤ºæ‰€æœ‰å¸ç§çš„è¯¦ç»†å› å­è¯„åˆ†ï¼ˆé»˜è®¤Falseï¼Œåªæ˜¾ç¤ºå‰10ä¸ªï¼‰

        Returns:
            æ‰«æç»“æœå­—å…¸

        æ€§èƒ½:
        - 100ä¸ªå¸ç§çº¦5ç§’
        - 0æ¬¡APIè°ƒç”¨
        """
        if not self.initialized:
            raise RuntimeError("æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize()")

        log("\n" + "=" * 60)
        log("ğŸ” å¼€å§‹æ‰¹é‡æ‰«æï¼ˆWebSocketç¼“å­˜åŠ é€Ÿï¼‰")
        log("=" * 60)

        scan_start = time.time()

        # ä½¿ç”¨åˆå§‹åŒ–æ—¶ä¿å­˜çš„å¸ç§åˆ—è¡¨ï¼ˆç¡®ä¿ä¸ç¼“å­˜ä¸€è‡´ï¼‰
        symbols = self.symbols.copy()

        # é™åˆ¶æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰
        if max_symbols:
            symbols = symbols[:max_symbols]

        log(f"   æ‰«æå¸ç§: {len(symbols)} ä¸ªé«˜æµåŠ¨æ€§å¸ç§")
        log(f"   æœ€ä½åˆ†æ•°: {min_score}")
        log("=" * 60)

        # é‡ç½®å…¨å±€ç»Ÿè®¡ï¼ˆv6.8: æ‰«æåè‡ªåŠ¨åˆ†æå¹¶å‘é€åˆ°Telegramï¼‰
        reset_global_stats()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Phase 1: ä¸‰å±‚æ™ºèƒ½æ•°æ®æ›´æ–°
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        current_time = datetime.now(TZ_UTC)
        current_minute = current_time.minute

        # Layer 1: ä»·æ ¼æ›´æ–°ï¼ˆæ¯æ¬¡éƒ½æ‰§è¡Œï¼Œæœ€è½»é‡ï¼‰
        log("\nğŸ“ˆ [Layer 1] æ›´æ–°å®æ—¶ä»·æ ¼...")
        try:
            if self.client is None:
                warn("âš ï¸  å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡Layer 1æ›´æ–°")
            else:
                await self.kline_cache.update_current_prices(
                    symbols=symbols,
                    client=self.client  # âœ… ä¿®å¤ï¼šä½¿ç”¨å·²åˆå§‹åŒ–çš„ self.client
                )
        except Exception as e:
            error(f"âŒ Layer 1 æ›´æ–°å¼‚å¸¸: {e}")
            import traceback
            error(traceback.format_exc())

        # Layer 2: Kçº¿å¢é‡æ›´æ–°ï¼ˆæ™ºèƒ½è§¦å‘ï¼‰
        # 15m Kçº¿ï¼šåœ¨02, 17, 32, 47åˆ†è§¦å‘
        if current_minute in [2, 17, 32, 47]:
            log(f"\nğŸ“Š [Layer 2] æ›´æ–°15m Kçº¿ï¼ˆå®Œæˆæ—¶é—´: {current_minute-2:02d}åˆ†ï¼‰...")
            try:
                if self.client is None:
                    warn("âš ï¸  å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡Layer 2 (15m)æ›´æ–°")
                else:
                    await self.kline_cache.update_completed_klines(
                        symbols=symbols,
                        intervals=['15m'],
                        client=self.client  # âœ… ä¿®å¤ï¼šä½¿ç”¨ self.client
                    )
            except Exception as e:
                error(f"âŒ Layer 2 (15m) æ›´æ–°å¼‚å¸¸: {e}")
                import traceback
                error(traceback.format_exc())

        # 1h/4h Kçº¿ï¼šåœ¨05åˆ†æˆ–07åˆ†è§¦å‘ï¼ˆæ¯å°æ—¶ä¸€æ¬¡ï¼Œ07åˆ†ä½œä¸ºå¤‡ä»½ï¼‰
        if current_minute in [5, 7]:
            log(f"\nğŸ“Š [Layer 2] æ›´æ–°1h/4h Kçº¿ï¼ˆå®Œæˆæ—¶é—´: {current_time.hour:02d}:00ï¼‰...")
            try:
                if self.client is None:
                    warn("âš ï¸  å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡Layer 2 (1h/4h)æ›´æ–°")
                else:
                    await self.kline_cache.update_completed_klines(
                        symbols=symbols,
                        intervals=['1h', '4h'],
                        client=self.client  # âœ… ä¿®å¤ï¼šä½¿ç”¨ self.client
                    )
            except Exception as e:
                error(f"âŒ Layer 2 (1h/4h) æ›´æ–°å¼‚å¸¸: {e}")
                import traceback
                error(traceback.format_exc())

        # Layer 3: å¸‚åœºæ•°æ®æ›´æ–°ï¼ˆä½é¢‘ï¼Œæ¯30åˆ†é’Ÿï¼‰
        if current_minute in [0, 30]:
            log(f"\nğŸ“‰ [Layer 3] æ›´æ–°å¸‚åœºæ•°æ®ï¼ˆèµ„é‡‘è´¹ç‡/æŒä»“é‡/BTC-ETH Kçº¿ï¼‰...")
            try:
                if self.client is None:
                    warn("âš ï¸  å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡Layer 3æ›´æ–°")
                else:
                    await self.kline_cache.update_market_data(
                        symbols=symbols,
                        client=self.client  # âœ… ä¿®å¤ï¼šä½¿ç”¨ self.client
                    )

                    # P0ä¿®å¤ï¼šå®šæœŸæ›´æ–°BTC/ETH Kçº¿ï¼ˆIå› å­éœ€è¦ï¼‰
                    log("   æ›´æ–°BTC/ETH Kçº¿ï¼ˆIå› å­ï¼‰...")
                    from ats_core.sources.binance import get_klines
                    try:
                        self.btc_klines = get_klines('BTCUSDT', '1h', 48)
                        self.eth_klines = get_klines('ETHUSDT', '1h', 48)
                        log(f"   âœ… BTC Kçº¿: {len(self.btc_klines)}æ ¹, ETH Kçº¿: {len(self.eth_klines)}æ ¹")
                    except Exception as e:
                        warn(f"   âš ï¸  BTC/ETH Kçº¿æ›´æ–°å¤±è´¥ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰: {e}")
            except Exception as e:
                error(f"âŒ Layer 3 æ›´æ–°å¼‚å¸¸: {e}")
                import traceback
                error(traceback.format_exc())

        log("\n" + "=" * 60)
        log("âœ… æ•°æ®æ›´æ–°å®Œæˆï¼Œå¼€å§‹åˆ†æå¸ç§")
        log("=" * 60)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v7.3.2-Full Phase 5: ç»Ÿä¸€å¸‚åœºä¸Šä¸‹æ–‡ç®¡ç†
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        log("\nğŸŒ [MarketContext] è®¡ç®—å…¨å±€å¸‚åœºä¸Šä¸‹æ–‡...")
        market_context_start = time.time()
        market_meta = self._get_market_context()
        market_context_elapsed = time.time() - market_context_start
        log(f"   âœ… MarketContextå·²ç”Ÿæˆï¼ˆè€—æ—¶{market_context_elapsed:.3f}ç§’ï¼‰")
        log(f"   ä¼˜åŒ–æ•ˆæœ: 1æ¬¡è®¡ç®— vs {len(symbols)}æ¬¡é‡å¤è®¡ç®— â†’ {len(symbols)}xæ€§èƒ½æå‡")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Phase 2: æ‰¹é‡æ‰«æåˆ†æ
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        results = []
        skipped = 0
        errors = 0

        log(f"\nå¼€å§‹æ‰«æ {len(symbols)} ä¸ªå¸ç§...")

        for i, symbol in enumerate(symbols):
            try:
                log(f"[{i+1}/{len(symbols)}] æ­£åœ¨åˆ†æ {symbol}...")

                # ä»ç¼“å­˜è·å–Kçº¿ï¼ˆ0æ¬¡APIè°ƒç”¨ï¼Œæ”¯æŒMTFï¼‰âœ…
                k1h = self.kline_cache.get_klines(symbol, '1h', 300)
                k4h = self.kline_cache.get_klines(symbol, '4h', 200)
                k15m = self.kline_cache.get_klines(symbol, '15m', 200)
                k1d = self.kline_cache.get_klines(symbol, '1d', 100)

                log(f"  â””â”€ Kçº¿æ•°æ®: 1h={len(k1h) if k1h else 0}æ ¹, 4h={len(k4h) if k4h else 0}æ ¹, 15m={len(k15m) if k15m else 0}æ ¹, 1d={len(k1d) if k1d else 0}æ ¹")

                # v6.2ä¿®å¤ï¼šè®¡ç®—çœŸå®å¸é¾„ï¼ˆåŸºäºKçº¿æ—¶é—´æˆ³ï¼Œè€ŒéKçº¿æ•°é‡ï¼‰
                # æ—§ä»£ç ä½¿ç”¨len(k1h)å¯¼è‡´BTC/ETHç­‰æˆç†Ÿå¸è¢«è¯¯åˆ¤ä¸ºæ–°å¸
                if k1h and len(k1h) > 0:
                    # Kçº¿æ ¼å¼: [timestamp_ms, open, high, low, close, volume, ...]
                    first_kline_ts = k1h[0][0]  # ç¬¬ä¸€æ ¹Kçº¿æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    latest_kline_ts = k1h[-1][0]  # æœ€åä¸€æ ¹Kçº¿æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    coin_age_ms = latest_kline_ts - first_kline_ts
                    coin_age_hours = coin_age_ms / (1000 * 3600)  # è½¬æ¢ä¸ºå°æ—¶
                    bars_1h = len(k1h)  # Kçº¿æ ¹æ•°
                else:
                    coin_age_hours = 0
                    bars_1h = 0

                coin_age_days = coin_age_hours / 24

                # v7.3.4è§„èŒƒç¬¦åˆæ€§ä¿®æ”¹ï¼šæŒ‰ç…§ NEWCOIN_SPEC.md Â§ 1 æ ‡å‡†
                # è§„èŒƒå®šä¹‰ï¼š
                # - è¿›å…¥æ–°å¸é€šé“: since_listing < 14d æˆ– bars_1h < 400
                # - å›åˆ‡æ ‡å‡†é€šé“: bars_1h â‰¥ 400 ä¸” OI/fundingè¿ç»­â‰¥3dï¼Œæˆ– since_listing â‰¥ 14d
                #
                # å½“å‰ç®€åŒ–å®ç°ï¼š
                # - ä½¿ç”¨bars_1h < 400ä½œä¸ºä¸»åˆ¤æ–­æ¡ä»¶ï¼ˆç¬¦åˆè§„èŒƒï¼‰
                # - coin_age_days < 14ä½œä¸ºè¾…åŠ©ï¼ˆåŸºäºKçº¿æ—¶é—´æˆ³ï¼ŒéçœŸå®ä¸Šå¸æ—¶é—´ï¼‰
                # - æœªå®ç°48hæ¸å˜åˆ‡æ¢ï¼ˆTODOï¼‰

                # æ£€æµ‹æ•°æ®å—é™æƒ…å†µ
                data_limited = (bars_1h >= 200)  # â‰¥200æ ¹1h Kçº¿ï¼Œè§†ä¸ºæ•°æ®å……è¶³

                # v7.3.40ä¿®å¤ï¼šä»é…ç½®è¯»å–æ–°å¸é˜¶æ®µè¯†åˆ«é˜ˆå€¼ï¼ˆé¿å…ç¡¬ç¼–ç ï¼‰
                config = get_thresholds()
                ultra_new_hours = config.config.get('æ–°å¸é˜¶æ®µè¯†åˆ«', {}).get('ultra_new_hours', 24)
                phase_A_hours = config.config.get('æ–°å¸é˜¶æ®µè¯†åˆ«', {}).get('phase_A_hours', 168)
                phase_B_hours = config.config.get('æ–°å¸é˜¶æ®µè¯†åˆ«', {}).get('phase_B_hours', 400)

                # æ ¹æ®è§„èŒƒåˆ¤æ–­å¸ç§ç±»å‹å¹¶ç¡®å®šæœ€å°æ•°æ®è¦æ±‚
                if data_limited:
                    # æ•°æ®å—é™ï¼ˆâ‰¥200æ ¹Kçº¿ï¼‰ï¼Œæ— æ³•ç¡®å®šçœŸå®å¸é¾„ï¼Œé»˜è®¤æˆç†Ÿå¸
                    min_k1h = 96
                    min_k4h = 50
                    coin_type = "æˆç†Ÿå¸(æ•°æ®å—é™)"
                elif bars_1h < phase_B_hours:
                    # è§„èŒƒæ¡ä»¶1: bars_1h < phase_B_hours â†’ æ–°å¸
                    if bars_1h < ultra_new_hours:  # é»˜è®¤ < 24å°æ—¶
                        min_k1h = 10
                        min_k4h = 3
                        coin_type = f"æ–°å¸Ultra(<{ultra_new_hours}h)"
                    elif bars_1h < phase_A_hours:  # é»˜è®¤ < 168å°æ—¶ï¼ˆ7å¤©ï¼‰
                        min_k1h = 30
                        min_k4h = 8
                        coin_type = f"æ–°å¸A({ultra_new_hours//24}-{phase_A_hours//24}d)"
                    else:  # phase_A_hours - phase_B_hoursï¼ˆé»˜è®¤ 7-16.7å¤©ï¼‰
                        min_k1h = 50
                        min_k4h = 15
                        coin_type = f"æ–°å¸B({phase_A_hours//24}-{phase_B_hours//24}d)"
                elif coin_age_days < 14:
                    # è§„èŒƒæ¡ä»¶2: since_listing < 14dï¼ˆè¿‘ä¼¼ï¼‰
                    min_k1h = 50
                    min_k4h = 15
                    coin_type = "æ–°å¸B(barsâ‰¥400ä½†<14d)"
                else:
                    # æˆç†Ÿå¸ï¼šbars_1h â‰¥ 400 ä¸” since_listing â‰¥ 14d
                    min_k1h = 96
                    min_k4h = 50
                    coin_type = "æˆç†Ÿå¸"

                # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                if not k1h or len(k1h) < min_k1h:
                    skipped += 1
                    log(f"  â””â”€ âš ï¸  è·³è¿‡ï¼ˆ{coin_type}ï¼Œ1hæ•°æ®ä¸è¶³ï¼š{len(k1h) if k1h else 0}<{min_k1h}ï¼‰")
                    continue

                if not k4h or len(k4h) < min_k4h:
                    skipped += 1
                    log(f"  â””â”€ âš ï¸  è·³è¿‡ï¼ˆ{coin_type}ï¼Œ4hæ•°æ®ä¸è¶³ï¼š{len(k4h) if k4h else 0}<{min_k4h}ï¼‰")
                    continue

                log(f"  â””â”€ å¸ç§ç±»å‹ï¼š{coin_type}ï¼ˆ{coin_age_hours}å°æ—¶ï¼‰")

                log(f"  â””â”€ å¼€å§‹å› å­åˆ†æ...")

                # æ€§èƒ½ç›‘æ§
                analysis_start = time.time()

                # è·å–v6.6å› å­ç³»ç»Ÿæ‰€éœ€çš„å¸‚åœºæ•°æ®
                orderbook = self.orderbook_cache.get(symbol)
                mark_price = self.mark_price_cache.get(symbol)
                funding_rate = self.funding_rate_cache.get(symbol)
                spot_price = self.spot_price_cache.get(symbol)
                # v6.6: ç§»é™¤ liquidationsï¼ˆQå› å­å·²åºŸå¼ƒï¼‰
                oi_data = self.oi_cache.get(symbol, [])  # Oå› å­ï¼ˆæŒä»“é‡å†å²ï¼‰

                # v7.3.2-Full: ä½¿ç”¨ç»Ÿä¸€çš„MarketContextï¼ˆåŒ…å«btc_klines/eth_klines/btc_trendï¼‰
                btc_klines = market_meta['btc_klines']  # Iè°ƒåˆ¶å™¨ï¼ˆç‹¬ç«‹æ€§ï¼‰
                eth_klines = market_meta['eth_klines']  # Iè°ƒåˆ¶å™¨ï¼ˆç‹¬ç«‹æ€§ï¼Œå‘åå…¼å®¹ï¼‰

                # v6.6å› å­åˆ†æï¼ˆ6å› å­+4è°ƒåˆ¶å™¨ï¼‰
                result = analyze_symbol_with_preloaded_klines(
                    symbol=symbol,
                    k1h=k1h,
                    k4h=k4h,
                    k15m=k15m,  # ç”¨äºå¾®ç¡®è®¤å’ŒMTF
                    k1d=k1d,    # ç”¨äºMTF
                    orderbook=orderbook,       # Lè°ƒåˆ¶å™¨ï¼ˆæµåŠ¨æ€§ï¼‰
                    mark_price=mark_price,     # Bå› å­ï¼ˆåŸºå·®+èµ„é‡‘è´¹ï¼‰
                    funding_rate=funding_rate, # Bå› å­ï¼ˆåŸºå·®+èµ„é‡‘è´¹ï¼‰
                    spot_price=spot_price,     # Bå› å­ï¼ˆåŸºå·®+èµ„é‡‘è´¹ï¼‰
                    oi_data=oi_data,           # Oå› å­ï¼ˆæŒä»“é‡å†å²ï¼‰
                    btc_klines=btc_klines,     # Iè°ƒåˆ¶å™¨ï¼ˆç‹¬ç«‹æ€§ï¼‰
                    eth_klines=eth_klines,     # Iè°ƒåˆ¶å™¨ï¼ˆç‹¬ç«‹æ€§ï¼‰
                    kline_cache=self.kline_cache,  # v6.6: å››é—¨DataQualæ£€æŸ¥
                    market_meta=market_meta    # v7.3.2-Full: ç»Ÿä¸€å¸‚åœºä¸Šä¸‹æ–‡ï¼ˆå«T_BTCï¼‰
                )

                # v7.3.41ä¿®å¤ï¼šbatch_scanç›´æ¥åº”ç”¨v7.2å¢å¼ºï¼ˆP1-Highï¼‰
                # æ ¹å› ï¼šä¹‹å‰batch_scanåªåšåŸºç¡€åˆ†æï¼Œrealtime_scannerå†åº”ç”¨v7.2å¢å¼º
                # ç»“æœï¼šscan_summary.mdæ˜¾ç¤º"v7.2å¢å¼ºå¤±è´¥100%"ï¼ˆé”™è¯¯ç»Ÿè®¡ï¼‰
                # ä¿®å¤ï¼šbatch_scanæ‰«ææ—¶ç›´æ¥åº”ç”¨v7.2å¢å¼ºï¼Œç¡®ä¿ç»Ÿè®¡æ­£ç¡®
                from ats_core.pipeline.analyze_symbol_v72 import analyze_with_v72_enhancements

                # ä»é…ç½®è¯»å–v7.2æ•°æ®è¦æ±‚ï¼ˆé¿å…ç¡¬ç¼–ç ï¼‰
                # v7.3.41ä¿®å¤ï¼šconfigæ˜¯ThresholdConfigå¯¹è±¡ï¼Œéœ€è¦ä½¿ç”¨config.config.get()
                min_klines_for_v72 = config.config.get('v72å¢å¼ºå‚æ•°', {}).get('min_klines_for_v72', 150)
                min_cvd_points = config.config.get('v72å¢å¼ºå‚æ•°', {}).get('min_cvd_points', 20)

                # ä»intermediate_dataè·å–æ•°æ®ï¼ˆv7.3.40å·²ä¿®å¤ï¼Œç¡®ä¿æ•°æ®å­˜åœ¨ï¼‰
                intermediate = result.get('intermediate_data', {})
                result_klines = intermediate.get('klines', [])
                result_cvd = intermediate.get('cvd_series', [])
                result_oi = intermediate.get('oi_data', [])
                result_atr = intermediate.get('atr_now', 0)

                # æ£€æŸ¥æ•°æ®æ˜¯å¦æ»¡è¶³v7.2è¦æ±‚
                if len(result_klines) >= min_klines_for_v72 and len(result_cvd) >= min_cvd_points:
                    try:
                        # åº”ç”¨v7.2å¢å¼ºï¼ˆåŒ…å«Gate6/7æ£€æŸ¥ï¼‰
                        result = analyze_with_v72_enhancements(
                            original_result=result,
                            symbol=symbol,
                            klines=result_klines,
                            oi_data=result_oi,
                            cvd_series=result_cvd,
                            atr_now=result_atr
                        )
                    except Exception as e:
                        warn(f"   âš ï¸  v7.2å¢å¼ºå¤±è´¥ {symbol}: {e}")
                        # å¤±è´¥æ—¶ç¡®ä¿æœ‰v72_enhancementså­—æ®µï¼ˆä¾›ç»Ÿè®¡ä½¿ç”¨ï¼‰
                        if 'v72_enhancements' not in result:
                            result['v72_enhancements'] = {}
                else:
                    # æ•°æ®ä¸è¶³æ—¶æ·»åŠ ç©ºçš„v72_enhancementsï¼ˆä¾›ç»Ÿè®¡ä½¿ç”¨ï¼‰
                    if 'v72_enhancements' not in result:
                        result['v72_enhancements'] = {}

                analysis_time = time.time() - analysis_start

                # æ€§èƒ½è¯¦æƒ…ï¼ˆæ…¢é€Ÿå¸ç§ï¼Œæ ¹æ®é…ç½®ï¼‰
                slow_threshold = self.output_config.get('performance', {}).get('slow_threshold_sec', 5.0)
                show_slow = self.output_config.get('performance', {}).get('show_slow_coins', True)

                if show_slow and analysis_time > slow_threshold:
                    log(f"  â””â”€ âš ï¸  åˆ†æè€—æ—¶è¾ƒé•¿: {analysis_time:.1f}ç§’")
                    # æ‰“å°å„æŒ‡æ ‡è€—æ—¶
                    perf = result.get('perf', {})
                    if perf:
                        slow_steps = {k: v for k, v in perf.items() if v > 1.0}
                        if slow_steps:
                            log(f"      æ…¢é€Ÿæ­¥éª¤:")
                            for step, t in sorted(slow_steps.items(), key=lambda x: -x[1]):
                                log(f"      - {step}: {t:.1f}ç§’")

                log(f"  â””â”€ åˆ†æå®Œæˆï¼ˆè€—æ—¶{analysis_time:.1f}ç§’ï¼‰")

                # v6.8: æ”¶é›†ç»Ÿè®¡æ•°æ®ï¼ˆç”¨äºæ‰«æåè‡ªåŠ¨åˆ†æï¼‰
                stats = get_global_stats()
                stats.add_symbol_result(symbol, result)

                # é˜¶æ®µ1.2bä¿®å¤ï¼šä½¿ç”¨åŸºæœ¬è´¨é‡æŒ‡æ ‡ç­›é€‰å€™é€‰ä¿¡å·ï¼ˆè€Œéä¾èµ–publish.primeï¼‰
                # è®¾è®¡ç†å¿µï¼šbatch_scanåšåˆæ­¥ç­›é€‰ï¼Œv7.2å±‚åšæœ€ç»ˆåˆ¤å®š
                confidence = result.get('confidence', 0)
                prime_strength = result.get('publish', {}).get('prime_strength', 0)

                # v7.3.4ä¿®å¤ï¼šä»é…ç½®è¯»å–å€™é€‰ä¿¡å·é˜ˆå€¼ï¼ˆé¿å…ç¡¬ç¼–ç 45ï¼‰
                # ä½¿ç”¨ä¸åŸºç¡€åˆ†æç›¸åŒçš„confidence_miné˜ˆå€¼ï¼Œç¡®ä¿å€™é€‰ä¿¡å·èƒ½ä¼ é€’åˆ°v7.2å±‚
                confidence_threshold = self.threshold_config.get_mature_threshold('confidence_min', 8)
                is_candidate = confidence >= confidence_threshold

                # å‘åå…¼å®¹ï¼šåŒæ—¶è¯»å–publish.primeï¼ˆä½†ä¸ä¾èµ–å®ƒï¼‰
                base_is_prime = result.get('publish', {}).get('prime', False)

                # ğŸ” v7.2å¢å¼ºï¼šä½¿ç”¨é…ç½®æ§åˆ¶è¯¦ç»†è¾“å‡º
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
                output_mode = self.output_config.get('output_detail_level', {}).get('mode', 'full')
                limited_count = self.output_config.get('output_detail_level', {}).get('limited_count', 10)

                # åˆ¤æ–­æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                should_show_detail = False
                if output_mode == 'full':
                    should_show_detail = True
                elif output_mode == 'limited':
                    should_show_detail = (i < limited_count)
                elif output_mode == 'minimal':
                    should_show_detail = False
                # å‘åå…¼å®¹ï¼šå¦‚æœä¼ å…¥äº†verboseå‚æ•°ï¼Œå¼ºåˆ¶æ˜¾ç¤º
                if verbose:
                    should_show_detail = True

                if should_show_detail:
                    scores = result.get('scores', {})
                    modulation = result.get('modulation', {})  # v2.0: F moved to modulation
                    prime_breakdown = result.get('publish', {}).get('prime_breakdown', {})
                    gates_info = result.get('gates', {})
                    scores_meta = result.get('scores_meta', {})  # v7.2: å…ƒæ•°æ®

                    log(f"  â””â”€ [è¯„åˆ†] confidence={confidence}, prime_strength={prime_strength}")

                    # 6æ ¸å¿ƒå› å­
                    if self.output_config.get('factor_output', {}).get('show_core_factors', True):
                        log(f"      A-å±‚æ ¸å¿ƒå› å­: T={scores.get('T',0):.1f}, M={scores.get('M',0):.1f}, C={scores.get('C',0):.1f}, "
                            f"V={scores.get('V',0):.1f}, O={scores.get('O',0):.1f}, B={scores.get('B',0):.1f}")

                    # 4è°ƒåˆ¶å™¨
                    if self.output_config.get('factor_output', {}).get('show_modulators', True):
                        log(f"      B-å±‚è°ƒåˆ¶å™¨: L={modulation.get('L',0):.1f}, S={modulation.get('S',0):.1f}, "
                            f"F={modulation.get('F',0):.1f}, I={modulation.get('I',0):.1f}")

                    # v7.2+: Få› å­è¯¦ç»†è¯Šæ–­æ•°æ®
                    if self.output_config.get('diagnostic_output', {}).get('show_f_factor_details', True):
                        F_value = modulation.get('F', 0)
                        F_meta = scores_meta.get('F', {})

                        # æå–Få› å­å…ƒæ•°æ®
                        F_raw = F_meta.get('F_raw', 'N/A')
                        fund_momentum = F_meta.get('fund_momentum', 'N/A')
                        price_momentum = F_meta.get('price_momentum', 'N/A')
                        atr_norm = F_meta.get('atr_norm', 'N/A')

                        # æ£€æŸ¥é¥±å’ŒçŠ¶æ€
                        saturation_threshold = self.output_config.get('diagnostic_output', {}).get('saturation_threshold', 98)
                        is_saturated = abs(F_value) >= saturation_threshold
                        saturation_indicator = " âš ï¸ é¥±å’Œ" if is_saturated else ""

                        log(f"      Få› å­è¯¦æƒ…{saturation_indicator}:")
                        log(f"        F={F_value:.0f}, F_raw={F_raw}, fund_momentum={fund_momentum}, price_momentum={price_momentum}, atr_norm={atr_norm}")

                        # å¦‚æœé…ç½®äº†é¥±å’Œè­¦å‘Šä¸”ç¡®å®é¥±å’Œï¼Œé¢å¤–æç¤º
                        if is_saturated and self.output_config.get('diagnostic_output', {}).get('alert_on_saturation', True):
                            log(f"        âš ï¸  Få› å­æ¥è¿‘é¥±å’Œï¼ˆ|F|>={saturation_threshold}ï¼‰ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´scaleå‚æ•°")

                    # v7.2+: Iå› å­è¯¦ç»†è¯Šæ–­æ•°æ®
                    if self.output_config.get('diagnostic_output', {}).get('show_i_factor_details', True):
                        I_value = modulation.get('I', 0)
                        I_meta = scores_meta.get('I', {})

                        beta_btc = I_meta.get('beta_btc', 'N/A')
                        beta_eth = I_meta.get('beta_eth', 'N/A')
                        independence_level = I_meta.get('independence_level', 'N/A')

                        log(f"      Iå› å­è¯¦æƒ…:")
                        log(f"        I={I_value:.0f}, beta_btc={beta_btc}, beta_eth={beta_eth}, level={independence_level}")

                    # é—¸é—¨ä¿¡æ¯
                    if self.output_config.get('factor_output', {}).get('show_gates', True):
                        log(f"      å››é—¨è°ƒèŠ‚: DataQual={gates_info.get('data_qual',0):.2f}, "
                            f"EV={gates_info.get('ev_gate',0):.2f}, "
                            f"Execution={gates_info.get('execution',0):.2f}, "
                            f"Probability={gates_info.get('probability',0):.2f}")

                    # Primeåˆ†è§£
                    if self.output_config.get('factor_output', {}).get('show_prime_breakdown', True):
                        log(f"      Primeåˆ†è§£: base={prime_breakdown.get('base_strength',0):.1f}, "
                            f"prob_bonus={prime_breakdown.get('prob_bonus',0):.1f}, "
                            f"P_chosen={prime_breakdown.get('P_chosen',0):.3f}")

                # P1.1+é˜¶æ®µ1.2bä¿®å¤ï¼šå°†å€™é€‰ä¿¡å·ä¼ é€’ç»™v7.2å±‚
                # è®¾è®¡ç†å¿µï¼š
                # - æ‰¹é‡æ‰«æå±‚ï¼šåˆæ­¥ç­›é€‰ï¼ˆconfidence >= 45ï¼‰
                # - v7.2å¢å¼ºå±‚ï¼šé›†ä¸­è¿‡æ»¤å’Œå‘å¸ƒå†³ç­–ï¼ˆç»Ÿä¸€æ ‡å‡†ï¼‰
                # - é¿å…å¤šå±‚é‡å¤è¿‡æ»¤å¯¼è‡´é€»è¾‘æ··ä¹±å’Œç”¨æˆ·å›°æƒ‘
                rejection_reasons = result.get('publish', {}).get('rejection_reason', [])

                if is_candidate:
                    # L1ä¿®å¤ï¼šåŸºç¡€å±‚å·²åœ¨intermediate_dataä¸­è¿”å›klines/oi_data/cvd_series
                    # ä¸éœ€è¦é‡å¤è®¡ç®—ï¼Œç›´æ¥ä½¿ç”¨resultå³å¯
                    # ï¼ˆä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™é¡¶å±‚å­—æ®µçš„è®¾ç½®ï¼‰
                    intermediate = result.get('intermediate_data', {})
                    if intermediate:
                        # å¦‚æœæœ‰intermediate_dataï¼Œæå–åˆ°é¡¶å±‚ï¼ˆv7.2å…¼å®¹æ€§ï¼‰
                        result['klines'] = intermediate.get('klines', k1h)
                        result['oi_data'] = intermediate.get('oi_data', oi_data)
                        result['cvd_series'] = intermediate.get('cvd_series', [])
                    else:
                        # é™çº§ï¼šå¦‚æœæ²¡æœ‰intermediate_dataï¼ˆæ—§ç‰ˆæœ¬ï¼‰ï¼Œè®¾ç½®é»˜è®¤å€¼
                        result['klines'] = k1h
                        result['oi_data'] = oi_data
                        result['cvd_series'] = []

                    results.append(result)

                    # è®°å½•å€™é€‰ä¿¡å·ï¼ˆé˜¶æ®µ1.2bï¼šæ ‡è®°ä¸ºå€™é€‰ï¼Œæœ€ç»ˆåˆ¤å®šåœ¨v7.2å±‚ï¼‰
                    candidate_mark = "âœ…" if base_is_prime else "ğŸ”¶"  # ğŸ”¶è¡¨ç¤ºå€™é€‰ï¼ˆä¸ç¡®å®šï¼‰
                    log(f"{candidate_mark} {symbol}: ç½®ä¿¡åº¦={confidence:.0f}, Primeå¼ºåº¦={prime_strength} (å€™é€‰ä¿¡å·ï¼Œå¾…v7.2æœ€ç»ˆåˆ¤å®š)")

                    # å®æ—¶å›è°ƒï¼šç«‹å³å¤„ç†æ–°å‘ç°çš„ä¿¡å·
                    if on_signal_found:
                        try:
                            await on_signal_found(result)
                        except Exception as e:
                            warn(f"âš ï¸  ä¿¡å·å›è°ƒå¤±è´¥: {e}")
                elif should_show_detail:
                    # æ˜¾ç¤ºæ‹’ç»åŸå› ï¼ˆæ ¹æ®é…ç½®ï¼‰
                    if rejection_reasons and self.output_config.get('rejection_output', {}).get('show_rejection_reasons', True):
                        max_reasons = self.output_config.get('rejection_output', {}).get('max_reasons_per_coin', 2)
                        log(f"  â””â”€ âŒ æ‹’ç»: {'; '.join(rejection_reasons[:max_reasons])}")

                # è¿›åº¦æ˜¾ç¤ºï¼ˆæ ¹æ®é…ç½®ï¼‰
                progress_interval = self.output_config.get('performance', {}).get('show_progress_interval', 20)
                if (i + 1) % progress_interval == 0:
                    elapsed = time.time() - scan_start
                    progress = (i + 1) / len(symbols) * 100
                    speed = (i + 1) / elapsed

                    log(f"   è¿›åº¦: {i+1}/{len(symbols)} ({progress:.0f}%), "
                        f"é€Ÿåº¦: {speed:.1f} å¸ç§/ç§’, "
                        f"å·²æ‰¾åˆ°: {len(results)} ä¸ªä¿¡å·")

            except Exception as e:
                errors += 1
                warn(f"âš ï¸  {symbol} åˆ†æå¤±è´¥: {e}")
                # v7.3.47 ä¸´æ—¶è¯Šæ–­ï¼šæ‰“å°å®Œæ•´å †æ ˆè·Ÿè¸ª
                import traceback
                warn(f"å®Œæ•´é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")

        scan_elapsed = time.time() - scan_start

        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = self.kline_cache.get_stats()

        log("\n" + "=" * 60)
        log("âœ… æ‰¹é‡æ‰«æå®Œæˆ")
        log("=" * 60)
        log(f"   æ€»å¸ç§: {len(symbols)}")
        log(f"   é«˜è´¨é‡ä¿¡å·: {len(results)}")
        log(f"   è·³è¿‡: {skipped}ï¼ˆæ•°æ®ä¸è¶³ï¼‰")
        log(f"   é”™è¯¯: {errors}")
        log(f"   è€—æ—¶: {scan_elapsed:.1f}ç§’")
        log(f"   é€Ÿåº¦: {len(symbols)/scan_elapsed:.1f} å¸ç§/ç§’ ğŸš€")
        log(f"   APIè°ƒç”¨: 0æ¬¡ âœ…")
        log(f"   ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']}")
        log(f"   å†…å­˜å ç”¨: {cache_stats['memory_estimate_mb']:.1f}MB")
        log("=" * 60)

        # v6.8: ç”Ÿæˆç»Ÿè®¡åˆ†ææŠ¥å‘Šå¹¶å†™å…¥ä»“åº“
        try:
            stats = get_global_stats()
            report = stats.generate_statistics_report()

            # æ‰“å°åˆ°æ—¥å¿—
            log("\n" + report)

            # v6.8+: å†™å…¥ä»“åº“ï¼ˆJSON + Markdownï¼‰
            try:
                from ats_core.analysis.report_writer import get_report_writer
                writer = get_report_writer()

                # ç”Ÿæˆæ•°æ®
                summary_data = stats.generate_summary_data()
                detail_data = stats.generate_detail_data()

                # æ·»åŠ æ‰«ææ€§èƒ½ä¿¡æ¯åˆ°summary
                summary_data['performance'] = {
                    'total_time_sec': round(scan_elapsed, 2),
                    'speed_coins_per_sec': round(len(symbols) / scan_elapsed, 2),
                    'api_calls': 0,
                    'cache_hit_rate': cache_stats.get('hit_rate', 'N/A'),
                    'memory_mb': cache_stats.get('memory_estimate_mb', 0)
                }

                # å†™å…¥æ–‡ä»¶
                files = writer.write_scan_report(
                    summary=summary_data,
                    detail=detail_data,
                    text_report=report
                )

                log("âœ… æŠ¥å‘Šå·²å†™å…¥ä»“åº“:")
                for key, path in files.items():
                    log(f"   - {key}: {path}")

                # v7.2+: å†™å…¥æ•°æ®åº“ï¼ˆå†å²ç»Ÿè®¡ï¼‰
                try:
                    from ats_core.data.analysis_db import get_analysis_db
                    analysis_db = get_analysis_db()
                    record_id = analysis_db.write_scan_statistics(summary_data)
                    log(f"âœ… æ‰«æç»Ÿè®¡å·²å†™å…¥æ•°æ®åº“ï¼ˆè®°å½•ID: {record_id}ï¼‰")
                except Exception as e:
                    warn(f"âš ï¸  å†™å…¥æ•°æ®åº“å¤±è´¥: {e}")

                # v6.9+: è‡ªåŠ¨æäº¤å¹¶æ¨é€åˆ°Gitä»“åº“ï¼ˆé™é»˜æ¨¡å¼ï¼‰
                import subprocess
                from pathlib import Path
                auto_commit_script = Path(__file__).parent.parent.parent / 'scripts' / 'auto_commit_reports.sh'

                if auto_commit_script.exists():
                    try:
                        result = subprocess.run(
                            ['bash', str(auto_commit_script)],
                            capture_output=True,
                            text=True,
                            timeout=60
                        )
                        if result.returncode == 0:
                            # åªæ˜¾ç¤ºè„šæœ¬è¾“å‡ºçš„æˆåŠŸæ¶ˆæ¯ï¼ˆâœ…å¼€å¤´çš„è¡Œï¼‰
                            for line in result.stdout.strip().split('\n'):
                                if line.startswith('âœ…'):
                                    log(line)
                                    break
                        else:
                            warn(f"âš ï¸  è‡ªåŠ¨æäº¤å¤±è´¥: {result.stderr}")
                    except subprocess.TimeoutExpired:
                        warn("âš ï¸  è‡ªåŠ¨æäº¤è¶…æ—¶ï¼ˆ60ç§’ï¼‰")
                    except Exception as e:
                        warn(f"âš ï¸  è‡ªåŠ¨æäº¤å¼‚å¸¸: {e}")
                else:
                    log(f"âš ï¸  è‡ªåŠ¨æäº¤è„šæœ¬ä¸å­˜åœ¨: {auto_commit_script}")

            except Exception as e:
                warn(f"âš ï¸  å†™å…¥ä»“åº“å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

            # v7.2+: å‘é€æ‰«ææ‘˜è¦åˆ°Telegramï¼ˆå¦‚æœæœ‰ä¿¡å·ä¸”é…ç½®å¯ç”¨ï¼‰
            try:
                import os
                import json
                signals_found = summary_data.get('scan_info', {}).get('signals_found', 0)

                # åªåœ¨æœ‰ä¿¡å·æ—¶å‘é€ç”µæŠ¥é€šçŸ¥
                if signals_found > 0:
                    # åŠ è½½Telegramé…ç½®
                    config_file = Path(__file__).parent.parent.parent / 'config' / 'telegram.json'
                    if config_file.exists():
                        with open(config_file, 'r') as f:
                            telegram_config = json.load(f)

                        bot_token = telegram_config.get('bot_token', '').strip()
                        chat_id = telegram_config.get('chat_id', '').strip()
                        enabled = telegram_config.get('enabled', False)
                        send_scan_summary = telegram_config.get('send_scan_summary', False)  # é»˜è®¤falseï¼Œä¸å‘é€æ‰«ææ‘˜è¦

                        if enabled and bot_token and chat_id and send_scan_summary:
                            # ç”Ÿæˆç®€çŸ­çš„ç”µæŠ¥æ¶ˆæ¯
                            timestamp = datetime.now(TZ_UTC).strftime('%Y-%m-%d %H:%M:%S UTC')
                            total_symbols = summary_data.get('scan_info', {}).get('total_symbols', 0)

                            # è·å–ä¿¡å·åˆ—è¡¨ï¼ˆæ˜¾ç¤ºæ‰€æœ‰ä¿¡å·ï¼‰
                            signals_list = summary_data.get('signals', [])

                            # å¦‚æœä¿¡å·æ•°é‡<=10ï¼Œå…¨éƒ¨æ˜¾ç¤º
                            # å¦‚æœ>10ï¼Œæ˜¾ç¤ºå‰10ä¸ªï¼Œå¹¶æ³¨æ˜è¿˜æœ‰å¤šå°‘ä¸ª
                            if len(signals_list) <= 10:
                                signal_text = '\n'.join([
                                    f"  â€¢ {s['symbol']}: Edge={s['edge']:.2f}, Conf={s['confidence']:.0f}, Prime={s['prime_strength']:.0f}"
                                    for s in signals_list
                                ])
                            else:
                                signal_text = '\n'.join([
                                    f"  â€¢ {s['symbol']}: Edge={s['edge']:.2f}, Conf={s['confidence']:.0f}, Prime={s['prime_strength']:.0f}"
                                    for s in signals_list[:10]
                                ])
                                signal_text += f"\n  ... è¿˜æœ‰{len(signals_list) - 10}ä¸ªä¿¡å·"

                            message = f"""ğŸ“Š <b>æ‰«æå®Œæˆ</b>

ğŸ• æ—¶é—´: {timestamp}
ğŸ“ˆ æ‰«æ: {total_symbols} ä¸ªå¸ç§
âœ… ä¿¡å·: {signals_found} ä¸ª

ğŸ¯ <b>Primeä¿¡å·</b>:
{signal_text}

ğŸ“ å®Œæ•´æŠ¥å‘Š: reports/latest/scan_summary.json"""

                            # å‘é€åˆ°Telegram
                            success = stats.send_to_telegram(message, bot_token, chat_id)
                            if success:
                                log("âœ… æ‰«ææ‘˜è¦å·²å‘é€åˆ°Telegram")
                            else:
                                warn("âš ï¸  å‘é€Telegramå¤±è´¥")
                        else:
                            if not send_scan_summary:
                                log("â„¹ï¸  æ‰«ææ‘˜è¦å·²ç¦ç”¨ï¼ˆsend_scan_summary=falseï¼‰ï¼Œä»…å‘é€äº¤æ˜“ä¿¡å·")
                            else:
                                log("â„¹ï¸  Telegramæœªå¯ç”¨æˆ–æœªé…ç½®")
                    else:
                        log("â„¹ï¸  æœªæ‰¾åˆ°Telegramé…ç½®æ–‡ä»¶")
                else:
                    log("â„¹ï¸  æ— ä¿¡å·ï¼Œè·³è¿‡Telegramé€šçŸ¥")
            except Exception as e:
                warn(f"âš ï¸  å‘é€Telegramæ‘˜è¦å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

            log("âœ… ç»Ÿè®¡åˆ†æå·²å®Œæˆå¹¶å†™å…¥ä»“åº“: reports/latest/")

        except Exception as e:
            warn(f"âš ï¸  ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå¤±è´¥: {e}")

        return {
            'results': results,
            'total_symbols': len(symbols),
            'signals_found': len(results),
            'skipped': skipped,
            'errors': errors,
            'elapsed_seconds': round(scan_elapsed, 2),
            'symbols_per_second': round(len(symbols) / scan_elapsed, 2),
            'api_calls': 0,  # âœ… 0æ¬¡APIè°ƒç”¨
            'cache_stats': cache_stats
        }

    async def close(self):
        """å…³é—­æ‰«æå™¨"""
        if self.client:
            await self.client.close()

        log("âœ… ä¼˜åŒ–æ‰¹é‡æ‰«æå™¨å·²å…³é—­")


# ============ ä¾¿æ·å‡½æ•° ============

async def run_optimized_scan(
    min_score: int = 70,
    max_symbols: Optional[int] = None
):
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œä¼˜åŒ–æ‰¹é‡æ‰«æ

    Args:
        min_score: æœ€ä½ä¿¡å·åˆ†æ•°
        max_symbols: æœ€å¤§æ‰«ææ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰

    ä½¿ç”¨:
    ```python
    import asyncio
    from ats_core.pipeline.batch_scan_optimized import run_optimized_scan

    # å®Œæ•´æ‰«æ
    asyncio.run(run_optimized_scan(min_score=75))

    # æµ‹è¯•æ‰«æï¼ˆä»…å‰20ä¸ªï¼‰
    asyncio.run(run_optimized_scan(min_score=70, max_symbols=20))
    ```

    æ€§èƒ½:
    - é¦–æ¬¡è¿è¡Œï¼šçº¦2åˆ†é’Ÿï¼ˆé¢„çƒ­ï¼‰
    - åç»­è¿è¡Œï¼šçº¦5ç§’ï¼ˆ100ä¸ªå¸ç§ï¼‰
    """
    scanner = OptimizedBatchScanner()

    try:
        # åˆå§‹åŒ–ï¼ˆä»…é¦–æ¬¡éœ€è¦ï¼Œçº¦2åˆ†é’Ÿï¼‰
        await scanner.initialize()

        # æ‰«æï¼ˆåç»­æ¯æ¬¡çº¦5ç§’ï¼‰
        results = await scanner.scan(
            min_score=min_score,
            max_symbols=max_symbols
        )

        # æ‰“å°ä¿¡å·
        if results['signals_found'] > 0:
            log("\n" + "=" * 60)
            log(f"ğŸ“Š å‘ç° {results['signals_found']} ä¸ªé«˜è´¨é‡ä¿¡å·")
            log("=" * 60)

            for r in results['results']:
                symbol = r.get('symbol', 'UNKNOWN')
                weighted_score = r.get('weighted_score', 0)
                side = 'LONG' if weighted_score > 0 else 'SHORT'
                confidence = r.get('confidence', 0)
                prime_strength = r.get('publish', {}).get('prime_strength', 0)

                log(f"   {symbol} {side}: "
                    f"Primeå¼ºåº¦={prime_strength}, "
                    f"ç½®ä¿¡åº¦={confidence:.0f}")

        return results

    finally:
        await scanner.close()


# ============ æ€§èƒ½å¯¹æ¯”æµ‹è¯• ============

async def benchmark_comparison(test_symbols: int = 20):
    """
    æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼ˆå½“å‰REST vs WebSocketç¼“å­˜ï¼‰

    Args:
        test_symbols: æµ‹è¯•å¸ç§æ•°é‡

    å¯¹æ¯”å†…å®¹:
    1. å½“å‰RESTæ–¹æ¡ˆï¼ˆæ¯æ¬¡è·å–Kçº¿ï¼‰
    2. WebSocketç¼“å­˜æ–¹æ¡ˆï¼ˆä»ç¼“å­˜è¯»å–ï¼‰
    """
    log("\n" + "=" * 60)
    log("ğŸ“Š æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    log("=" * 60)
    log(f"   æµ‹è¯•å¸ç§æ•°: {test_symbols}")
    log("=" * 60)

    # 1. æµ‹è¯•WebSocketç¼“å­˜æ–¹æ¡ˆ
    log("\n1ï¸âƒ£  æµ‹è¯•WebSocketç¼“å­˜æ–¹æ¡ˆ...")
    ws_start = time.time()

    scanner = OptimizedBatchScanner()
    await scanner.initialize()
    ws_results = await scanner.scan(max_symbols=test_symbols)

    ws_elapsed = time.time() - ws_start
    await scanner.close()

    # 2. æµ‹è¯•å½“å‰RESTæ–¹æ¡ˆï¼ˆæ¨¡æ‹Ÿï¼‰
    log("\n2ï¸âƒ£  æµ‹è¯•å½“å‰RESTæ–¹æ¡ˆï¼ˆæ¨¡æ‹Ÿï¼‰...")
    from ats_core.pipeline.analyze_symbol import analyze_symbol
    from ats_core.pools.pool_manager import get_pool_manager

    rest_start = time.time()

    manager = get_pool_manager(
        elite_cache_hours=24,
        overlay_cache_hours=1,
        verbose=False
    )
    symbols, _ = manager.get_merged_universe()
    symbols = symbols[:test_symbols]

    rest_results = []
    for symbol in symbols:
        try:
            result = analyze_symbol(symbol)
            prime_strength = result.get('publish', {}).get('prime_strength', 0)
            if prime_strength >= 70:
                rest_results.append(result)
        except Exception:
            pass

    rest_elapsed = time.time() - rest_start

    # 3. å¯¹æ¯”ç»“æœ
    log("\n" + "=" * 60)
    log("ğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ")
    log("=" * 60)

    log(f"\nå½“å‰RESTæ–¹æ¡ˆ:")
    log(f"   è€—æ—¶: {rest_elapsed:.1f}ç§’")
    log(f"   é€Ÿåº¦: {test_symbols/rest_elapsed:.1f} å¸ç§/ç§’")
    log(f"   ä¿¡å·æ•°: {len(rest_results)}")

    log(f"\nWebSocketç¼“å­˜æ–¹æ¡ˆ:")
    log(f"   è€—æ—¶: {ws_elapsed:.1f}ç§’ï¼ˆåŒ…å«é¢„çƒ­ï¼‰")
    log(f"   é€Ÿåº¦: {test_symbols/ws_elapsed:.1f} å¸ç§/ç§’")
    log(f"   ä¿¡å·æ•°: {ws_results['signals_found']}")

    # è®¡ç®—æ‰«æéƒ¨åˆ†çš„é€Ÿåº¦ï¼ˆæ’é™¤é¢„çƒ­ï¼‰
    scan_only_time = ws_results['elapsed_seconds']

    log(f"\nWebSocketç¼“å­˜æ–¹æ¡ˆï¼ˆä»…æ‰«æéƒ¨åˆ†ï¼‰:")
    log(f"   è€—æ—¶: {scan_only_time:.1f}ç§’")
    log(f"   é€Ÿåº¦: {test_symbols/scan_only_time:.1f} å¸ç§/ç§’ ğŸš€")

    speedup = rest_elapsed / scan_only_time

    log(f"\nâš¡ æ€§èƒ½æå‡:")
    log(f"   é€Ÿåº¦æå‡: {speedup:.1f}x")
    log(f"   APIè°ƒç”¨å‡å°‘: 100% (400æ¬¡ â†’ 0æ¬¡)")

    log("=" * 60)


if __name__ == "__main__":
    # è¿è¡Œä¼˜åŒ–æ‰«æï¼ˆæ‰«æå…¨éƒ¨å¸ç§ï¼‰
    asyncio.run(run_optimized_scan(min_score=65))

    # æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼ˆéœ€è¦pool_manageræ¨¡å—ï¼‰
    # asyncio.run(benchmark_comparison(test_symbols=20))
