import os, time, json
from ats_core.cfg import CFG
from ats_core.pools.pool_manager import get_pool_manager
from ats_core.pipeline.analyze_symbol import analyze_symbol
from ats_core.outputs.telegram_fmt import render_trade, render_watch
from ats_core.outputs.publisher import telegram_send
from ats_core.logging import log, warn

DATA = os.path.join(os.path.dirname(os.path.dirname(__file__)), "..", "data", "reports")
os.makedirs(DATA, exist_ok=True)

def batch_run():
    """
    æ‰¹é‡æ‰«æï¼ˆä¼˜åŒ–ç‰ˆ - ä½¿ç”¨æ™ºèƒ½ç¼“å­˜æ± ï¼‰

    æ–°æ¶æ„:
    - Elite Pool (24hç¼“å­˜): ç¨³å®šå¸ç§
    - Overlay Pool (1hç¼“å­˜): å¼‚å¸¸å¸ç§ + æ–°å¸
    - APIè°ƒç”¨é‡: -90%
    - æ‰«æé€Ÿåº¦: +10å€
    """
    # ä½¿ç”¨æ–°çš„æ± ç®¡ç†å™¨ï¼ˆè‡ªåŠ¨å¤„ç†ç¼“å­˜ï¼‰
    manager = get_pool_manager(
        elite_cache_hours=24,
        overlay_cache_hours=1,
        verbose=True
    )

    # è·å–åˆå¹¶åçš„å€™é€‰æ± ï¼ˆè‡ªåŠ¨æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæœŸï¼‰
    syms, metadata = manager.get_merged_universe()

    log(f"ğŸš€ å¼€å§‹æ‰¹é‡æ‰«æ: {len(syms)} ä¸ªå¸ç§")
    log(f"   Elite Pool: {metadata['elite_count']} ä¸ª (ç¼“å­˜{'æœ‰æ•ˆ' if metadata['elite_cache_valid'] else 'é‡å»º'})")
    log(f"   Overlay Pool: {metadata['overlay_count']} ä¸ª (ç¼“å­˜{'æœ‰æ•ˆ' if metadata['overlay_cache_valid'] else 'é‡å»º'})")
    log(f"   APIä¼˜åŒ–: ~90% è°ƒç”¨é‡é™ä½ ğŸš€")
    for sym in syms:
        try:
            r = analyze_symbol(sym)
            pub = r.get("publish") or {}
            html = render_trade(r) if pub.get("prime") else render_watch(r)
            telegram_send(html)
            # save report
            ts=time.strftime("%Y%m%dT%H%MZ", time.gmtime())
            with open(os.path.join(DATA, f"scan_{sym}_{ts}.md"),"w",encoding="utf-8") as f:
                f.write(html)
        except Exception as e:
            warn("batch %s error: %s", sym, e)
        time.sleep(CFG.get("limits","per_symbol_delay_ms", default=600)/1000.0)