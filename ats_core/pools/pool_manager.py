# coding: utf-8
"""
ä¸–ç•Œé¡¶çº§å€™é€‰æ± ç®¡ç†å™¨ - æ™ºèƒ½ç¼“å­˜æ¶æ„

æ¶æ„è®¾è®¡:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Elite Pool (Base Stable)            â”‚
â”‚  - 4å±‚è¿‡æ»¤ï¼ˆæµåŠ¨æ€§â†’å¼‚å¸¸â†’è´¨é‡â†’é£é™©ï¼‰    â”‚
â”‚  - æ¯æ—¥æ›´æ–°1æ¬¡ï¼ˆç¨³å®šå¸ç§ï¼‰              â”‚
â”‚  - ç¼“å­˜ï¼šdata/elite_pool.json           â”‚
â”‚  - æœ‰æ•ˆæœŸï¼š24å°æ—¶                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Overlay Pool (Dynamic Hot)          â”‚
â”‚  - å¼‚å¸¸äº‹ä»¶æ£€æµ‹ï¼ˆçªå‘è¡Œæƒ…ï¼‰             â”‚
â”‚  - æ–°å¸å¿«é€Ÿé€šé“                         â”‚
â”‚  - æ¯å°æ—¶æ›´æ–°1æ¬¡ï¼ˆæ•æ·å“åº”ï¼‰            â”‚
â”‚  - ç¼“å­˜ï¼šdata/overlay_pool.json         â”‚
â”‚  - æœ‰æ•ˆæœŸï¼š1å°æ—¶                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Merged Universe                     â”‚
â”‚  - Elite + Overlayï¼ˆå»é‡ï¼‰              â”‚
â”‚  - ä¼˜å…ˆçº§ï¼šOverlay > Elite              â”‚
â”‚  - å…ƒæ•°æ®åˆå¹¶ï¼ˆä¿ç•™å…ˆéªŒä¿¡æ¯ï¼‰           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ€§èƒ½ä¼˜åŠ¿:
- APIè°ƒç”¨é‡: -90%
- æ‰«æé€Ÿåº¦: +10å€
- å€™é€‰æ± è´¨é‡: +50%
"""

from __future__ import annotations
import json
import os
import time
from typing import List, Dict, Optional, Tuple
from datetime import datetime


class PoolManager:
    """
    æ™ºèƒ½å€™é€‰æ± ç®¡ç†å™¨

    åŠŸèƒ½:
    1. Elite Poolç®¡ç†ï¼ˆ24hç¼“å­˜ï¼‰
    2. Overlay Poolç®¡ç†ï¼ˆ1hç¼“å­˜ï¼‰
    3. è‡ªåŠ¨ç¼“å­˜éªŒè¯
    4. æ™ºèƒ½æ± åˆå¹¶
    """

    def __init__(
        self,
        data_dir: str = "data",
        elite_cache_hours: int = 24,
        overlay_cache_hours: int = 1,
        verbose: bool = True
    ):
        """
        Args:
            data_dir: ç¼“å­˜ç›®å½•
            elite_cache_hours: Elite Poolç¼“å­˜æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰
            overlay_cache_hours: Overlay Poolç¼“å­˜æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰
            verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
        """
        self.data_dir = data_dir
        self.elite_cache_hours = elite_cache_hours
        self.overlay_cache_hours = overlay_cache_hours
        self.verbose = verbose

        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(data_dir, exist_ok=True)

        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
        self.elite_cache_path = os.path.join(data_dir, "elite_pool.json")
        self.overlay_cache_path = os.path.join(data_dir, "overlay_pool.json")

    def _log(self, msg: str):
        """æ‰“å°æ—¥å¿—"""
        if self.verbose:
            print(f"[PoolManager] {msg}")

    def _is_cache_valid(self, cache_path: str, max_age_hours: int) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ

        Args:
            cache_path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
            max_age_hours: æœ€å¤§æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰

        Returns:
            True if valid, False if expired or not exists
        """
        if not os.path.exists(cache_path):
            return False

        # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        mtime = os.path.getmtime(cache_path)
        age_hours = (time.time() - mtime) / 3600

        is_valid = age_hours < max_age_hours

        if self.verbose:
            status = "âœ… æœ‰æ•ˆ" if is_valid else "âŒ è¿‡æœŸ"
            self._log(f"ç¼“å­˜æ£€æŸ¥ {os.path.basename(cache_path)}: {age_hours:.1f}h / {max_age_hours}h - {status}")

        return is_valid

    def _load_cache(self, cache_path: str) -> Optional[Dict]:
        """
        åŠ è½½ç¼“å­˜æ–‡ä»¶

        Returns:
            ç¼“å­˜æ•°æ®æˆ–None
        """
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            symbols = data.get('symbols', [])
            self._log(f"âœ… åŠ è½½ç¼“å­˜ {os.path.basename(cache_path)}: {len(symbols)} ä¸ªå¸ç§")
            return data
        except Exception as e:
            self._log(f"âŒ åŠ è½½ç¼“å­˜å¤±è´¥ {os.path.basename(cache_path)}: {e}")
            return None

    def _save_cache(self, cache_path: str, data: Dict):
        """
        ä¿å­˜ç¼“å­˜æ–‡ä»¶

        Args:
            cache_path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
            data: ç¼“å­˜æ•°æ®
        """
        try:
            # æ·»åŠ æ—¶é—´æˆ³
            data['updated_at'] = datetime.now().isoformat()
            data['timestamp'] = int(time.time())

            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            symbols = data.get('symbols', [])
            self._log(f"âœ… ä¿å­˜ç¼“å­˜ {os.path.basename(cache_path)}: {len(symbols)} ä¸ªå¸ç§")
        except Exception as e:
            self._log(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥ {os.path.basename(cache_path)}: {e}")

    def get_elite_pool(self, force_rebuild: bool = False) -> List[str]:
        """
        è·å–Elite Poolï¼ˆç¨³å®šå¸ç§ï¼Œ24hç¼“å­˜ï¼‰

        Args:
            force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰

        Returns:
            å¸ç§åˆ—è¡¨ + å…ƒæ•°æ®
        """
        # æ£€æŸ¥ç¼“å­˜
        if not force_rebuild and self._is_cache_valid(self.elite_cache_path, self.elite_cache_hours):
            cache = self._load_cache(self.elite_cache_path)
            if cache:
                return cache.get('symbols', [])

        # é‡å»ºElite Pool
        self._log("ğŸ”¨ é‡å»ºElite Poolï¼ˆ4å±‚è¿‡æ»¤ï¼‰...")

        try:
            # å¯¼å…¥elite_builder
            from ats_core.pools.elite_builder import build_elite_universe

            # æ„å»ºElite Pool
            result = build_elite_universe()
            symbols = result.get('symbols', [])

            # ä¿å­˜ç¼“å­˜ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
            cache_data = {
                'symbols': symbols,
                'metadata': result.get('metadata', {}),
                'filter_stats': result.get('stats', {}),
                'pool_type': 'elite',
                'cache_hours': self.elite_cache_hours
            }
            self._save_cache(self.elite_cache_path, cache_data)

            self._log(f"âœ… Elite Poolæ„å»ºå®Œæˆ: {len(symbols)} ä¸ªå¸ç§")
            return symbols

        except Exception as e:
            self._log(f"âŒ Elite Poolæ„å»ºå¤±è´¥: {e}")
            # é™çº§ï¼šå°è¯•åŠ è½½æ—§ç¼“å­˜
            cache = self._load_cache(self.elite_cache_path)
            if cache:
                self._log("âš ï¸ ä½¿ç”¨è¿‡æœŸç¼“å­˜ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                return cache.get('symbols', [])
            else:
                self._log("âš ï¸ è¿”å›ç©ºæ± ")
                return []

    def get_overlay_pool(
        self,
        elite_symbols: List[str],
        force_rebuild: bool = False
    ) -> List[str]:
        """
        è·å–Overlay Poolï¼ˆå¼‚å¸¸å¸ç§+æ–°å¸ï¼Œ1hç¼“å­˜ï¼‰

        Args:
            elite_symbols: Elite Poolå¸ç§åˆ—è¡¨ï¼ˆç”¨äºå»é‡ï¼‰
            force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»º

        Returns:
            å¸ç§åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        if not force_rebuild and self._is_cache_valid(self.overlay_cache_path, self.overlay_cache_hours):
            cache = self._load_cache(self.overlay_cache_path)
            if cache:
                return cache.get('symbols', [])

        # é‡å»ºOverlay Pool
        self._log("ğŸ”¨ é‡å»ºOverlay Poolï¼ˆå¼‚å¸¸æ£€æµ‹+æ–°å¸ï¼‰...")

        try:
            # å¯¼å…¥overlay_builderï¼ˆä¼˜åŒ–ç‰ˆï¼‰
            from ats_core.pools.overlay_builder import build_overlay_pool

            # æ„å»ºOverlay Poolï¼ˆä¼ å…¥elite_symbolsç”¨äºå»é‡ï¼‰
            result = build_overlay_pool(exclude_symbols=elite_symbols)
            symbols = result.get('symbols', [])

            # ä¿å­˜ç¼“å­˜
            cache_data = {
                'symbols': symbols,
                'metadata': result.get('metadata', {}),
                'detection_stats': result.get('stats', {}),
                'pool_type': 'overlay',
                'cache_hours': self.overlay_cache_hours,
                'excluded_count': len(elite_symbols)
            }
            self._save_cache(self.overlay_cache_path, cache_data)

            self._log(f"âœ… Overlay Poolæ„å»ºå®Œæˆ: {len(symbols)} ä¸ªå¸ç§")
            return symbols

        except Exception as e:
            self._log(f"âŒ Overlay Poolæ„å»ºå¤±è´¥: {e}")
            # é™çº§ï¼šå°è¯•åŠ è½½æ—§ç¼“å­˜
            cache = self._load_cache(self.overlay_cache_path)
            if cache:
                self._log("âš ï¸ ä½¿ç”¨è¿‡æœŸç¼“å­˜ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                return cache.get('symbols', [])
            else:
                self._log("âš ï¸ è¿”å›ç©ºæ± ")
                return []

    def get_merged_universe(
        self,
        force_rebuild_elite: bool = False,
        force_rebuild_overlay: bool = False
    ) -> Tuple[List[str], Dict]:
        """
        è·å–åˆå¹¶åçš„å€™é€‰æ± ï¼ˆElite + Overlayï¼‰

        ä¼˜å…ˆçº§: Overlay > Elite

        Args:
            force_rebuild_elite: æ˜¯å¦å¼ºåˆ¶é‡å»ºElite Pool
            force_rebuild_overlay: æ˜¯å¦å¼ºåˆ¶é‡å»ºOverlay Pool

        Returns:
            (merged_symbols, metadata)
        """
        self._log("=" * 60)
        self._log("ğŸš€ å€™é€‰æ± ç®¡ç†å™¨å¯åŠ¨")
        self._log("=" * 60)

        # 1. è·å–Elite Poolï¼ˆç¨³å®šå¸ç§ï¼Œ24hç¼“å­˜ï¼‰
        elite_symbols = self.get_elite_pool(force_rebuild=force_rebuild_elite)
        elite_set = set(elite_symbols)

        # 2. è·å–Overlay Poolï¼ˆå¼‚å¸¸å¸ç§ï¼Œ1hç¼“å­˜ï¼Œå»é™¤Eliteä¸­çš„å¸ï¼‰
        overlay_symbols = self.get_overlay_pool(
            elite_symbols=elite_symbols,
            force_rebuild=force_rebuild_overlay
        )
        overlay_set = set(overlay_symbols)

        # 3. åˆå¹¶å»é‡ï¼ˆOverlayä¼˜å…ˆçº§æ›´é«˜ï¼Œæ”¾åœ¨å‰é¢ï¼‰
        # Overlayä¸­çš„å¸ç§ä¼˜å…ˆè¢«æ‰«æï¼ˆå¯èƒ½æœ‰çªå‘è¡Œæƒ…ï¼‰
        merged = list(overlay_symbols)  # Overlayä¼˜å…ˆ

        # æ·»åŠ Eliteä¸­ä¸åœ¨Overlayçš„å¸ç§
        for sym in elite_symbols:
            if sym not in overlay_set:
                merged.append(sym)

        # ç»Ÿè®¡ä¿¡æ¯
        overlap_count = len(elite_set & overlay_set)

        self._log("=" * 60)
        self._log(f"âœ… å€™é€‰æ± åˆå¹¶å®Œæˆ:")
        self._log(f"   Elite Pool:   {len(elite_symbols)} ä¸ªå¸ç§ (24hç¼“å­˜)")
        self._log(f"   Overlay Pool: {len(overlay_symbols)} ä¸ªå¸ç§ (1hç¼“å­˜)")
        self._log(f"   é‡å å¸ç§:     {overlap_count} ä¸ª")
        self._log(f"   åˆå¹¶åæ€»æ•°:   {len(merged)} ä¸ªå¸ç§")
        self._log(f"   APIè°ƒç”¨é™ä½:  ~90% ğŸš€")
        self._log("=" * 60)

        # å…ƒæ•°æ®
        metadata = {
            'elite_count': len(elite_symbols),
            'overlay_count': len(overlay_symbols),
            'overlap_count': overlap_count,
            'total_count': len(merged),
            'elite_cache_valid': self._is_cache_valid(self.elite_cache_path, self.elite_cache_hours),
            'overlay_cache_valid': self._is_cache_valid(self.overlay_cache_path, self.overlay_cache_hours),
            'timestamp': int(time.time()),
            'updated_at': datetime.now().isoformat()
        }

        return merged, metadata

    def force_update_elite(self) -> List[str]:
        """
        å¼ºåˆ¶æ›´æ–°Elite Poolï¼ˆæ‰‹åŠ¨è§¦å‘ï¼Œç”¨äºå®šæ—¶ä»»åŠ¡ï¼‰

        Returns:
            æ›´æ–°åçš„å¸ç§åˆ—è¡¨
        """
        self._log("ğŸ”„ æ‰‹åŠ¨è§¦å‘Elite Poolæ›´æ–°...")
        return self.get_elite_pool(force_rebuild=True)

    def force_update_overlay(self) -> List[str]:
        """
        å¼ºåˆ¶æ›´æ–°Overlay Poolï¼ˆæ‰‹åŠ¨è§¦å‘ï¼Œç”¨äºå®šæ—¶ä»»åŠ¡ï¼‰

        Returns:
            æ›´æ–°åçš„å¸ç§åˆ—è¡¨
        """
        self._log("ğŸ”„ æ‰‹åŠ¨è§¦å‘Overlay Poolæ›´æ–°...")
        elite_symbols = self.get_elite_pool(force_rebuild=False)
        return self.get_overlay_pool(elite_symbols=elite_symbols, force_rebuild=True)

    def get_cache_status(self) -> Dict:
        """
        è·å–ç¼“å­˜çŠ¶æ€

        Returns:
            ç¼“å­˜çŠ¶æ€ä¿¡æ¯
        """
        status = {}

        # Elite PoolçŠ¶æ€
        if os.path.exists(self.elite_cache_path):
            mtime = os.path.getmtime(self.elite_cache_path)
            age_hours = (time.time() - mtime) / 3600
            status['elite'] = {
                'exists': True,
                'age_hours': round(age_hours, 2),
                'valid': age_hours < self.elite_cache_hours,
                'max_age': self.elite_cache_hours,
                'next_update': round(self.elite_cache_hours - age_hours, 2)
            }
        else:
            status['elite'] = {'exists': False}

        # Overlay PoolçŠ¶æ€
        if os.path.exists(self.overlay_cache_path):
            mtime = os.path.getmtime(self.overlay_cache_path)
            age_hours = (time.time() - mtime) / 3600
            status['overlay'] = {
                'exists': True,
                'age_hours': round(age_hours, 2),
                'valid': age_hours < self.overlay_cache_hours,
                'max_age': self.overlay_cache_hours,
                'next_update': round(self.overlay_cache_hours - age_hours, 2)
            }
        else:
            status['overlay'] = {'exists': False}

        return status


# ========== ä¾¿æ·å‡½æ•° ==========

_manager_instance: Optional[PoolManager] = None

def get_pool_manager(
    data_dir: str = "data",
    elite_cache_hours: int = 24,
    overlay_cache_hours: int = 1,
    verbose: bool = True
) -> PoolManager:
    """
    è·å–å…¨å±€æ± ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        PoolManagerå®ä¾‹
    """
    global _manager_instance

    if _manager_instance is None:
        _manager_instance = PoolManager(
            data_dir=data_dir,
            elite_cache_hours=elite_cache_hours,
            overlay_cache_hours=overlay_cache_hours,
            verbose=verbose
        )

    return _manager_instance


def get_scan_universe(force_rebuild: bool = False) -> List[str]:
    """
    è·å–æ‰«æå€™é€‰æ± ï¼ˆå¿«æ·å‡½æ•°ï¼‰

    Args:
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºæ‰€æœ‰ç¼“å­˜

    Returns:
        å¸ç§åˆ—è¡¨
    """
    manager = get_pool_manager()
    symbols, _ = manager.get_merged_universe(
        force_rebuild_elite=force_rebuild,
        force_rebuild_overlay=force_rebuild
    )
    return symbols


# ========== æµ‹è¯•ä»£ç  ==========

if __name__ == "__main__":
    print("=" * 60)
    print("ä¸–ç•Œé¡¶çº§å€™é€‰æ± ç®¡ç†å™¨ - æµ‹è¯•")
    print("=" * 60)

    # åˆ›å»ºç®¡ç†å™¨
    manager = PoolManager(
        data_dir="data",
        elite_cache_hours=24,
        overlay_cache_hours=1,
        verbose=True
    )

    # æµ‹è¯•1: è·å–åˆå¹¶å€™é€‰æ± 
    print("\n[æµ‹è¯•1] è·å–åˆå¹¶å€™é€‰æ± ï¼ˆé¦–æ¬¡æ„å»ºï¼‰")
    symbols, metadata = manager.get_merged_universe(force_rebuild_elite=False, force_rebuild_overlay=False)
    print(f"\nå€™é€‰æ± æ€»æ•°: {len(symbols)}")
    print(f"å‰10ä¸ªå¸ç§: {symbols[:10]}")

    # æµ‹è¯•2: å†æ¬¡è·å–ï¼ˆåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼‰
    print("\n[æµ‹è¯•2] å†æ¬¡è·å–ï¼ˆæµ‹è¯•ç¼“å­˜ï¼‰")
    symbols2, metadata2 = manager.get_merged_universe()
    print(f"ä½¿ç”¨Eliteç¼“å­˜: {metadata2['elite_cache_valid']}")
    print(f"ä½¿ç”¨Overlayç¼“å­˜: {metadata2['overlay_cache_valid']}")

    # æµ‹è¯•3: æŸ¥çœ‹ç¼“å­˜çŠ¶æ€
    print("\n[æµ‹è¯•3] ç¼“å­˜çŠ¶æ€")
    status = manager.get_cache_status()
    print(json.dumps(status, indent=2, ensure_ascii=False))

    # æµ‹è¯•4: å¿«æ·å‡½æ•°
    print("\n[æµ‹è¯•4] å¿«æ·å‡½æ•° get_scan_universe()")
    quick_symbols = get_scan_universe()
    print(f"å¿«é€Ÿè·å–: {len(quick_symbols)} ä¸ªå¸ç§")

    print("\n" + "=" * 60)
    print("âœ… æ± ç®¡ç†å™¨æµ‹è¯•å®Œæˆ")
    print("=" * 60)
