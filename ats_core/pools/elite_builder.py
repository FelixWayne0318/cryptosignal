# coding: utf-8
from __future__ import annotations

"""
ä¸–ç•Œé¡¶çº§å€™é€‰æ± æ„å»ºå™¨ï¼ˆElite Universe Builderï¼‰

æ ¸å¿ƒå“²å­¦ï¼š
1. æ–¹å‘ä¸­æ€§ï¼šå¤šç©ºå¯¹ç§°ï¼Œä¸é¢„åˆ¤æ–¹å‘
2. ä¿¡æ¯ç†µæœ€å¤§åŒ–ï¼šæ•æ‰æ‰€æœ‰æœ‰æ•ˆå¼‚å¸¸
3. å¾®è§‚ç»“æ„ä¼˜å…ˆï¼šè®¢å•æµ > ä»·æ ¼
4. å› å­ç‹¬ç«‹æ€§ï¼šé¿å…å†—ä½™ä¿¡å·
5. åŠ¨æ€é˜ˆå€¼ï¼šå¸‚åœºçŠ¶æ€è‡ªé€‚åº”

å‚è€ƒï¼šRenaissance Technologies / Two Sigma / Citadel æ€è·¯
"""

import os
import json
import math
from typing import List, Dict, Any, Tuple
from statistics import median, stdev
from ats_core.cfg import CFG
from ats_core.sources.tickers import all_24h
from ats_core.sources.binance import get_klines, get_open_interest_hist
from ats_core.features.cvd import cvd_mix_with_oi_price
from ats_core.logging import log

DATA = os.path.join(os.path.dirname(os.path.dirname(__file__)), "..", "data")
os.makedirs(DATA, exist_ok=True)

# ============ å·¥å…·å‡½æ•° ============

def _to_f(x) -> float:
    try:
        return float(x)
    except:
        return 0.0

def _ema(seq: List[float], n: int) -> List[float]:
    if not seq or n <= 1:
        return [_to_f(v) for v in seq]
    k = 2.0 / (n + 1.0)
    e = None
    out = []
    for v in seq:
        v = _to_f(v)
        e = v if e is None else (e + k * (v - e))
        out.append(e)
    return out

def _robust_zscore(values: List[float]) -> float:
    """é²æ£’Zåˆ†æ•°ï¼ˆç”¨MADä»£æ›¿æ ‡å‡†å·®ï¼ŒæŠ—å¼‚å¸¸å€¼ï¼‰"""
    if len(values) < 3:
        return 0.0
    med = median(values)
    mad = median([abs(v - med) for v in values])
    if mad < 1e-12:
        return 0.0
    return (values[-1] - med) / (1.4826 * mad)

def _percentile_rank(value: float, values: List[float]) -> float:
    """ç™¾åˆ†ä½æ’åï¼ˆ0-100ï¼‰"""
    if len(values) == 0:
        return 50.0
    sorted_vals = sorted(values)
    rank = sum(1 for v in sorted_vals if v < value)
    return 100.0 * rank / len(sorted_vals)

# ============ Layer 0: å®‡å®™è¿‡æ»¤ ============

def _layer0_universe_filter(tickers: List[Dict]) -> List[Dict]:
    """
    Layer 0: åŸºç¡€å®‡å®™è¿‡æ»¤
    ç›®æ ‡ï¼šæ’é™¤ä¸å¯äº¤æ˜“çš„åƒåœ¾å¸

    è¿‡æ»¤æ¡ä»¶ï¼š
    - USDTæ°¸ç»­åˆçº¦
    - éé»‘åå•
    """
    log("ğŸŒ [Layer 0] å®‡å®™è¿‡æ»¤...")
    blacklist = getattr(CFG, 'blacklist', []) or []

    universe = []
    for t in tickers:
        try:
            sym = t["symbol"]
            if not sym.endswith("USDT"):
                continue
            if sym in blacklist:
                continue
            universe.append(t)
        except:
            continue

    log(f"   âœ… {len(tickers)} â†’ {len(universe)} ä¸ªUSDTäº¤æ˜“å¯¹")
    return universe

# ============ Layer 1: æµåŠ¨æ€§ç­›é€‰ ============

def _layer1_liquidity_screen(universe: List[Dict], params: Dict) -> List[Dict]:
    """
    Layer 1: æµåŠ¨æ€§ç­›é€‰
    ç›®æ ‡ï¼šç¡®ä¿å¯æ‰§è¡Œæ€§ï¼ˆæ»‘ç‚¹å¯æ§ã€æ·±åº¦å……è¶³ï¼‰

    æ ¸å¿ƒæŒ‡æ ‡ï¼š
    1. æˆäº¤é¢ï¼ˆ24h Quote Volumeï¼‰
    2. æˆäº¤ç¬”æ•°ï¼ˆ24h Trades Countï¼‰
    3. ç‚¹å·®ä¼°è®¡ï¼ˆPrice Change Velocityï¼‰

    é¡¶çº§æ€ç»´ï¼šæµåŠ¨æ€§ä¸æ˜¯è¶Šé«˜è¶Šå¥½ï¼Œè€Œæ˜¯"è¶³å¤Ÿæ‰§è¡Œ + æœ‰æ³¢åŠ¨"
    """
    log("ğŸ’§ [Layer 1] æµåŠ¨æ€§ç­›é€‰...")

    min_quote = params.get("min_quote_volume", 5_000_000)  # 500ä¸‡USDT
    min_trades = params.get("min_trades_24h", 10_000)      # 1ä¸‡ç¬”

    liquid = []
    for t in universe:
        try:
            quote_vol = _to_f(t.get("quoteVolume", 0))
            trades = _to_f(t.get("count", 0))

            # æµåŠ¨æ€§è¯„åˆ†ï¼ˆ0-100ï¼‰
            vol_score = min(100, quote_vol / 50_000_000 * 100)  # 5000ä¸‡=100åˆ†
            trade_score = min(100, trades / 100_000 * 100)      # 10ä¸‡ç¬”=100åˆ†
            liquidity_score = 0.7 * vol_score + 0.3 * trade_score

            if quote_vol >= min_quote and trades >= min_trades:
                t["_liquidity_score"] = liquidity_score
                liquid.append(t)
        except:
            continue

    log(f"   âœ… {len(universe)} â†’ {len(liquid)} ä¸ªï¼ˆæµåŠ¨æ€§åˆæ ¼ï¼‰")
    return liquid

# ============ Layer 2: å¼‚å¸¸äº‹ä»¶æ£€æµ‹ ============

def _layer2_anomaly_detection(candidates: List[Dict], params: Dict) -> List[Dict]:
    """
    Layer 2: å¼‚å¸¸äº‹ä»¶æ£€æµ‹ï¼ˆæ–¹å‘ä¸­æ€§ï¼‰
    ç›®æ ‡ï¼šæ•æ‰å¸‚åœºå¾®è§‚ç»“æ„å¼‚å¸¸ï¼ˆä¸ç®¡æ¶¨è·Œï¼‰

    æ£€æµ‹6ä¸ªç‹¬ç«‹ç»´åº¦çš„å¼‚å¸¸ï¼š
    1. ä»·æ ¼å¼‚å¸¸ï¼ˆPrice Anomalyï¼‰- zåˆ†æ•°
    2. é‡èƒ½å¼‚å¸¸ï¼ˆVolume Surgeï¼‰- ç›¸å¯¹æ”¾å¤§
    3. æŒä»“å¼‚å¸¸ï¼ˆOI Jumpï¼‰- æ æ†æ¶Œå…¥
    4. ä»·-é‡èƒŒç¦»ï¼ˆPrice-Volume Divergenceï¼‰
    5. æ³¢åŠ¨ç‡çªå˜ï¼ˆVolatility Spikeï¼‰
    6. èµ„é‡‘æµå¼‚å¸¸ï¼ˆFund Flow Imbalanceï¼‰

    é¡¶çº§æ€ç»´ï¼šå¼‚å¸¸ = ä¿¡æ¯ï¼Œæ–¹å‘ç”±åç»­åˆ†æåˆ¤æ–­
    """
    log("ğŸ” [Layer 2] å¼‚å¸¸äº‹ä»¶æ£€æµ‹ï¼ˆ6ç»´ç‹¬ç«‹æ£€æµ‹ï¼‰...")

    anomalies = []
    processed = 0

    for idx, t in enumerate(candidates, 1):
        try:
            sym = t["symbol"]

            # æ˜¾ç¤ºè¿›åº¦
            if idx % 10 == 0 or idx == 1 or idx == len(candidates):
                log(f"   [{idx}/{len(candidates)}] {sym}...")

            # è·å–æ•°æ®ï¼ˆè½»é‡çº§ï¼Œåªè¦60æ ¹1h Kçº¿ï¼‰
            k1 = get_klines(sym, "1h", 60)
            if not k1 or len(k1) < 30:
                continue

            oi = get_open_interest_hist(sym, "1h", 60)

            # æå–ä»·æ ¼/é‡èƒ½æ•°æ®
            closes = [_to_f(r[4]) for r in k1]
            volumes = [_to_f(r[7]) for r in k1]  # quote volume
            oi_values = [_to_f(r[5]) for r in oi] if oi and len(oi) >= 30 else [0] * len(k1)

            # === 1. ä»·æ ¼å¼‚å¸¸æ£€æµ‹ ===
            # è®¡ç®—24hæ”¶ç›Šç‡åºåˆ—ï¼ˆç”¨14å¤©æ•°æ®ï¼‰
            returns_24h = []
            for i in range(24, min(len(closes), 14 * 24)):
                if closes[i - 24] > 0:
                    returns_24h.append(math.log(closes[i] / closes[i - 24]))

            price_z = _robust_zscore(returns_24h) if len(returns_24h) >= 20 else 0.0
            price_anomaly = abs(price_z)  # å¼‚å¸¸å¼ºåº¦ï¼ˆä¸çœ‹æ–¹å‘ï¼‰

            # === 2. é‡èƒ½å¼‚å¸¸æ£€æµ‹ ===
            v5 = sum(volumes[-5:]) / 5 if len(volumes) >= 5 else 0
            v20 = sum(volumes[-20:]) / 20 if len(volumes) >= 20 else 1
            volume_surge = (v5 / v20) if v20 > 0 else 1.0

            # === 3. æŒä»“å¼‚å¸¸æ£€æµ‹ ===
            if len(oi_values) >= 24 and oi_values[-24] > 0:
                oi_change_24h = (oi_values[-1] - oi_values[-24]) / oi_values[-24]
                oi_anomaly = abs(oi_change_24h) * 100  # è½¬ä¸ºç™¾åˆ†æ¯”
            else:
                oi_anomaly = 0.0

            # === 4. ä»·-é‡èƒŒç¦»æ£€æµ‹ ===
            # ä»·æ ¼å˜åŒ–æ–¹å‘ vs é‡èƒ½æ–¹å‘
            price_dir = 1 if closes[-1] > closes[-6] else -1
            vol_dir = 1 if v5 > v20 else -1
            pv_divergence = 1.0 if price_dir != vol_dir else 0.0  # èƒŒç¦»=1ï¼Œä¸€è‡´=0

            # === 5. æ³¢åŠ¨ç‡çªå˜æ£€æµ‹ ===
            # æœ€è¿‘5æ ¹vså‰20æ ¹çš„æ³¢åŠ¨ç‡æ¯”å€¼
            recent_vol = stdev(closes[-5:]) if len(closes) >= 5 else 0
            normal_vol = stdev(closes[-25:-5]) if len(closes) >= 25 else 1e-9
            volatility_spike = (recent_vol / normal_vol) if normal_vol > 1e-9 else 1.0

            # === 6. èµ„é‡‘æµå¼‚å¸¸æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆCVDï¼‰===
            # ç”¨ä¹°å–æˆäº¤é‡å·®å¼‚ä¼°ç®—
            try:
                taker_buy_quote = [_to_f(r[10]) for r in k1]  # takerBuyQuoteVolume
                taker_sell_quote = [volumes[i] - taker_buy_quote[i] for i in range(len(volumes))]

                # æœ€è¿‘6hçš„èµ„é‡‘å‡€æµå…¥
                flow_6h = sum(taker_buy_quote[-6:]) - sum(taker_sell_quote[-6:])
                total_6h = sum(volumes[-6:])
                flow_imbalance = abs(flow_6h / total_6h) if total_6h > 0 else 0.0
            except:
                flow_imbalance = 0.0

            # === ç»¼åˆå¼‚å¸¸è¯„åˆ†ï¼ˆ6ç»´åŠ æƒï¼‰===
            # æ¯ä¸ªç»´åº¦ç‹¬ç«‹å½’ä¸€åŒ–åˆ°0-100
            scores = {
                "price_anomaly": min(100, price_anomaly * 20),        # Z>5 = 100åˆ†
                "volume_surge": min(100, (volume_surge - 1) * 50),    # v5/v20=3 = 100åˆ†
                "oi_anomaly": min(100, oi_anomaly * 5),                # 20%OIå˜åŒ– = 100åˆ†
                "pv_divergence": pv_divergence * 30,                   # èƒŒç¦» = 30åˆ†
                "volatility_spike": min(100, (volatility_spike - 1) * 30),  # æ³¢åŠ¨ç‡3å€ = 60åˆ†
                "flow_imbalance": min(100, flow_imbalance * 200),      # 50%å¤±è¡¡ = 100åˆ†
            }

            # å–æœ€å¼ºçš„3ä¸ªå¼‚å¸¸ç»´åº¦ï¼ˆé¿å…å™ªéŸ³ï¼‰
            top3_scores = sorted(scores.values(), reverse=True)[:3]
            anomaly_score = sum(top3_scores) / 3  # å¹³å‡åˆ†

            # é˜ˆå€¼ï¼šå¼‚å¸¸åˆ†æ•° >= 40ï¼ˆè‡³å°‘æœ‰ä¸€ä¸ªç»´åº¦æ˜¾è‘—å¼‚å¸¸ï¼‰
            min_anomaly_score = params.get("min_anomaly_score", 40)

            if anomaly_score >= min_anomaly_score:
                t["_anomaly_score"] = anomaly_score
                t["_anomaly_details"] = scores
                t["_price_z"] = price_z  # ä¿ç•™æ–¹å‘ä¿¡æ¯ï¼ˆåç»­ç”¨ï¼‰
                anomalies.append(t)

                # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„å¼‚å¸¸
                top_dim = max(scores, key=scores.get)
                if idx % 10 != 0 and idx != 1:
                    log(f"   [{idx}/{len(candidates)}] {sym} âš¡ å¼‚å¸¸ (åˆ†æ•°={anomaly_score:.0f}, ä¸»å› ={top_dim})")

            processed += 1

        except Exception as e:
            continue

    log(f"   âœ… {len(candidates)} â†’ {len(anomalies)} ä¸ªï¼ˆæ£€æµ‹åˆ°å¼‚å¸¸ï¼‰")
    return anomalies

# ============ Layer 3: å¤šå› å­è¯„åˆ† ============

def _layer3_multifactor_scoring(anomalies: List[Dict], params: Dict) -> List[Dict]:
    """
    Layer 3: å¤šå› å­è´¨é‡è¯„åˆ†ï¼ˆæ–¹å‘æ„ŸçŸ¥ï¼‰
    ç›®æ ‡ï¼šåœ¨å¼‚å¸¸å¸ä¸­ï¼Œè¯„ä¼°åšå¤š/åšç©ºçš„è´¨é‡

    è¯„åˆ†ç»´åº¦ï¼ˆä¸analyze_symbolå¯¹é½ï¼‰ï¼š
    1. è¶‹åŠ¿å¼ºåº¦ï¼ˆTrend Strengthï¼‰- ä¸çœ‹æ–¹å‘ï¼Œåªçœ‹å¼ºåº¦
    2. åŠ¨é‡è´¨é‡ï¼ˆMomentum Qualityï¼‰
    3. æµåŠ¨æ€§çŠ¶æ€ï¼ˆLiquidity Stateï¼‰
    4. å¾®è§‚ç»“æ„ï¼ˆMicrostructureï¼‰

    è¾“å‡ºï¼šæ¯ä¸ªå¸çš„long_scoreå’Œshort_scoreï¼ˆ0-100ï¼‰
    """
    log("ğŸ“Š [Layer 3] å¤šå› å­è´¨é‡è¯„åˆ†...")

    scored = []

    for idx, t in enumerate(anomalies, 1):
        try:
            sym = t["symbol"]

            # è·å–æ•°æ®ï¼ˆå·²åœ¨Layer 2è·å–è¿‡ï¼Œè¿™é‡Œé‡æ–°è·å–æ˜¯ä¸ºäº†è®¡ç®—æ›´å¤šæŒ‡æ ‡ï¼‰
            k1 = get_klines(sym, "1h", 60)
            if not k1 or len(k1) < 30:
                continue

            oi = get_open_interest_hist(sym, "1h", 60)

            closes = [_to_f(r[4]) for r in k1]
            volumes = [_to_f(r[7]) for r in k1]

            # === 1. è¶‹åŠ¿å¼ºåº¦è¯„åˆ† ===
            ema5 = _ema(closes, 5)
            ema20 = _ema(closes, 20)

            # è¶‹åŠ¿æ–¹å‘ï¼ˆ+1=å¤šå¤´ï¼Œ-1=ç©ºå¤´ï¼‰
            trend_dir = 1 if ema5[-1] > ema20[-1] else -1

            # è¶‹åŠ¿å¼ºåº¦ï¼ˆEMAæ’åˆ—ä¸€è‡´æ€§ï¼Œ0-100ï¼‰
            ema_consistency = sum(1 for i in range(-6, 0) if (ema5[i] > ema20[i]) == (trend_dir > 0))
            trend_strength = ema_consistency / 6 * 100

            # === 2. åŠ¨é‡è´¨é‡è¯„åˆ† ===
            # æ–œç‡æ–¹å‘ä¸€è‡´æ€§
            slope_6h = (closes[-1] - closes[-7]) / 6 if len(closes) >= 7 else 0
            slope_dir = 1 if slope_6h > 0 else -1

            # åŠ¨é‡æ–¹å‘ä¸è¶‹åŠ¿ä¸€è‡´æ€§
            momentum_quality = 100 if slope_dir == trend_dir else 30

            # === 3. æµåŠ¨æ€§çŠ¶æ€è¯„åˆ† ===
            # é‡èƒ½æ”¯æŒï¼ˆv5/v20ï¼Œ1.0-3.0 = 0-100åˆ†ï¼‰
            v5 = sum(volumes[-5:]) / 5
            v20 = sum(volumes[-20:]) / 20
            volume_support = min(100, (v5 / v20 - 1.0) * 50) if v20 > 0 else 0

            # === 4. å¾®è§‚ç»“æ„è¯„åˆ† ===
            # OIå˜åŒ–æ–¹å‘ï¼ˆä¸ä»·æ ¼ä¸€è‡´=å¥½ï¼‰
            if oi and len(oi) >= 7:
                oi_values = [_to_f(r[5]) for r in oi]
                oi_change_6h = (oi_values[-1] - oi_values[-7]) / oi_values[-7] if oi_values[-7] > 0 else 0
                oi_dir = 1 if oi_change_6h > 0 else -1

                # å¾®è§‚ç»“æ„å¾—åˆ†ï¼ˆä»·æ ¼ã€OIåŒå‘=100ï¼Œåå‘=0ï¼‰
                microstructure_score = 100 if oi_dir == trend_dir else 20
            else:
                microstructure_score = 50  # ä¸­æ€§

            # === ç»¼åˆè¯„åˆ† ===
            # åŸºç¡€è´¨é‡åˆ†ï¼ˆ0-100ï¼‰
            base_quality = (
                0.35 * trend_strength +
                0.25 * momentum_quality +
                0.20 * volume_support +
                0.20 * microstructure_score
            )

            # åšå¤š/åšç©ºåˆ†æ•°ï¼ˆæ ¹æ®è¶‹åŠ¿æ–¹å‘åˆ†é…ï¼‰
            if trend_dir > 0:
                long_score = base_quality
                short_score = max(0, 100 - base_quality)  # åå‘åˆ†æ•°
            else:
                short_score = base_quality
                long_score = max(0, 100 - base_quality)

            # é˜ˆå€¼ï¼šè‡³å°‘æœ‰ä¸€ä¸ªæ–¹å‘åˆ†æ•° >= 60
            min_quality = params.get("min_quality_score", 60)

            if long_score >= min_quality or short_score >= min_quality:
                t["_long_score"] = long_score
                t["_short_score"] = short_score
                t["_trend_dir"] = "LONG" if trend_dir > 0 else "SHORT"
                scored.append(t)
        except:
            continue

    log(f"   âœ… {len(anomalies)} â†’ {len(scored)} ä¸ªï¼ˆè´¨é‡åˆæ ¼ï¼‰")
    return scored

# ============ Layer 4: é£é™©è¿‡æ»¤ ============

def _layer4_risk_filter(scored: List[Dict], params: Dict) -> List[Dict]:
    """
    Layer 4: é£é™©è¿‡æ»¤ï¼ˆæ’é™¤é™·é˜±ï¼‰
    ç›®æ ‡ï¼šæ’é™¤é«˜é£é™©å¸ï¼ˆæ“çºµã€æµåŠ¨æ€§æ¯ç«­ã€æç«¯æ³¢åŠ¨ï¼‰

    é£é™©æ£€æµ‹ï¼š
    1. æç«¯æ³¢åŠ¨ï¼ˆå¯èƒ½æ˜¯æ“çºµï¼‰
    2. æµåŠ¨æ€§æ¯ç«­ï¼ˆæ— æ³•å¹³ä»“ï¼‰
    3. ä»·æ ¼è·ç¦»æå€¼è¿‡è¿‘ï¼ˆè¿½é«˜/è¿½è·Œï¼‰
    """
    log("ğŸ›¡ï¸  [Layer 4] é£é™©è¿‡æ»¤...")

    filtered = []

    for t in scored:
        try:
            sym = t["symbol"]

            # è·å–æ•°æ®
            k1 = get_klines(sym, "1h", 72)  # 72å°æ—¶ï¼ˆ3å¤©ï¼‰
            if not k1 or len(k1) < 72:
                filtered.append(t)  # æ•°æ®ä¸è¶³ï¼Œä¿å®ˆé€šè¿‡
                continue

            highs = [_to_f(r[2]) for r in k1]
            lows = [_to_f(r[3]) for r in k1]
            closes = [_to_f(r[4]) for r in k1]
            volumes = [_to_f(r[7]) for r in k1]

            current_price = closes[-1]

            # === é£é™©1ï¼šæç«¯æ³¢åŠ¨æ£€æµ‹ ===
            # å•æ ¹Kçº¿æ¶¨è·Œå¹…è¶…è¿‡20%ï¼ˆå¯èƒ½æ˜¯æ“çºµæˆ–æµåŠ¨æ€§å·®ï¼‰
            max_1h_change = max(abs(closes[i] - closes[i-1]) / closes[i-1] for i in range(1, len(closes)))
            if max_1h_change > 0.20:  # 20%
                log(f"   âš ï¸  {sym} è¿‡æ»¤ï¼ˆæç«¯æ³¢åŠ¨ï¼š{max_1h_change:.1%}ï¼‰")
                continue

            # === é£é™©2ï¼šæµåŠ¨æ€§æ¯ç«­æ£€æµ‹ ===
            # æœ€è¿‘6hæˆäº¤é‡éª¤é™ï¼ˆä½äºå‰66hå¹³å‡çš„30%ï¼‰
            vol_6h = sum(volumes[-6:])
            vol_66h_avg = sum(volumes[-72:-6]) / 66
            if vol_6h < vol_66h_avg * 6 * 0.30:  # ä½äº30%
                log(f"   âš ï¸  {sym} è¿‡æ»¤ï¼ˆæµåŠ¨æ€§æ¯ç«­ï¼‰")
                continue

            # === é£é™©3ï¼šè¿½é«˜/è¿½è·Œæ£€æµ‹ ===
            # è·ç¦»72hé«˜ç‚¹/ä½ç‚¹è¿‡è¿‘ï¼ˆ<3%ï¼‰
            hh_72 = max(highs)
            ll_72 = min(lows)

            dist_to_high = (hh_72 - current_price) / hh_72
            dist_to_low = (current_price - ll_72) / ll_72

            max_distance = params.get("anti_chase_distance", 0.03)  # 3%

            if dist_to_high < max_distance:
                log(f"   âš ï¸  {sym} è¿‡æ»¤ï¼ˆè·é«˜ç‚¹è¿‡è¿‘ï¼š{dist_to_high:.1%}ï¼‰")
                continue

            if dist_to_low < max_distance:
                log(f"   âš ï¸  {sym} è¿‡æ»¤ï¼ˆè·ä½ç‚¹è¿‡è¿‘ï¼š{dist_to_low:.1%}ï¼‰")
                continue

            # é€šè¿‡æ‰€æœ‰é£é™©æ£€æµ‹
            filtered.append(t)

        except:
            # æ£€æµ‹å¤±è´¥ï¼Œä¿å®ˆé€šè¿‡
            filtered.append(t)
            continue

    log(f"   âœ… {len(scored)} â†’ {len(filtered)} ä¸ªï¼ˆé£é™©æ£€æŸ¥é€šè¿‡ï¼‰")
    return filtered

# ============ ä¸»å‡½æ•° ============

def build_elite_universe() -> Tuple[List[str], Dict[str, Any]]:
    """
    ä¸–ç•Œé¡¶çº§å€™é€‰æ± æ„å»º

    è¿”å›ï¼š
    - symbols: æœ€ç»ˆå€™é€‰æ± äº¤æ˜“å¯¹åˆ—è¡¨
    - metadata: æ¯ä¸ªäº¤æ˜“å¯¹çš„å…ƒæ•°æ®ï¼ˆåˆ†æ•°ã€æ–¹å‘ç­‰ï¼‰
    """
    log("=" * 60)
    log("ğŸ† Elite Universe Builder - ä¸–ç•Œé¡¶çº§å€™é€‰æ± æ„å»º")
    log("=" * 60)

    params = CFG.get("elite_universe", {})

    # Layer 0: å®‡å®™è¿‡æ»¤
    tickers = all_24h()
    universe = _layer0_universe_filter(tickers)

    # Layer 1: æµåŠ¨æ€§ç­›é€‰
    liquid = _layer1_liquidity_screen(universe, params)

    # Layer 2: å¼‚å¸¸äº‹ä»¶æ£€æµ‹
    anomalies = _layer2_anomaly_detection(liquid, params)

    # Layer 3: å¤šå› å­è¯„åˆ†
    scored = _layer3_multifactor_scoring(anomalies, params)

    # Layer 4: é£é™©è¿‡æ»¤
    final = _layer4_risk_filter(scored, params)

    # æŒ‰ç»¼åˆåˆ†æ•°æ’åºï¼ˆå–long_scoreå’Œshort_scoreçš„æœ€å¤§å€¼ï¼‰
    final_sorted = sorted(final, key=lambda x: max(x.get("_long_score", 0), x.get("_short_score", 0)), reverse=True)

    # æå–å…ƒæ•°æ®
    metadata = {}
    symbols = []
    for t in final_sorted:
        sym = t["symbol"]
        symbols.append(sym)
        metadata[sym] = {
            "long_score": t.get("_long_score", 0),
            "short_score": t.get("_short_score", 0),
            "trend_dir": t.get("_trend_dir", "NEUTRAL"),
            "anomaly_score": t.get("_anomaly_score", 0),
            "anomaly_details": t.get("_anomaly_details", {}),
            "liquidity_score": t.get("_liquidity_score", 0),
        }

    # ä¿å­˜ç»“æœ
    with open(os.path.join(DATA, "elite_universe.json"), "w", encoding="utf-8") as f:
        json.dump({"symbols": symbols, "metadata": metadata}, f, ensure_ascii=False, indent=2)

    log("=" * 60)
    log(f"ğŸ¯ æœ€ç»ˆå€™é€‰æ± ï¼š{len(symbols)} ä¸ªäº¤æ˜“å¯¹")
    if len(symbols) > 0:
        log(f"   å‰10å: {', '.join(symbols[:10])}")

        # ç»Ÿè®¡å¤šç©ºåˆ†å¸ƒ
        longs = sum(1 for s in symbols if metadata[s]["trend_dir"] == "LONG")
        shorts = sum(1 for s in symbols if metadata[s]["trend_dir"] == "SHORT")
        log(f"   åšå¤šæœºä¼š: {longs} ä¸ª ({longs/len(symbols)*100:.0f}%)")
        log(f"   åšç©ºæœºä¼š: {shorts} ä¸ª ({shorts/len(symbols)*100:.0f}%)")
    log("=" * 60)

    return symbols, metadata
