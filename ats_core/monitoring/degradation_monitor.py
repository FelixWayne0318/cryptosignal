# coding: utf-8
"""
é™çº§äº‹ä»¶ç›‘æ§ç³»ç»Ÿï¼ˆv3.1ï¼‰

æä¾›å…¨å±€é™çº§äº‹ä»¶è®°å½•ã€ç»Ÿè®¡å’Œåˆ†æåŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- è®°å½•æ‰€æœ‰å› å­çš„é™çº§äº‹ä»¶
- æŒ‰å› å­ã€çº§åˆ«ã€æ—¶é—´èŒƒå›´ç»Ÿè®¡é™çº§æ¬¡æ•°
- å¯¼å‡ºé™çº§æŠ¥å‘Šï¼ˆJSON/CSVæ ¼å¼ï¼‰
- å®æ—¶é™çº§å‘Šè­¦

ä½¿ç”¨ç¤ºä¾‹ï¼š
    from ats_core.monitoring import record_degradation, get_degradation_stats

    # è®°å½•é™çº§äº‹ä»¶
    record_degradation(
        factor_name="M",
        level="degraded",
        confidence=0.6,
        actual_data=12,
        required_data=20,
        reason="insufficient_data"
    )

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = get_degradation_stats(factor_name="M", last_n_hours=24)
    print(f"Må› å­24å°æ—¶å†…é™çº§{stats['total_events']}æ¬¡")
"""

import time
import json
from typing import Dict, List, Any, Optional
from collections import defaultdict
from threading import Lock


class DegradationMonitor:
    """é™çº§äº‹ä»¶ç›‘æ§å™¨

    å…¨å±€å•ä¾‹ï¼Œè®°å½•å’Œåˆ†ææ‰€æœ‰å› å­çš„é™çº§äº‹ä»¶ã€‚

    çº¿ç¨‹å®‰å…¨ï¼šä½¿ç”¨Lockä¿æŠ¤å…±äº«æ•°æ®ã€‚
    """

    def __init__(self, max_events: int = 10000):
        """
        Args:
            max_events: æœ€å¤§äº‹ä»¶è®°å½•æ•°ï¼ˆè¶…è¿‡åè‡ªåŠ¨æ¸…ç†æ—§äº‹ä»¶ï¼‰
        """
        self.max_events = max_events
        self._events = []  # æ‰€æœ‰é™çº§äº‹ä»¶åˆ—è¡¨
        self._lock = Lock()  # çº¿ç¨‹é”

        # ç»Ÿè®¡ç¼“å­˜ï¼ˆæŒ‰å› å­åç§°ï¼‰
        self._stats_cache = {}
        self._cache_timestamp = 0
        self._cache_ttl = 60  # ç¼“å­˜æœ‰æ•ˆæœŸ60ç§’

    def record_event(
        self,
        factor_name: str,
        level: str,
        confidence: float,
        actual_data: int,
        required_data: int,
        reason: str,
        symbol: Optional[str] = None,
        additional_info: Optional[Dict[str, Any]] = None
    ):
        """è®°å½•é™çº§äº‹ä»¶

        Args:
            factor_name: å› å­åç§°ï¼ˆå¦‚"M", "C+", "V+"ç­‰ï¼‰
            level: é™çº§çº§åˆ«ï¼ˆ"normal", "warning", "degraded", "disabled"ï¼‰
            confidence: ç½®ä¿¡åº¦ï¼ˆ0.0 - 1.0ï¼‰
            actual_data: å®é™…æ•°æ®é‡
            required_data: æœ€å°è¦æ±‚æ•°æ®é‡
            reason: é™çº§åŸå› ï¼ˆå¦‚"insufficient_data"ï¼‰
            symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¯é€‰ï¼‰
            additional_info: é¢å¤–ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        """
        with self._lock:
            event = {
                "timestamp": time.time(),
                "factor_name": factor_name,
                "level": level,
                "confidence": round(confidence, 3),
                "actual_data": actual_data,
                "required_data": required_data,
                "data_ratio": round(actual_data / max(1, required_data), 3),
                "reason": reason,
                "symbol": symbol
            }

            # åˆå¹¶é¢å¤–ä¿¡æ¯
            if additional_info:
                event.update(additional_info)

            self._events.append(event)

            # è‡ªåŠ¨æ¸…ç†æ—§äº‹ä»¶
            if len(self._events) > self.max_events:
                # ä¿ç•™æœ€è¿‘50%çš„äº‹ä»¶
                self._events = self._events[-(self.max_events // 2):]

            # æ¸…é™¤ç»Ÿè®¡ç¼“å­˜
            self._invalidate_cache()

    def get_stats(
        self,
        factor_name: Optional[str] = None,
        last_n_hours: Optional[int] = None,
        min_level: Optional[str] = None
    ) -> Dict[str, Any]:
        """è·å–é™çº§ç»Ÿè®¡ä¿¡æ¯

        Args:
            factor_name: ç­›é€‰ç‰¹å®šå› å­ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰å› å­ï¼‰
            last_n_hours: ç­›é€‰æœ€è¿‘Nå°æ—¶çš„äº‹ä»¶ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰æ—¶é—´ï¼‰
            min_level: æœ€å°é™çº§çº§åˆ«ï¼ˆ"warning", "degraded", "disabled"ï¼‰

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ï¼š
            - total_events: æ€»äº‹ä»¶æ•°
            - by_factor: æŒ‰å› å­åˆ†ç»„çš„äº‹ä»¶æ•°
            - by_level: æŒ‰çº§åˆ«åˆ†ç»„çš„äº‹ä»¶æ•°
            - avg_confidence: å¹³å‡ç½®ä¿¡åº¦
            - avg_data_ratio: å¹³å‡æ•°æ®å……è¶³ç‡
            - recent_events: æœ€è¿‘10ä¸ªäº‹ä»¶
        """
        with self._lock:
            # ç­›é€‰äº‹ä»¶
            filtered_events = self._filter_events(
                factor_name=factor_name,
                last_n_hours=last_n_hours,
                min_level=min_level
            )

            if not filtered_events:
                return {
                    "total_events": 0,
                    "by_factor": {},
                    "by_level": {},
                    "avg_confidence": 1.0,
                    "avg_data_ratio": 1.0,
                    "recent_events": []
                }

            # æŒ‰å› å­å’Œçº§åˆ«ç»Ÿè®¡
            by_factor = defaultdict(int)
            by_level = defaultdict(int)
            total_confidence = 0.0
            total_data_ratio = 0.0

            for event in filtered_events:
                by_factor[event["factor_name"]] += 1
                by_level[event["level"]] += 1
                total_confidence += event["confidence"]
                total_data_ratio += event["data_ratio"]

            return {
                "total_events": len(filtered_events),
                "by_factor": dict(by_factor),
                "by_level": dict(by_level),
                "avg_confidence": round(total_confidence / len(filtered_events), 3),
                "avg_data_ratio": round(total_data_ratio / len(filtered_events), 3),
                "recent_events": filtered_events[-10:]  # æœ€è¿‘10ä¸ª
            }

    def _filter_events(
        self,
        factor_name: Optional[str] = None,
        last_n_hours: Optional[int] = None,
        min_level: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """ç­›é€‰äº‹ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        Args:
            factor_name: å› å­åç§°ç­›é€‰
            last_n_hours: æ—¶é—´èŒƒå›´ç­›é€‰ï¼ˆå°æ—¶ï¼‰
            min_level: æœ€å°çº§åˆ«ç­›é€‰

        Returns:
            ç­›é€‰åçš„äº‹ä»¶åˆ—è¡¨
        """
        # çº§åˆ«ä¼˜å…ˆçº§æ˜ å°„
        level_priority = {
            "normal": 0,
            "warning": 1,
            "degraded": 2,
            "disabled": 3
        }
        min_priority = level_priority.get(min_level, 0) if min_level else 0

        # æ—¶é—´æˆ³é˜ˆå€¼
        time_threshold = time.time() - (last_n_hours * 3600) if last_n_hours else 0

        filtered = []
        for event in self._events:
            # å› å­åç§°ç­›é€‰
            if factor_name and event["factor_name"] != factor_name:
                continue

            # æ—¶é—´èŒƒå›´ç­›é€‰
            if last_n_hours and event["timestamp"] < time_threshold:
                continue

            # çº§åˆ«ç­›é€‰
            if min_level:
                event_priority = level_priority.get(event["level"], 0)
                if event_priority < min_priority:
                    continue

            filtered.append(event)

        return filtered

    def export_to_json(
        self,
        file_path: str,
        factor_name: Optional[str] = None,
        last_n_hours: Optional[int] = None
    ):
        """å¯¼å‡ºé™çº§äº‹ä»¶åˆ°JSONæ–‡ä»¶

        Args:
            file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            factor_name: ç­›é€‰ç‰¹å®šå› å­ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰å› å­ï¼‰
            last_n_hours: ç­›é€‰æœ€è¿‘Nå°æ—¶çš„äº‹ä»¶ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰æ—¶é—´ï¼‰
        """
        with self._lock:
            filtered_events = self._filter_events(
                factor_name=factor_name,
                last_n_hours=last_n_hours
            )

            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "export_time": time.time(),
                    "total_events": len(filtered_events),
                    "filter": {
                        "factor_name": factor_name,
                        "last_n_hours": last_n_hours
                    },
                    "events": filtered_events
                }, f, indent=2, ensure_ascii=False)

    def export_to_csv(
        self,
        file_path: str,
        factor_name: Optional[str] = None,
        last_n_hours: Optional[int] = None
    ):
        """å¯¼å‡ºé™çº§äº‹ä»¶åˆ°CSVæ–‡ä»¶

        Args:
            file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            factor_name: ç­›é€‰ç‰¹å®šå› å­ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰å› å­ï¼‰
            last_n_hours: ç­›é€‰æœ€è¿‘Nå°æ—¶çš„äº‹ä»¶ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰æ—¶é—´ï¼‰
        """
        import csv

        with self._lock:
            filtered_events = self._filter_events(
                factor_name=factor_name,
                last_n_hours=last_n_hours
            )

            if not filtered_events:
                return

            # è·å–æ‰€æœ‰å­—æ®µåï¼ˆä»ç¬¬ä¸€ä¸ªäº‹ä»¶ï¼‰
            fieldnames = list(filtered_events[0].keys())

            with open(file_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(filtered_events)

    def get_alert_summary(self, threshold_hours: int = 1) -> Dict[str, Any]:
        """è·å–é™çº§å‘Šè­¦æ‘˜è¦

        è¯†åˆ«æœ€è¿‘Nå°æ—¶å†…é¢‘ç¹é™çº§çš„å› å­ï¼Œç”¨äºå®æ—¶å‘Šè­¦ã€‚

        Args:
            threshold_hours: æ—¶é—´é˜ˆå€¼ï¼ˆå°æ—¶ï¼‰

        Returns:
            å‘Šè­¦æ‘˜è¦ï¼ŒåŒ…å«ï¼š
            - critical_factors: ä¸¥é‡é™çº§çš„å› å­åˆ—è¡¨
            - warning_factors: è­¦å‘Šçº§åˆ«çš„å› å­åˆ—è¡¨
            - summary: æ–‡æœ¬æ‘˜è¦
        """
        stats = self.get_stats(last_n_hours=threshold_hours)

        critical_factors = []
        warning_factors = []

        for factor, count in stats["by_factor"].items():
            # è·å–è¯¥å› å­çš„è¯¦ç»†ç»Ÿè®¡
            factor_stats = self.get_stats(
                factor_name=factor,
                last_n_hours=threshold_hours
            )

            # åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
            disabled_count = factor_stats["by_level"].get("disabled", 0)
            degraded_count = factor_stats["by_level"].get("degraded", 0)

            if disabled_count > 0:
                critical_factors.append({
                    "factor": factor,
                    "disabled_count": disabled_count,
                    "avg_confidence": factor_stats["avg_confidence"]
                })
            elif degraded_count > 0:
                warning_factors.append({
                    "factor": factor,
                    "degraded_count": degraded_count,
                    "avg_confidence": factor_stats["avg_confidence"]
                })

        # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
        summary_parts = []
        if critical_factors:
            summary_parts.append(f"ğŸš¨ ä¸¥é‡: {len(critical_factors)}ä¸ªå› å­å®Œå…¨ç¦ç”¨")
        if warning_factors:
            summary_parts.append(f"âš ï¸ è­¦å‘Š: {len(warning_factors)}ä¸ªå› å­é™çº§")

        return {
            "critical_factors": critical_factors,
            "warning_factors": warning_factors,
            "summary": " | ".join(summary_parts) if summary_parts else "âœ… æ­£å¸¸",
            "total_events": stats["total_events"]
        }

    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰äº‹ä»¶è®°å½•"""
        with self._lock:
            self._events = []
            self._invalidate_cache()

    def _invalidate_cache(self):
        """æ¸…é™¤ç»Ÿè®¡ç¼“å­˜"""
        self._stats_cache = {}
        self._cache_timestamp = 0


# ========== å…¨å±€å•ä¾‹ ==========

_global_monitor: Optional[DegradationMonitor] = None
_monitor_lock = Lock()


def get_global_monitor() -> DegradationMonitor:
    """è·å–å…¨å±€é™çº§ç›‘æ§å™¨å•ä¾‹

    Returns:
        å…¨å±€DegradationMonitorå®ä¾‹
    """
    global _global_monitor

    if _global_monitor is None:
        with _monitor_lock:
            if _global_monitor is None:
                _global_monitor = DegradationMonitor()

    return _global_monitor


# ========== ä¾¿æ·å‡½æ•° ==========

def record_degradation(
    factor_name: str,
    level: str,
    confidence: float,
    actual_data: int,
    required_data: int,
    reason: str,
    symbol: Optional[str] = None,
    **kwargs
):
    """è®°å½•é™çº§äº‹ä»¶ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        factor_name: å› å­åç§°
        level: é™çº§çº§åˆ«
        confidence: ç½®ä¿¡åº¦
        actual_data: å®é™…æ•°æ®é‡
        required_data: è¦æ±‚æ•°æ®é‡
        reason: é™çº§åŸå› 
        symbol: äº¤æ˜“å¯¹ï¼ˆå¯é€‰ï¼‰
        **kwargs: é¢å¤–ä¿¡æ¯
    """
    monitor = get_global_monitor()
    monitor.record_event(
        factor_name=factor_name,
        level=level,
        confidence=confidence,
        actual_data=actual_data,
        required_data=required_data,
        reason=reason,
        symbol=symbol,
        additional_info=kwargs
    )


def get_degradation_stats(
    factor_name: Optional[str] = None,
    last_n_hours: Optional[int] = None
) -> Dict[str, Any]:
    """è·å–é™çº§ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        factor_name: å› å­åç§°ï¼ˆå¯é€‰ï¼‰
        last_n_hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼Œå¯é€‰ï¼‰

    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    monitor = get_global_monitor()
    return monitor.get_stats(
        factor_name=factor_name,
        last_n_hours=last_n_hours
    )
