# coding: utf-8
"""
æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å™¨

åŠŸèƒ½ï¼š
1. 5æŠ˜æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ï¼ˆTimeSeriesSplitï¼‰
2. è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ—¶é—´æ®µçš„ç¨³å®šæ€§
3. æ£€æµ‹æ—¶é—´ä¾èµ–æ€§è¿‡æ‹Ÿåˆ
4. ç”Ÿæˆäº¤å‰éªŒè¯æŠ¥å‘Š

ç†è®ºåŸºç¡€ï¼š
æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ç‰¹ç‚¹ï¼š
- ä¸èƒ½éšæœºæ‰“ä¹±ï¼ˆå¿…é¡»ä¿æŒæ—¶é—´é¡ºåºï¼‰
- ä½¿ç”¨æ»šåŠ¨çª—å£ï¼ˆRolling Windowï¼‰æˆ–æ‰©å±•çª—å£ï¼ˆExpanding Windowï¼‰
- è®­ç»ƒé›†å§‹ç»ˆåœ¨æµ‹è¯•é›†ä¹‹å‰

5æŠ˜ç¤ºä¾‹ï¼ˆExpanding Windowï¼‰:
Fold 1: Train[0:20]    Test[20:40]
Fold 2: Train[0:40]    Test[40:60]
Fold 3: Train[0:60]    Test[60:80]
Fold 4: Train[0:80]    Test[80:100]
Fold 5: Train[0:100]   Test[100:120]

è¯„ä¼°æŒ‡æ ‡ï¼š
- Mean Accuracy: å¹³å‡å‡†ç¡®ç‡
- Std Accuracy: å‡†ç¡®ç‡æ ‡å‡†å·®ï¼ˆè¶Šå°è¶Šç¨³å®šï¼‰
- Mean IC: å¹³å‡IC
- IC Consistency: ICä¸€è‡´æ€§ï¼ˆæ‰€æœ‰foldçš„ICåŒå·æ¯”ä¾‹ï¼‰
"""

from __future__ import annotations
from typing import Dict, List, Tuple, Any, Callable, Optional
import numpy as np
from collections import defaultdict


class TimeSeriesCrossValidator:
    """æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å™¨"""

    def __init__(
        self,
        n_splits: int = 5,
        test_size: Optional[int] = None,
        expanding_window: bool = True
    ):
        """
        åˆå§‹åŒ–äº¤å‰éªŒè¯å™¨

        Args:
            n_splits: æŠ˜æ•°ï¼ˆé»˜è®¤5ï¼‰
            test_size: æµ‹è¯•é›†å¤§å°ï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨è®¡ç®—ï¼‰
            expanding_window: æ˜¯å¦ä½¿ç”¨æ‰©å±•çª—å£ï¼ˆTrueï¼‰è¿˜æ˜¯æ»šåŠ¨çª—å£ï¼ˆFalseï¼‰
        """
        self.n_splits = n_splits
        self.test_size = test_size
        self.expanding_window = expanding_window

        # å­˜å‚¨äº¤å‰éªŒè¯ç»“æœ
        self.cv_results = {}

    def split(
        self,
        X: List[Any],
        y: Optional[List[Any]] = None
    ) -> List[Tuple[List[int], List[int]]]:
        """
        ç”Ÿæˆè®­ç»ƒ/æµ‹è¯•é›†ç´¢å¼•

        Args:
            X: ç‰¹å¾æ•°æ®
            y: æ ‡ç­¾æ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            [(train_indices, test_indices), ...]
        """
        n_samples = len(X)

        if n_samples < self.n_splits + 1:
            raise ValueError(f"Not enough samples ({n_samples}) for {self.n_splits} splits")

        # è®¡ç®—æµ‹è¯•é›†å¤§å°
        if self.test_size is None:
            # è‡ªåŠ¨è®¡ç®—ï¼šç¡®ä¿æ¯ä¸ªfoldéƒ½æœ‰åˆç†çš„æµ‹è¯•é›†å¤§å°
            test_size = max(1, n_samples // (self.n_splits + 1))
        else:
            test_size = self.test_size

        # ç”Ÿæˆsplits
        splits = []

        for i in range(self.n_splits):
            if self.expanding_window:
                # æ‰©å±•çª—å£ï¼šè®­ç»ƒé›†é€æ¸æ‰©å¤§
                test_start = (i + 1) * test_size
                test_end = test_start + test_size

                if test_end > n_samples:
                    break

                train_indices = list(range(0, test_start))
                test_indices = list(range(test_start, test_end))

            else:
                # æ»šåŠ¨çª—å£ï¼šè®­ç»ƒé›†å’Œæµ‹è¯•é›†å¤§å°å›ºå®š
                test_start = (i + 1) * test_size
                test_end = test_start + test_size

                if test_end > n_samples:
                    break

                train_start = max(0, test_start - test_size * self.n_splits)
                train_indices = list(range(train_start, test_start))
                test_indices = list(range(test_start, test_end))

            if train_indices and test_indices:
                splits.append((train_indices, test_indices))

        return splits

    def cross_validate(
        self,
        X: List[Any],
        y: List[Any],
        model_fn: Callable,
        score_fn: Optional[Callable] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œäº¤å‰éªŒè¯

        Args:
            X: ç‰¹å¾æ•°æ®åˆ—è¡¨
            y: æ ‡ç­¾æ•°æ®åˆ—è¡¨
            model_fn: æ¨¡å‹è®­ç»ƒå‡½æ•° model_fn(X_train, y_train) -> model
            score_fn: è¯„åˆ†å‡½æ•° score_fn(model, X_test, y_test) -> score
                     é»˜è®¤ä½¿ç”¨åˆ†ç±»å‡†ç¡®ç‡

        Returns:
            äº¤å‰éªŒè¯ç»“æœå­—å…¸
        """
        if score_fn is None:
            # é»˜è®¤è¯„åˆ†å‡½æ•°ï¼šåˆ†ç±»å‡†ç¡®ç‡
            def default_score_fn(model, X_test, y_test):
                predictions = [model.predict(x) for x in X_test]
                correct = sum(1 for pred, true in zip(predictions, y_test) if pred == true)
                return correct / len(y_test)

            score_fn = default_score_fn

        # ç”Ÿæˆsplits
        splits = self.split(X, y)

        if len(splits) < 2:
            return {
                "error": "Insufficient data for cross-validation",
                "n_samples": len(X),
                "n_splits_possible": len(splits)
            }

        # æ‰§è¡Œäº¤å‰éªŒè¯
        fold_scores = []
        fold_details = []

        for fold_idx, (train_indices, test_indices) in enumerate(splits):
            # æå–è®­ç»ƒ/æµ‹è¯•æ•°æ®
            X_train = [X[i] for i in train_indices]
            y_train = [y[i] for i in train_indices]
            X_test = [X[i] for i in test_indices]
            y_test = [y[i] for i in test_indices]

            # è®­ç»ƒæ¨¡å‹
            model = model_fn(X_train, y_train)

            # è¯„åˆ†
            score = score_fn(model, X_test, y_test)
            fold_scores.append(score)

            fold_details.append({
                "fold": fold_idx + 1,
                "train_size": len(train_indices),
                "test_size": len(test_indices),
                "score": score
            })

        # è®¡ç®—ç»Ÿè®¡é‡
        mean_score = np.mean(fold_scores)
        std_score = np.std(fold_scores)
        min_score = np.min(fold_scores)
        max_score = np.max(fold_scores)

        # ç¨³å®šæ€§è¯„ä¼°
        if std_score < 0.05:
            stability = "excellent"
        elif std_score < 0.10:
            stability = "good"
        elif std_score < 0.15:
            stability = "fair"
        else:
            stability = "poor"

        # å­˜å‚¨ç»“æœ
        self.cv_results = {
            "n_splits": len(splits),
            "fold_scores": fold_scores,
            "fold_details": fold_details,
            "mean_score": mean_score,
            "std_score": std_score,
            "min_score": min_score,
            "max_score": max_score,
            "stability": stability
        }

        return self.cv_results

    def cross_validate_ic(
        self,
        factor_scores: List[Dict[str, float]],
        future_returns: List[float]
    ) -> Dict[str, Dict[str, Any]]:
        """
        å¯¹æ‰€æœ‰å› å­æ‰§è¡ŒICäº¤å‰éªŒè¯

        Args:
            factor_scores: å› å­è¯„åˆ†åˆ—è¡¨ [{factor_name: score}, ...]
            future_returns: æœªæ¥æ”¶ç›Šåˆ—è¡¨

        Returns:
            {factor_name: cv_results, ...}
        """
        if not factor_scores or not future_returns:
            return {}

        # è·å–æ‰€æœ‰å› å­åç§°
        factor_names = list(factor_scores[0].keys())

        results = {}

        for factor_name in factor_names:
            # æå–è¯¥å› å­çš„æ‰€æœ‰è¯„åˆ†
            X = [[obs[factor_name]] for obs in factor_scores]
            y = future_returns

            # å®šä¹‰ç®€å•çš„"æ¨¡å‹"å’Œè¯„åˆ†å‡½æ•°ï¼ˆICè®¡ç®—ï¼‰
            def simple_model_fn(X_train, y_train):
                # è¿”å›è®­ç»ƒæ•°æ®ï¼ˆç”¨äºICè®¡ç®—ï¼‰
                return (X_train, y_train)

            def ic_score_fn(model, X_test, y_test):
                # è®¡ç®—ICï¼ˆSpearmanç§©ç›¸å…³ï¼‰
                X_test_flat = [x[0] for x in X_test]

                # ç§©ç›¸å…³
                factor_ranks = self._rank(X_test_flat)
                return_ranks = self._rank(y_test)

                ic = np.corrcoef(factor_ranks, return_ranks)[0, 1]

                # å¤„ç†NaN
                if np.isnan(ic):
                    ic = 0.0

                return ic

            # æ‰§è¡Œäº¤å‰éªŒè¯
            cv_result = self.cross_validate(X, y, simple_model_fn, ic_score_fn)

            # è®¡ç®—ICä¸€è‡´æ€§ï¼ˆæ‰€æœ‰foldçš„ICåŒå·æ¯”ä¾‹ï¼‰
            if "fold_scores" in cv_result:
                fold_ics = cv_result["fold_scores"]
                positive_ics = sum(1 for ic in fold_ics if ic > 0)
                negative_ics = sum(1 for ic in fold_ics if ic < 0)

                ic_consistency = max(positive_ics, negative_ics) / len(fold_ics)

                cv_result["ic_consistency"] = ic_consistency
                cv_result["consistent_direction"] = "positive" if positive_ics > negative_ics else "negative"

            results[factor_name] = cv_result

        return results

    def _rank(self, values: List[float]) -> List[float]:
        """è®¡ç®—ç§©"""
        sorted_indices = np.argsort(values)
        ranks = np.empty(len(values))
        ranks[sorted_indices] = np.arange(len(values))
        return ranks.tolist()

    def generate_report(self) -> str:
        """
        ç”Ÿæˆäº¤å‰éªŒè¯æŠ¥å‘Š

        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Š
        """
        if not self.cv_results:
            return "# Cross-Validation Report\n\nâš ï¸ No cross-validation results available\n"

        report = []
        report.append("# Time Series Cross-Validation Report")
        report.append("")
        report.append(f"**Method**: {'Expanding Window' if self.expanding_window else 'Rolling Window'}")
        report.append(f"**Number of Splits**: {self.cv_results['n_splits']}")
        report.append("")

        # æ€»ä½“ç»“æœ
        report.append("## Overall Results")
        report.append("")
        report.append(f"- **Mean Score**: {self.cv_results['mean_score']:.4f}")
        report.append(f"- **Std Score**: {self.cv_results['std_score']:.4f}")
        report.append(f"- **Min Score**: {self.cv_results['min_score']:.4f}")
        report.append(f"- **Max Score**: {self.cv_results['max_score']:.4f}")
        report.append(f"- **Stability**: {self.cv_results['stability'].upper()}")
        report.append("")

        # Foldè¯¦æƒ…
        report.append("## Fold Details")
        report.append("")
        report.append("| Fold | Train Size | Test Size | Score |")
        report.append("|------|------------|-----------|-------|")

        for fold_detail in self.cv_results["fold_details"]:
            report.append(
                f"| {fold_detail['fold']} | {fold_detail['train_size']} | "
                f"{fold_detail['test_size']} | {fold_detail['score']:.4f} |"
            )

        report.append("")

        # ç¨³å®šæ€§è¯„ä¼°
        stability = self.cv_results["stability"]

        if stability == "excellent":
            report.append("## âœ… Excellent Stability")
            report.append("")
            report.append("The model shows consistent performance across all folds (Std < 0.05).")
            report.append("Low risk of overfitting.")
        elif stability == "good":
            report.append("## âœ… Good Stability")
            report.append("")
            report.append("The model shows good consistency (Std < 0.10).")
        elif stability == "fair":
            report.append("## âš ï¸ Fair Stability")
            report.append("")
            report.append("The model shows moderate variability (Std < 0.15).")
            report.append("Consider:")
            report.append("- Increasing training data")
            report.append("- Simplifying the model")
            report.append("- Using regularization")
        else:
            report.append("## âŒ Poor Stability")
            report.append("")
            report.append("The model shows high variability across folds (Std >= 0.15).")
            report.append("")
            report.append("âš ï¸ **High risk of overfitting!**")
            report.append("")
            report.append("Recommended actions:")
            report.append("1. Reduce model complexity")
            report.append("2. Increase training data")
            report.append("3. Apply stronger regularization")
            report.append("4. Re-examine feature engineering")

        report.append("")

        return "\n".join(report)

    def generate_factor_ic_report(
        self,
        factor_ic_results: Dict[str, Dict[str, Any]]
    ) -> str:
        """
        ç”Ÿæˆå› å­ICäº¤å‰éªŒè¯æŠ¥å‘Š

        Args:
            factor_ic_results: cross_validate_ic()çš„è¿”å›ç»“æœ

        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Š
        """
        report = []
        report.append("# Factor IC Cross-Validation Report")
        report.append("")
        report.append(f"**Method**: {'Expanding Window' if self.expanding_window else 'Rolling Window'}")
        report.append(f"**Number of Splits**: {self.n_splits}")
        report.append("")

        # æ±‡æ€»è¡¨æ ¼
        report.append("## Factor IC Summary")
        report.append("")
        report.append("| Factor | Mean IC | Std IC | IC Consistency | Stable |")
        report.append("|--------|---------|--------|----------------|--------|")

        for factor_name, cv_result in sorted(
            factor_ic_results.items(),
            key=lambda x: abs(x[1].get("mean_score", 0)),
            reverse=True
        ):
            if "error" in cv_result:
                continue

            mean_ic = cv_result["mean_score"]
            std_ic = cv_result["std_score"]
            ic_consistency = cv_result.get("ic_consistency", 0)

            stable = "âœ…" if ic_consistency >= 0.8 else ("âš ï¸" if ic_consistency >= 0.6 else "âŒ")

            report.append(
                f"| **{factor_name}** | {mean_ic:.4f} | {std_ic:.4f} | "
                f"{ic_consistency:.2f} | {stable} |"
            )

        report.append("")

        # ç¨³å®šå› å­
        stable_factors = [
            name for name, result in factor_ic_results.items()
            if result.get("ic_consistency", 0) >= 0.8
        ]

        if stable_factors:
            report.append("## âœ… Stable Factors (IC Consistency >= 0.8)")
            report.append("")
            for factor_name in stable_factors:
                result = factor_ic_results[factor_name]
                direction = result.get("consistent_direction", "unknown")
                report.append(f"- **{factor_name}**: Consistently {direction} (IC Consistency: {result['ic_consistency']:.2f})")
            report.append("")

        # ä¸ç¨³å®šå› å­
        unstable_factors = [
            name for name, result in factor_ic_results.items()
            if result.get("ic_consistency", 1) < 0.6
        ]

        if unstable_factors:
            report.append("## âš ï¸ Unstable Factors (IC Consistency < 0.6)")
            report.append("")
            report.append("These factors show inconsistent predictive power across time periods:")
            report.append("")
            for factor_name in unstable_factors:
                result = factor_ic_results[factor_name]
                report.append(f"- **{factor_name}**: IC Consistency = {result.get('ic_consistency', 0):.2f}")
            report.append("")
            report.append("ğŸ’¡ Consider:")
            report.append("- Removing these factors")
            report.append("- Investigating time-dependent behavior")
            report.append("- Using rolling windows or adaptive weighting")

        report.append("")

        return "\n".join(report)


# ========== æµ‹è¯•ä»£ç  ==========

if __name__ == "__main__":
    print("=" * 70)
    print("æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å™¨æµ‹è¯•")
    print("=" * 70)

    # åˆ›å»ºéªŒè¯å™¨
    cv = TimeSeriesCrossValidator(n_splits=5, expanding_window=True)

    # æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)

    print("\n[æ¨¡æ‹Ÿæ•°æ®] ç”Ÿæˆ150ä¸ªè§‚æµ‹...")

    factor_scores = []
    future_returns = []

    for i in range(150):
        # æ¨¡æ‹Ÿæœªæ¥æ”¶ç›Š
        future_return = np.random.randn() * 0.02  # Â±2%
        future_returns.append(future_return)

        # æ¨¡æ‹Ÿå› å­ï¼ˆTæœ‰ç¨³å®šé¢„æµ‹èƒ½åŠ›ï¼ŒMä¸ç¨³å®šï¼‰
        T = future_return * 10 + np.random.randn() * 20  # ç¨³å®š
        M = future_return * (5 if i < 100 else -5) + np.random.randn() * 25  # ä¸ç¨³å®š

        factor_scores.append({"T": T, "M": M})

    # å› å­ICäº¤å‰éªŒè¯
    print("\n[å› å­ICäº¤å‰éªŒè¯]")
    ic_results = cv.cross_validate_ic(factor_scores, future_returns)

    for factor_name, result in ic_results.items():
        if "error" not in result:
            print(f"\n  {factor_name}:")
            print(f"    Mean IC:       {result['mean_score']:.4f}")
            print(f"    Std IC:        {result['std_score']:.4f}")
            print(f"    ICä¸€è‡´æ€§:       {result['ic_consistency']:.2f}")
            print(f"    ç¨³å®šæ€§:        {result['stability']}")

    # ç”ŸæˆæŠ¥å‘Š
    print("\n[ç”ŸæˆæŠ¥å‘Š]")
    factor_report = cv.generate_factor_ic_report(ic_results)

    # ä¿å­˜æŠ¥å‘Š
    report_path = "/tmp/cross_validation_report.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(factor_report)

    print(f"  æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

    # æ˜¾ç¤ºæŠ¥å‘Š
    print("\n[æŠ¥å‘Šé¢„è§ˆ]")
    print("-" * 70)
    print(factor_report)

    print("\n" + "=" * 70)
    print("âœ… æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å™¨æµ‹è¯•å®Œæˆ")
    print("=" * 70)
