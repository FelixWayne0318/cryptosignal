# coding: utf-8
"""
IC (Information Coefficient) ç›‘æ§å™¨

åŠŸèƒ½ï¼š
1. è®¡ç®—å› å­ICå€¼ï¼ˆé¢„æµ‹èƒ½åŠ›ï¼‰
2. ç›‘æ§ICè¡°å‡ï¼ˆè¿‡æ‹Ÿåˆé¢„è­¦ï¼‰
3. è¿½è¸ªIR (Information Ratio)
4. ç”ŸæˆICæ—¶é—´åºåˆ—å›¾è¡¨

ç†è®ºåŸºç¡€ï¼š
IC (Information Coefficient):
- IC = Corr(Factor_Score, Future_Return)
- è¡¡é‡å› å­å¯¹æœªæ¥æ”¶ç›Šçš„é¢„æµ‹èƒ½åŠ›
- IC > 0.05: æ˜¾è‘—é¢„æµ‹èƒ½åŠ›
- IC > 0.10: å¼ºé¢„æµ‹èƒ½åŠ›
- IC < 0: è´Ÿå‘é¢„æµ‹ï¼ˆéœ€è¦åè½¬ï¼‰

ICè¡°å‡æ£€æµ‹ï¼š
- æ ·æœ¬å†…IC vs æ ·æœ¬å¤–ICå·®å¼‚ > 30% â†’ è¿‡æ‹Ÿåˆè­¦å‘Š
- ICæŒç»­ä¸‹é™ â†’ å› å­å¤±æ•ˆè­¦å‘Š

IR (Information Ratio):
- IR = IC_mean / IC_std
- è¡¡é‡å› å­ç¨³å®šæ€§
- IR > 0.5: ç¨³å®š
- IR > 1.0: éå¸¸ç¨³å®š
"""

from __future__ import annotations
from typing import Dict, List, Tuple, Any, Optional
import numpy as np
from collections import defaultdict, deque


class ICMonitor:
    """ICç›‘æ§å™¨"""

    def __init__(
        self,
        ic_threshold: float = 0.05,
        decay_threshold: float = 0.30,
        window_size: int = 50
    ):
        """
        åˆå§‹åŒ–ICç›‘æ§å™¨

        Args:
            ic_threshold: ICé˜ˆå€¼ï¼ˆé»˜è®¤0.05ï¼‰
            decay_threshold: ICè¡°å‡é˜ˆå€¼ï¼ˆé»˜è®¤30%ï¼‰
            window_size: æ»šåŠ¨çª—å£å¤§å°ï¼ˆé»˜è®¤50ï¼‰
        """
        self.ic_threshold = ic_threshold
        self.decay_threshold = decay_threshold
        self.window_size = window_size

        # å­˜å‚¨å› å­è¯„åˆ†å’Œæœªæ¥æ”¶ç›Š
        self.factor_scores_history = defaultdict(lambda: deque(maxlen=window_size))
        self.future_returns_history = deque(maxlen=window_size)

        # å­˜å‚¨ICæ—¶é—´åºåˆ—
        self.ic_timeseries = defaultdict(list)

        # æ ·æœ¬å†…/å¤–åˆ’åˆ†ç‚¹
        self.in_sample_size = None

    def add_observation(
        self,
        factor_scores: Dict[str, float],
        future_return: float
    ):
        """
        æ·»åŠ ä¸€æ¬¡è§‚æµ‹

        Args:
            factor_scores: å› å­è¯„åˆ†å­—å…¸ {factor_name: score}
            future_return: æœªæ¥æ”¶ç›Šï¼ˆå¦‚1h/4h/24håçš„æ”¶ç›Šç‡ï¼‰
        """
        for factor_name, score in factor_scores.items():
            self.factor_scores_history[factor_name].append(score)

        self.future_returns_history.append(future_return)

    def add_batch_observations(
        self,
        observations: List[Tuple[Dict[str, float], float]]
    ):
        """
        æ‰¹é‡æ·»åŠ è§‚æµ‹

        Args:
            observations: [(factor_scores, future_return), ...]
        """
        for factor_scores, future_return in observations:
            self.add_observation(factor_scores, future_return)

    def calculate_ic(
        self,
        factor_name: str,
        use_rank: bool = True
    ) -> Tuple[float, int]:
        """
        è®¡ç®—å•ä¸ªå› å­çš„IC

        Args:
            factor_name: å› å­åç§°
            use_rank: æ˜¯å¦ä½¿ç”¨Spearmanç§©ç›¸å…³ï¼ˆé»˜è®¤Trueï¼Œæ›´ç¨³å¥ï¼‰

        Returns:
            (ic_value, sample_size)
        """
        if factor_name not in self.factor_scores_history:
            return 0.0, 0

        factor_scores = list(self.factor_scores_history[factor_name])
        future_returns = list(self.future_returns_history)

        # å¯¹é½é•¿åº¦
        min_length = min(len(factor_scores), len(future_returns))

        if min_length < 2:
            return 0.0, 0

        factor_scores = factor_scores[-min_length:]
        future_returns = future_returns[-min_length:]

        # è®¡ç®—ç›¸å…³ç³»æ•°
        if use_rank:
            # Spearmanç§©ç›¸å…³ï¼ˆæ›´ç¨³å¥ï¼‰
            factor_ranks = self._rank(factor_scores)
            return_ranks = self._rank(future_returns)
            ic = np.corrcoef(factor_ranks, return_ranks)[0, 1]
        else:
            # Pearsonç›¸å…³
            ic = np.corrcoef(factor_scores, future_returns)[0, 1]

        # å¤„ç†NaN
        if np.isnan(ic):
            ic = 0.0

        return ic, min_length

    def _rank(self, values: List[float]) -> List[float]:
        """è®¡ç®—ç§©"""
        sorted_indices = np.argsort(values)
        ranks = np.empty(len(values))
        ranks[sorted_indices] = np.arange(len(values))
        return ranks.tolist()

    def calculate_all_ic(self, use_rank: bool = True) -> Dict[str, Tuple[float, int]]:
        """
        è®¡ç®—æ‰€æœ‰å› å­çš„IC

        Args:
            use_rank: æ˜¯å¦ä½¿ç”¨ç§©ç›¸å…³

        Returns:
            {factor_name: (ic_value, sample_size), ...}
        """
        ic_results = {}

        for factor_name in self.factor_scores_history.keys():
            ic, sample_size = self.calculate_ic(factor_name, use_rank)
            ic_results[factor_name] = (ic, sample_size)

        return ic_results

    def calculate_ir(self, factor_name: str) -> Tuple[float, float, float]:
        """
        è®¡ç®—Information Ratio

        Args:
            factor_name: å› å­åç§°

        Returns:
            (IR, IC_mean, IC_std)
        """
        if factor_name not in self.ic_timeseries or len(self.ic_timeseries[factor_name]) < 2:
            return 0.0, 0.0, 0.0

        ic_series = self.ic_timeseries[factor_name]

        ic_mean = np.mean(ic_series)
        ic_std = np.std(ic_series)

        if ic_std == 0:
            ir = 0.0
        else:
            ir = ic_mean / ic_std

        return ir, ic_mean, ic_std

    def detect_ic_decay(
        self,
        factor_name: str,
        in_sample_ratio: float = 0.8
    ) -> Dict[str, Any]:
        """
        æ£€æµ‹ICè¡°å‡ï¼ˆè¿‡æ‹Ÿåˆæ£€æµ‹ï¼‰

        Args:
            factor_name: å› å­åç§°
            in_sample_ratio: æ ·æœ¬å†…æ¯”ä¾‹ï¼ˆé»˜è®¤80%ï¼‰

        Returns:
            {
                "in_sample_ic": float,
                "out_sample_ic": float,
                "decay_pct": float,
                "is_overfitting": bool,
                "severity": str
            }
        """
        if factor_name not in self.factor_scores_history:
            return {"error": "Factor not found"}

        factor_scores = list(self.factor_scores_history[factor_name])
        future_returns = list(self.future_returns_history)

        min_length = min(len(factor_scores), len(future_returns))

        if min_length < 10:
            return {"error": "Insufficient data"}

        # åˆ’åˆ†æ ·æœ¬å†…/å¤–
        split_point = int(min_length * in_sample_ratio)

        if split_point < 5 or (min_length - split_point) < 5:
            return {"error": "Insufficient data for train/test split"}

        # æ ·æœ¬å†…
        in_scores = factor_scores[:split_point]
        in_returns = future_returns[:split_point]
        in_ic = np.corrcoef(in_scores, in_returns)[0, 1]

        # æ ·æœ¬å¤–
        out_scores = factor_scores[split_point:]
        out_returns = future_returns[split_point:]
        out_ic = np.corrcoef(out_scores, out_returns)[0, 1]

        # å¤„ç†NaN
        in_ic = 0.0 if np.isnan(in_ic) else in_ic
        out_ic = 0.0 if np.isnan(out_ic) else out_ic

        # è®¡ç®—è¡°å‡ç™¾åˆ†æ¯”
        if abs(in_ic) < 1e-9:
            decay_pct = 0.0
        else:
            decay_pct = (in_ic - out_ic) / abs(in_ic)

        # åˆ¤æ–­æ˜¯å¦è¿‡æ‹Ÿåˆ
        is_overfitting = decay_pct > self.decay_threshold

        # ä¸¥é‡ç¨‹åº¦
        if decay_pct > 0.5:
            severity = "severe"
        elif decay_pct > self.decay_threshold:
            severity = "moderate"
        elif decay_pct > 0.1:
            severity = "mild"
        else:
            severity = "none"

        return {
            "in_sample_ic": in_ic,
            "out_sample_ic": out_ic,
            "decay_pct": decay_pct,
            "is_overfitting": is_overfitting,
            "severity": severity,
            "in_sample_size": split_point,
            "out_sample_size": min_length - split_point
        }

    def update_ic_timeseries(self):
        """æ›´æ–°ICæ—¶é—´åºåˆ—ï¼ˆç”¨äºè¿½è¸ªICå˜åŒ–ï¼‰"""
        ic_results = self.calculate_all_ic()

        for factor_name, (ic, _) in ic_results.items():
            self.ic_timeseries[factor_name].append(ic)

    def generate_report(self) -> str:
        """
        ç”ŸæˆICç›‘æ§æŠ¥å‘Š

        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Š
        """
        report = []
        report.append("# IC (Information Coefficient) Monitoring Report")
        report.append("")
        report.append(f"**IC Threshold**: {self.ic_threshold}")
        report.append(f"**Decay Threshold**: {self.decay_threshold * 100:.0f}%")
        report.append(f"**Sample Size**: {len(self.future_returns_history)}")
        report.append("")

        # å½“å‰ICå€¼
        ic_results = self.calculate_all_ic()

        report.append("## Current IC Values")
        report.append("")
        report.append("| Factor | IC | Sample Size | Significance |")
        report.append("|--------|-----|-------------|--------------|")

        for factor_name, (ic, sample_size) in sorted(ic_results.items(), key=lambda x: abs(x[1][0]), reverse=True):
            # åˆ¤æ–­æ˜¾è‘—æ€§
            if abs(ic) >= 0.10:
                sig = "ğŸ”¥ Strong"
            elif abs(ic) >= self.ic_threshold:
                sig = "âœ… Significant"
            elif abs(ic) > 0:
                sig = "âš ï¸ Weak"
            else:
                sig = "âŒ None"

            report.append(f"| **{factor_name}** | {ic:.4f} | {sample_size} | {sig} |")

        report.append("")

        # IR (Information Ratio)
        report.append("## Information Ratio (IR)")
        report.append("")
        report.append("| Factor | IR | IC Mean | IC Std | Stability |")
        report.append("|--------|-----|---------|--------|-----------|")

        for factor_name in self.factor_scores_history.keys():
            ir, ic_mean, ic_std = self.calculate_ir(factor_name)

            # åˆ¤æ–­ç¨³å®šæ€§
            if abs(ir) >= 1.0:
                stability = "ğŸ”¥ Excellent"
            elif abs(ir) >= 0.5:
                stability = "âœ… Good"
            elif abs(ir) > 0:
                stability = "âš ï¸ Fair"
            else:
                stability = "âŒ Poor"

            report.append(f"| **{factor_name}** | {ir:.3f} | {ic_mean:.4f} | {ic_std:.4f} | {stability} |")

        report.append("")

        # ICè¡°å‡æ£€æµ‹
        report.append("## IC Decay Detection (Overfitting Check)")
        report.append("")

        has_overfitting = False

        for factor_name in self.factor_scores_history.keys():
            decay_result = self.detect_ic_decay(factor_name)

            if "error" in decay_result:
                continue

            if decay_result["is_overfitting"]:
                has_overfitting = True

                report.append(f"### âš ï¸ {factor_name} - Overfitting Detected")
                report.append("")
                report.append(f"- **In-Sample IC**: {decay_result['in_sample_ic']:.4f}")
                report.append(f"- **Out-Sample IC**: {decay_result['out_sample_ic']:.4f}")
                report.append(f"- **Decay**: {decay_result['decay_pct']*100:.1f}%")
                report.append(f"- **Severity**: {decay_result['severity'].upper()}")
                report.append("")

        if not has_overfitting:
            report.append("âœ… **No overfitting detected** - All factors maintain consistent IC")
            report.append("")

        # å»ºè®®
        report.append("## Recommendations")
        report.append("")

        low_ic_factors = [name for name, (ic, _) in ic_results.items() if abs(ic) < self.ic_threshold]

        if low_ic_factors:
            report.append(f"âš ï¸ **Low IC factors** (IC < {self.ic_threshold}):")
            for factor_name in low_ic_factors:
                report.append(f"  - {factor_name}")
            report.append("")
            report.append("ğŸ’¡ Consider:")
            report.append("  1. Removing or transforming low-IC factors")
            report.append("  2. Investigating why these factors have weak predictive power")
            report.append("  3. Checking data quality and calculation logic")
            report.append("")

        if has_overfitting:
            report.append("âš ï¸ **Overfitting detected**:")
            report.append("")
            report.append("ğŸ’¡ Actions:")
            report.append("  1. Reduce model complexity (fewer factors or simpler transformations)")
            report.append("  2. Use regularization (L1/L2)")
            report.append("  3. Increase training data")
            report.append("  4. Re-validate factor logic on fresh data")
            report.append("")

        return "\n".join(report)

    def reset(self):
        """é‡ç½®ç›‘æ§å™¨"""
        self.factor_scores_history.clear()
        self.future_returns_history.clear()
        self.ic_timeseries.clear()


# ========== æµ‹è¯•ä»£ç  ==========

if __name__ == "__main__":
    print("=" * 70)
    print("ICç›‘æ§å™¨æµ‹è¯•")
    print("=" * 70)

    # åˆ›å»ºç›‘æ§å™¨
    monitor = ICMonitor(ic_threshold=0.05, decay_threshold=0.30)

    # æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)

    print("\n[æ¨¡æ‹Ÿæ•°æ®] ç”Ÿæˆ100ä¸ªè§‚æµ‹...")

    for i in range(100):
        # æ¨¡æ‹Ÿæœªæ¥æ”¶ç›Šï¼ˆéšæœºæ¸¸èµ°ï¼‰
        future_return = np.random.randn() * 0.02  # Â±2%

        # æ¨¡æ‹Ÿ10ä¸ªå› å­
        # T: é«˜é¢„æµ‹èƒ½åŠ› (ICâ‰ˆ0.15)
        T = future_return * 10 + np.random.randn() * 20

        # M: ä¸­ç­‰é¢„æµ‹èƒ½åŠ› (ICâ‰ˆ0.08)
        M = future_return * 5 + np.random.randn() * 25

        # C+: ä½é¢„æµ‹èƒ½åŠ› (ICâ‰ˆ0.03)
        C_plus = future_return * 2 + np.random.randn() * 30

        # S: æ— é¢„æµ‹èƒ½åŠ› (ICâ‰ˆ0)
        S = np.random.uniform(0, 100)

        # V+: è´Ÿå‘é¢„æµ‹ (ICâ‰ˆ-0.05)
        V_plus = -future_return * 3 + np.random.randn() * 20

        # å…¶ä»–å› å­ï¼ˆéšæœºï¼‰
        O_plus = np.random.randn() * 25
        L = np.random.uniform(0, 100)
        B = np.random.randn() * 25
        Q = np.random.randn() * 15
        I = np.random.uniform(0, 100)

        factor_scores = {
            "T": T,
            "M": M,
            "C+": C_plus,
            "S": S,
            "V+": V_plus,
            "O+": O_plus,
            "L": L,
            "B": B,
            "Q": Q,
            "I": I
        }

        monitor.add_observation(factor_scores, future_return)

    # è®¡ç®—IC
    print("\n[è®¡ç®—ICå€¼]")
    ic_results = monitor.calculate_all_ic()

    for factor_name, (ic, sample_size) in sorted(ic_results.items(), key=lambda x: abs(x[1][0]), reverse=True):
        sig = "Strong" if abs(ic) >= 0.10 else ("Significant" if abs(ic) >= 0.05 else "Weak")
        print(f"  {factor_name:5s}: IC = {ic:7.4f} ({sig})")

    # ICè¡°å‡æ£€æµ‹
    print("\n[ICè¡°å‡æ£€æµ‹]")
    for factor_name in ["T", "M", "C+"]:
        decay_result = monitor.detect_ic_decay(factor_name)

        if "error" not in decay_result:
            print(f"\n  {factor_name}:")
            print(f"    æ ·æœ¬å†…IC:  {decay_result['in_sample_ic']:.4f}")
            print(f"    æ ·æœ¬å¤–IC:  {decay_result['out_sample_ic']:.4f}")
            print(f"    è¡°å‡:      {decay_result['decay_pct']*100:.1f}%")
            print(f"    è¿‡æ‹Ÿåˆ:    {'Yes' if decay_result['is_overfitting'] else 'No'}")

    # ç”ŸæˆæŠ¥å‘Š
    print("\n[ç”ŸæˆæŠ¥å‘Š]")
    report = monitor.generate_report()

    # ä¿å­˜æŠ¥å‘Š
    report_path = "/tmp/ic_monitoring_report.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"  æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

    # æ˜¾ç¤ºæŠ¥å‘Šï¼ˆå‰35è¡Œï¼‰
    print("\n[æŠ¥å‘Šé¢„è§ˆ]")
    print("-" * 70)
    lines = report.split("\n")
    for line in lines[:35]:
        print(line)
    if len(lines) > 35:
        print(f"... ({len(lines) - 35} more lines)")

    print("\n" + "=" * 70)
    print("âœ… ICç›‘æ§å™¨æµ‹è¯•å®Œæˆ")
    print("=" * 70)
