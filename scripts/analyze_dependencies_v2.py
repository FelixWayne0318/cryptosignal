#!/usr/bin/env python3
"""
ä¾èµ–åˆ†æå·¥å…· v2
ä»ç³»ç»Ÿå…¥å£ç‚¹å¼€å§‹ï¼Œåˆ†ææ‰€æœ‰è¢«ä½¿ç”¨çš„Pythonæ–‡ä»¶å’Œé…ç½®æ–‡ä»¶
"""

import os
import sys
import re
import ast
from pathlib import Path
from typing import Set, Dict, List
import json

class DependencyAnalyzer:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root).resolve()
        self.used_files: Set[Path] = set()
        self.import_graph: Dict[Path, Set[Path]] = {}
        self.config_files: Set[Path] = set()
        self.processed_files: Set[Path] = set()

    def analyze_from_entrypoint(self, entrypoint: str):
        """ä»å…¥å£ç‚¹å¼€å§‹åˆ†ææ‰€æœ‰ä¾èµ–"""
        entry_path = self.project_root / entrypoint
        if not entry_path.exists():
            print(f"âš ï¸  å…¥å£æ–‡ä»¶ä¸å­˜åœ¨: {entrypoint}")
            return

        print(f"ğŸ” ä»å…¥å£ç‚¹å¼€å§‹åˆ†æ: {entrypoint}")
        self._analyze_file(entry_path)

    def _analyze_file(self, file_path: Path):
        """é€’å½’åˆ†æå•ä¸ªæ–‡ä»¶çš„ä¾èµ–"""
        if file_path in self.processed_files:
            return

        self.processed_files.add(file_path)
        self.used_files.add(file_path)

        if file_path.suffix != '.py':
            return

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ä½¿ç”¨ASTè§£æimportè¯­å¥
            try:
                tree = ast.parse(content, filename=str(file_path))
                imports = self._extract_imports(tree, file_path)
                self.import_graph[file_path] = imports

                # é€’å½’åˆ†æå¯¼å…¥çš„æ–‡ä»¶
                for imported_file in imports:
                    if imported_file and imported_file.exists():
                        self._analyze_file(imported_file)
            except SyntaxError as e:
                print(f"âš ï¸  è¯­æ³•é”™è¯¯ {file_path}: {e}")

            # åˆ†æé…ç½®æ–‡ä»¶å¼•ç”¨
            self._extract_config_references(content, file_path)

        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¯»å– {file_path}: {e}")

    def _extract_imports(self, tree: ast.AST, current_file: Path) -> Set[Path]:
        """ä»ASTä¸­æå–importè¯­å¥å¹¶è§£æä¸ºæ–‡ä»¶è·¯å¾„"""
        imports = set()

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    module_name = alias.name
                    file_path = self._resolve_module(module_name, current_file)
                    if file_path:
                        imports.add(file_path)

            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    module_name = node.module
                    file_path = self._resolve_module(module_name, current_file)
                    if file_path:
                        imports.add(file_path)

        return imports

    def _resolve_module(self, module_name: str, current_file: Path) -> Path:
        """å°†æ¨¡å—åè§£æä¸ºæ–‡ä»¶è·¯å¾„"""
        # å¤„ç†ç›¸å¯¹å¯¼å…¥
        if module_name.startswith('.'):
            # ç›¸å¯¹å½“å‰æ–‡ä»¶çš„ç›®å½•
            current_dir = current_file.parent
            parts = module_name.split('.')
            level = len([p for p in parts if not p])
            module_parts = [p for p in parts if p]

            target_dir = current_dir
            for _ in range(level - 1):
                target_dir = target_dir.parent

            for part in module_parts:
                target_dir = target_dir / part

            # å°è¯• __init__.py æˆ– module.py
            if (target_dir / '__init__.py').exists():
                return target_dir / '__init__.py'
            elif (target_dir.parent / f'{target_dir.name}.py').exists():
                return target_dir.parent / f'{target_dir.name}.py'
        else:
            # ç»å¯¹å¯¼å…¥
            parts = module_name.split('.')

            # å°è¯•ä»é¡¹ç›®æ ¹ç›®å½•è§£æ
            target = self.project_root / '/'.join(parts)

            if (target / '__init__.py').exists():
                return target / '__init__.py'
            elif (self.project_root / f"{'/'.join(parts)}.py").exists():
                return self.project_root / f"{'/'.join(parts)}.py"

        return None

    def _extract_config_references(self, content: str, file_path: Path):
        """æå–é…ç½®æ–‡ä»¶å¼•ç”¨"""
        # æŸ¥æ‰¾å¸¸è§çš„é…ç½®æ–‡ä»¶å¼•ç”¨æ¨¡å¼
        patterns = [
            r'["\']config/([^"\']+\.json)["\']',
            r'["\']config/([^"\']+\.yaml)["\']',
            r'["\']config/([^"\']+\.yml)["\']',
            r'Path\(["\']config/([^"\']+)["\']',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                config_path = self.project_root / 'config' / match
                if config_path.exists():
                    self.config_files.add(config_path)
                    self.used_files.add(config_path)

    def find_all_python_files(self) -> Set[Path]:
        """æŸ¥æ‰¾é¡¹ç›®ä¸­æ‰€æœ‰Pythonæ–‡ä»¶"""
        all_files = set()

        for ext in ['*.py']:
            for file in self.project_root.rglob(ext):
                # æ’é™¤ __pycache__ å’Œéšè—ç›®å½•
                if '__pycache__' not in file.parts and not any(p.startswith('.') for p in file.parts):
                    all_files.add(file)

        return all_files

    def find_all_doc_files(self) -> Dict[str, List[Path]]:
        """æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶å¹¶åˆ†ç±»"""
        doc_files = {
            'standards': [],  # è§„èŒƒæ–‡æ¡£
            'docs': [],       # è¯´æ˜æ–‡æ¡£
            'tests': [],      # æµ‹è¯•æ–‡ä»¶
            'diagnose': [],   # è¯Šæ–­æ–‡ä»¶
            'other': []       # å…¶ä»–
        }

        # æŸ¥æ‰¾markdownæ–‡ä»¶
        for md_file in self.project_root.rglob('*.md'):
            if '__pycache__' in md_file.parts or any(p.startswith('.') for p in md_file.parts):
                continue

            rel_path = md_file.relative_to(self.project_root)

            # æ ¹æ®å†…å®¹å’Œä½ç½®åˆ†ç±»
            if 'standards' in md_file.parts or 'STANDARD' in md_file.name.upper():
                doc_files['standards'].append(md_file)
            elif 'docs' in md_file.parts:
                doc_files['docs'].append(md_file)
            elif 'tests' in md_file.parts or 'test' in md_file.name.lower():
                doc_files['tests'].append(md_file)
            elif 'diagnose' in md_file.parts or 'diagnostic' in md_file.name.lower():
                doc_files['diagnose'].append(md_file)
            elif md_file.parent == self.project_root:
                # æ ¹ç›®å½•çš„æ–‡æ¡£éœ€è¦è¿›ä¸€æ­¥åˆ†ç±»
                name_lower = md_file.name.lower()
                if any(kw in name_lower for kw in ['standard', 'spec', 'rule', 'convention']):
                    doc_files['standards'].append(md_file)
                elif any(kw in name_lower for kw in ['doc', 'readme', 'guide', 'manual', 'fix', 'report', 'summary']):
                    doc_files['docs'].append(md_file)
                elif any(kw in name_lower for kw in ['test', 'diagnostic', 'diagnose', 'check']):
                    doc_files['diagnose'].append(md_file)
                else:
                    doc_files['other'].append(md_file)
            else:
                doc_files['other'].append(md_file)

        return doc_files

    def generate_report(self) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        all_py_files = self.find_all_python_files()
        unused_py_files = all_py_files - self.used_files
        doc_files = self.find_all_doc_files()

        report = {
            'total_python_files': len(all_py_files),
            'used_python_files': len(self.used_files & all_py_files),
            'unused_python_files': len(unused_py_files),
            'config_files': len(self.config_files),
            'unused_files_list': [str(f.relative_to(self.project_root)) for f in sorted(unused_py_files)],
            'doc_files': {
                category: [str(f.relative_to(self.project_root)) for f in files]
                for category, files in doc_files.items()
            }
        }

        return report


def main():
    """ä¸»å‡½æ•°"""
    project_root = Path(__file__).parent
    analyzer = DependencyAnalyzer(project_root)

    # å®šä¹‰ç³»ç»Ÿå…¥å£ç‚¹
    entrypoints = [
        'scripts/realtime_signal_scanner.py',
        'scripts/init_databases.py',
        'setup.sh',  # Shellè„šæœ¬ä¼šåˆ†æå…¶ä¸­çš„Pythonè°ƒç”¨
    ]

    print("=" * 60)
    print("ğŸ” CryptoSignal ä¾èµ–åˆ†æ v2")
    print("=" * 60)
    print()

    # ä»æ‰€æœ‰å…¥å£ç‚¹åˆ†æ
    for entry in entrypoints:
        entry_path = project_root / entry
        if entry_path.exists() and entry_path.suffix == '.py':
            analyzer.analyze_from_entrypoint(entry)

    # ç”ŸæˆæŠ¥å‘Š
    print()
    print("=" * 60)
    print("ğŸ“Š åˆ†ææŠ¥å‘Š")
    print("=" * 60)

    report = analyzer.generate_report()

    print(f"\nğŸ“ Python æ–‡ä»¶ç»Ÿè®¡:")
    print(f"   æ€»è®¡: {report['total_python_files']} ä¸ª")
    print(f"   ä½¿ç”¨ä¸­: {report['used_python_files']} ä¸ª")
    print(f"   æœªä½¿ç”¨: {report['unused_python_files']} ä¸ª")

    print(f"\nâš™ï¸  é…ç½®æ–‡ä»¶: {report['config_files']} ä¸ª")

    print(f"\nğŸ“ æ–‡æ¡£æ–‡ä»¶ç»Ÿè®¡:")
    for category, files in report['doc_files'].items():
        if files:
            print(f"   {category}: {len(files)} ä¸ª")

    if report['unused_python_files'] > 0:
        print(f"\nâŒ æœªä½¿ç”¨çš„ Python æ–‡ä»¶ ({report['unused_python_files']} ä¸ª):")
        for file in report['unused_files_list'][:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
            print(f"   - {file}")
        if len(report['unused_files_list']) > 20:
            print(f"   ... è¿˜æœ‰ {len(report['unused_files_list']) - 20} ä¸ª")

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    output_file = project_root / 'dependency_analysis_report.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    print()

    return report


if __name__ == '__main__':
    main()
