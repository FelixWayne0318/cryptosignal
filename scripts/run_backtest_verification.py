#!/usr/bin/env python3
# coding: utf-8
"""
v7.2ç³»ç»Ÿå›æµ‹éªŒè¯è„šæœ¬

ç›®çš„ï¼š
1. ä»æ•°æ®åº“åŠ è½½å†å²ä¿¡å·
2. ä½¿ç”¨çœŸå®ä»·æ ¼æ•°æ®å›æµ‹ä¿¡å·è¡¨ç°
3. è®¡ç®—å…³é”®ç»©æ•ˆæŒ‡æ ‡ï¼ˆèƒœç‡ã€å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤ï¼‰
4. ç”Ÿæˆå®Œæ•´çš„éªŒè¯æŠ¥å‘Š

è¦æ±‚ï¼ˆæ¥è‡ªSYSTEM_REFACTOR_V72_AUDIT.md - P1.2ï¼‰ï¼š
- è‡³å°‘6ä¸ªæœˆçš„å†å²æ•°æ®
- å…³é”®æŒ‡æ ‡ï¼šèƒœç‡ã€å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤ã€åˆ©æ¶¦å› å­
- åˆ†æ–¹å‘ç»Ÿè®¡ï¼ˆåšå¤š/åšç©ºï¼‰
- åˆ†æ—¶æ®µç»Ÿè®¡ï¼ˆæœˆåº¦æ”¶ç›Šï¼‰
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
import sqlite3
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from ats_backtest import BacktestEngine, BacktestDataLoader, calculate_metrics, format_metrics_report
from ats_backtest.report import generate_report, save_report, print_full_report


def query_signals_from_db(db_path: str, start_time: datetime, end_time: datetime, min_probability: float = 0) -> list:
    """
    ä»cryptosignal.dbçš„signalsè¡¨åŠ è½½å†å²ä¿¡å·

    Args:
        db_path: æ•°æ®åº“è·¯å¾„
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´
        min_probability: æœ€å°æ¦‚ç‡è¿‡æ»¤

    Returns:
        ä¿¡å·åˆ—è¡¨ï¼ˆå­—å…¸æ ¼å¼ï¼‰
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # æŸ¥è¯¢ä¿¡å·ï¼ˆæ—¶é—´æˆ³å­˜å‚¨ä¸ºå­—ç¬¦ä¸²ï¼‰
    query = """
    SELECT
        id,
        symbol,
        timestamp,
        side,
        probability,
        entry_price,
        stop_loss,
        take_profit_1,
        take_profit_2,
        current_price,
        is_prime,
        scores
    FROM signals
    WHERE timestamp >= ? AND timestamp <= ?
        AND probability >= ?
        AND entry_price IS NOT NULL
        AND stop_loss IS NOT NULL
    ORDER BY timestamp ASC
    """

    # æ—¶é—´æˆ³æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼ˆæ•°æ®åº“ä¸­å­˜å‚¨ä¸ºDATETIMEå­—ç¬¦ä¸²ï¼‰
    start_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
    end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')

    cursor.execute(query, (start_str, end_str, min_probability))
    rows = cursor.fetchall()

    signals = []
    for row in rows:
        signal_id, symbol, ts_str, side, prob, entry_price, stop_loss, tp1, tp2, current_price, is_prime, scores_json = row

        # è§£ææ—¶é—´æˆ³
        try:
            # å°è¯•è§£æå¸¦å°æ•°çš„æ—¶é—´æˆ³
            timestamp = datetime.strptime(ts_str.split('.')[0], '%Y-%m-%d %H:%M:%S')
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ ¼å¼
            try:
                timestamp = datetime.fromisoformat(ts_str)
            except:
                print(f"âš ï¸  Failed to parse timestamp: {ts_str}, skipping signal")
                continue

        # è§£æscores JSON
        scores_dict = {}
        if scores_json:
            try:
                scores_dict = json.loads(scores_json)
            except:
                scores_dict = {}

        # æ„å»ºä¿¡å·å­—å…¸
        signals.append({
            'signal_id': str(signal_id),
            'timestamp': timestamp,
            'entry_time': timestamp,
            'symbol': symbol,
            'side': side.lower(),  # è½¬æ¢ä¸ºå°å†™ (long/short)
            'entry_price': entry_price,
            'current_price': current_price or entry_price,
            'stop_loss': stop_loss,
            'sl': stop_loss,
            'take_profit_1': tp1,
            'tp1': tp1,
            'take_profit_2': tp2,
            'tp2': tp2,
            'probability': prob or 0.5,
            'scores': scores_dict or {},
            'is_prime': bool(is_prime),
        })

    conn.close()

    print(f"âœ… Loaded {len(signals)} signals from database")
    print(f"   Period: {start_time.date()} to {end_time.date()}")
    if signals:
        symbols = set(s['symbol'] for s in signals)
        print(f"   Symbols: {len(symbols)} unique coins")

    return signals


def check_data_availability(db_path: str) -> dict:
    """
    æ£€æŸ¥æ•°æ®åº“ä¸­çš„æ•°æ®å¯ç”¨æ€§

    Returns:
        æ•°æ®ç»Ÿè®¡å­—å…¸
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # æ£€æŸ¥signalsè¡¨æ˜¯å¦å­˜åœ¨
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='signals'")
    if not cursor.fetchone():
        conn.close()
        return {'error': 'signals table not found'}

    # ç»Ÿè®¡ä¿¡å·æ•°é‡
    cursor.execute("SELECT COUNT(*) FROM signals")
    total_signals = cursor.fetchone()[0]

    # ç»Ÿè®¡æœ‰æ•ˆä¿¡å·ï¼ˆæœ‰entry_priceå’Œstop_lossï¼‰
    cursor.execute("SELECT COUNT(*) FROM signals WHERE entry_price IS NOT NULL AND stop_loss IS NOT NULL")
    valid_signals = cursor.fetchone()[0]

    # è·å–æ—¶é—´èŒƒå›´
    cursor.execute("SELECT MIN(timestamp), MAX(timestamp) FROM signals WHERE entry_price IS NOT NULL")
    min_ts_str, max_ts_str = cursor.fetchone()

    earliest = None
    latest = None
    if min_ts_str and max_ts_str:
        try:
            earliest = datetime.strptime(min_ts_str.split('.')[0], '%Y-%m-%d %H:%M:%S')
            latest = datetime.strptime(max_ts_str.split('.')[0], '%Y-%m-%d %H:%M:%S')
        except:
            # å°è¯•å…¶ä»–æ ¼å¼
            try:
                earliest = datetime.fromisoformat(min_ts_str)
                latest = datetime.fromisoformat(max_ts_str)
            except:
                pass

    # ç»Ÿè®¡å¸ç§æ•°é‡
    cursor.execute("SELECT COUNT(DISTINCT symbol) FROM signals WHERE entry_price IS NOT NULL")
    unique_symbols = cursor.fetchone()[0]

    conn.close()

    # è®¡ç®—æ•°æ®è·¨åº¦
    duration_days = 0
    if earliest and latest:
        duration_days = (latest - earliest).days

    return {
        'total_signals': total_signals,
        'valid_signals': valid_signals,
        'earliest_signal': earliest,
        'latest_signal': latest,
        'duration_days': duration_days,
        'unique_symbols': unique_symbols,
    }


def run_backtest_verification(
    start_time: datetime = None,
    end_time: datetime = None,
    initial_capital: float = 10000,
    min_confidence: float = 0,
    save_results: bool = True
):
    """
    è¿è¡Œå®Œæ•´çš„å›æµ‹éªŒè¯

    Args:
        start_time: å›æµ‹å¼€å§‹æ—¶é—´ï¼ˆé»˜è®¤ï¼š6ä¸ªæœˆå‰ï¼‰
        end_time: å›æµ‹ç»“æŸæ—¶é—´ï¼ˆé»˜è®¤ï¼šç°åœ¨ï¼‰
        initial_capital: åˆå§‹èµ„é‡‘ï¼ˆUSDTï¼‰
        min_confidence: æœ€å°ç½®ä¿¡åº¦è¿‡æ»¤
        save_results: æ˜¯å¦ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    """
    print("=" * 80)
    print("  v7.2 System Backtest Verification")
    print("=" * 80)
    print()

    # 1. ç¡®å®šæ•°æ®åº“è·¯å¾„
    db_path = project_root / "data" / "database" / "cryptosignal.db"

    if not db_path.exists():
        print(f"âŒ Database not found: {db_path}")
        print("   Please run the system to generate historical signals first.")
        return None

    print(f"ğŸ“‚ Database: {db_path}")
    print()

    # 2. æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
    print("ğŸ” Checking data availability...")
    print()
    data_stats = check_data_availability(str(db_path))

    if 'error' in data_stats:
        print(f"âŒ {data_stats['error']}")
        return None

    print(f"  Total signals in DB:       {data_stats['total_signals']}")
    print(f"  Valid signals:             {data_stats['valid_signals']}")
    print(f"  Unique symbols:            {data_stats['unique_symbols']}")
    print(f"  Earliest signal:           {data_stats['earliest_signal']}")
    print(f"  Latest signal:             {data_stats['latest_signal']}")
    print(f"  Data coverage:             {data_stats['duration_days']} days")
    print()

    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®
    if data_stats['valid_signals'] == 0:
        print("âŒ No valid signals found in database.")
        print("   Please run the system to generate signals first.")
        return None

    if data_stats['duration_days'] < 7:
        print(f"âš ï¸  Warning: Only {data_stats['duration_days']} days of data available.")
        print("   For reliable backtest, at least 180 days (6 months) is recommended.")
        print()

    # 3. ç¡®å®šå›æµ‹æ—¶é—´èŒƒå›´
    if start_time is None:
        # é»˜è®¤ï¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®ï¼Œæˆ–æœ€è¿‘6ä¸ªæœˆ
        if data_stats['earliest_signal']:
            start_time = data_stats['earliest_signal']
        else:
            start_time = datetime.now() - timedelta(days=180)

    if end_time is None:
        # é»˜è®¤ï¼šä½¿ç”¨æœ€æ–°æ•°æ®ç‚¹
        if data_stats['latest_signal']:
            end_time = data_stats['latest_signal']
        else:
            end_time = datetime.now()

    print(f"ğŸ“… Backtest Period")
    print(f"   Start: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   End:   {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   Duration: {(end_time - start_time).days} days")
    print()

    # 4. åŠ è½½ä¿¡å·æ•°æ®
    print("ğŸ“Š Loading signals from database...")
    signals = query_signals_from_db(
        db_path=str(db_path),
        start_time=start_time,
        end_time=end_time,
        min_probability=min_confidence
    )

    if not signals:
        print("âŒ No signals found in the specified period.")
        return None

    print()

    # 5. åŠ è½½ä»·æ ¼æ•°æ®
    print("ğŸ“ˆ Loading price data...")
    data_loader = BacktestDataLoader()

    # æå–æ‰€æœ‰æ¶‰åŠçš„å¸ç§
    symbols = list(set(s['symbol'] for s in signals))
    print(f"   Loading data for {len(symbols)} symbols...")

    price_data = data_loader.load_price_data(
        symbols=symbols,
        start_time=start_time,
        end_time=end_time + timedelta(days=7),  # é¢å¤–åŠ è½½7å¤©ä»¥è·Ÿè¸ªé€€å‡º
        interval='1h',
        use_cache=True
    )

    if not price_data:
        print("âŒ Failed to load price data.")
        return None

    print()

    # 6. è¿è¡Œå›æµ‹
    print("ğŸš€ Running backtest...")
    print()

    engine = BacktestEngine(
        start_time=start_time,
        end_time=end_time,
        initial_capital=initial_capital,
        position_size_pct=0.02,  # æ¯æ¬¡2%ä»“ä½
        max_open_trades=5,       # æœ€å¤š5ä¸ªæŒä»“
        ttl_hours=8,             # ä¿¡å·æœ‰æ•ˆæœŸ8å°æ—¶
        commission_rate=0.0004   # å¸å®‰æ‰‹ç»­è´¹0.04%
    )

    results = engine.run_from_signals(signals, price_data)

    if 'error' in results:
        print(f"âŒ Backtest error: {results['error']}")
        return None

    print()
    print("=" * 80)
    print()

    # 7. è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    closed_trades = results['trades']
    equity_curve = results['equity_curve']

    metrics = calculate_metrics(
        trades=closed_trades,
        equity_curve=equity_curve,
        initial_capital=initial_capital
    )

    # 8. æ‰“å°å®Œæ•´æŠ¥å‘Š
    print_full_report(closed_trades, metrics, equity_curve)

    # 9. ä¿å­˜æŠ¥å‘Š
    if save_results:
        report_data = generate_report(
            trades=closed_trades,
            metrics=metrics,
            config={
                'start_time': start_time.isoformat(),
                'end_time': end_time.isoformat(),
                'initial_capital': initial_capital,
                'position_size_pct': 0.02,
                'max_open_trades': 5,
                'ttl_hours': 8,
                'commission_rate': 0.0004,
                'min_confidence': min_confidence,
            },
            include_trades=True
        )

        # ä¿å­˜JSONæŠ¥å‘Š
        report_dir = project_root / "data" / "backtest" / "reports"
        report_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = save_report(report_data, output_dir=str(report_dir), filename=f"backtest_{timestamp}.json")

        print()
        print(f"ğŸ’¾ Report saved to: {report_file}")

        # åŒæ—¶ä¿å­˜ä¸ºMarkdownæ ¼å¼çš„äººç±»å¯è¯»æŠ¥å‘Š
        md_file = report_dir / f"backtest_{timestamp}.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(generate_markdown_report(metrics, results['summary'], closed_trades))

        print(f"ğŸ’¾ Markdown report saved to: {md_file}")

    print()
    print("=" * 80)
    print("âœ… Backtest verification completed!")
    print("=" * 80)

    return {
        'metrics': metrics,
        'trades': closed_trades,
        'equity_curve': equity_curve,
        'summary': results['summary']
    }


def generate_markdown_report(metrics: dict, summary: dict, trades: list) -> str:
    """
    ç”ŸæˆMarkdownæ ¼å¼çš„å›æµ‹æŠ¥å‘Š

    Args:
        metrics: æ€§èƒ½æŒ‡æ ‡
        summary: å›æµ‹æ‘˜è¦
        trades: äº¤æ˜“åˆ—è¡¨

    Returns:
        Markdownæ–‡æœ¬
    """
    lines = []

    lines.append("# v7.2 System Backtest Verification Report")
    lines.append("")
    lines.append(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("---")
    lines.append("")

    # 1. æ‰§è¡Œæ‘˜è¦
    lines.append("## 1. Executive Summary")
    lines.append("")
    lines.append(f"- **Total Trades:** {metrics['total_trades']}")
    lines.append(f"- **Win Rate:** {metrics['win_rate']*100:.2f}%")
    lines.append(f"- **Total Return:** {metrics['total_return']*100:+.2f}%")
    lines.append(f"- **Profit Factor:** {metrics['profit_factor']:.2f}")
    lines.append(f"- **Sharpe Ratio:** {metrics['sharpe_ratio']:.2f}")
    lines.append(f"- **Max Drawdown:** {metrics['max_drawdown_pct']*100:.2f}%")
    lines.append("")

    # 2. ç»©æ•ˆè¯„çº§
    wr = metrics['win_rate']
    if wr >= 0.60:
        rating = "Excellent (A)"
        assessment = "System performance exceeds industry standards."
    elif wr >= 0.50:
        rating = "Good (B)"
        assessment = "System performance meets professional standards."
    elif wr >= 0.40:
        rating = "Fair (C)"
        assessment = "System performance is acceptable but needs improvement."
    else:
        rating = "Needs Improvement (D)"
        assessment = "System requires significant optimization."

    lines.append("## 2. Performance Rating")
    lines.append("")
    lines.append(f"**Rating:** {rating}")
    lines.append("")
    lines.append(f"**Assessment:** {assessment}")
    lines.append("")

    # 3. å…³é”®æŒ‡æ ‡
    lines.append("## 3. Key Metrics")
    lines.append("")
    lines.append("### 3.1 Trading Statistics")
    lines.append("")
    lines.append(f"- Winning Trades: {metrics['winning_trades']} ({metrics['win_rate']*100:.1f}%)")
    lines.append(f"- Losing Trades: {metrics['losing_trades']}")
    lines.append(f"- Breakeven Trades: {metrics['breakeven_trades']}")
    lines.append(f"- Average Win: {metrics['avg_win']:+.2f}%")
    lines.append(f"- Average Loss: {metrics['avg_loss']:+.2f}%")
    lines.append(f"- Best Trade: {metrics['best_trade']:+.2f}%")
    lines.append(f"- Worst Trade: {metrics['worst_trade']:+.2f}%")
    lines.append("")

    lines.append("### 3.2 Risk Metrics")
    lines.append("")
    lines.append(f"- Maximum Drawdown: {metrics['max_drawdown_pct']*100:.2f}%")
    lines.append(f"- Drawdown Duration: {metrics['max_drawdown_duration_hours']:.1f} hours")
    lines.append(f"- Sharpe Ratio: {metrics['sharpe_ratio']:.2f}")
    lines.append(f"- Sortino Ratio: {metrics['sortino_ratio']:.2f}")
    lines.append(f"- Calmar Ratio: {metrics['calmar_ratio']:.2f}")
    lines.append("")

    lines.append("### 3.3 Direction Analysis")
    lines.append("")
    lines.append(f"- Long Trades: {metrics['long_trades']} (Win Rate: {metrics['long_win_rate']*100:.1f}%)")
    lines.append(f"- Short Trades: {metrics['short_trades']} (Win Rate: {metrics['short_win_rate']*100:.1f}%)")
    lines.append("")

    # 4. é€€å‡ºåŸå› åˆ†æ
    lines.append("## 4. Exit Reason Analysis")
    lines.append("")
    reasons = metrics['exit_reasons']
    total_exits = sum(reasons.values())
    if total_exits > 0:
        for reason, count in reasons.items():
            pct = count / total_exits * 100
            lines.append(f"- {reason.upper()}: {count} ({pct:.1f}%)")
    lines.append("")

    # 5. æœˆåº¦æ”¶ç›Š
    if metrics.get('monthly_returns'):
        lines.append("## 5. Monthly Returns")
        lines.append("")
        lines.append("| Month | Return |")
        lines.append("|-------|--------|")
        for month, ret in sorted(metrics['monthly_returns'].items()):
            lines.append(f"| {month} | {ret:+.2f}% |")
        lines.append("")

    # 6. ç»“è®ºå’Œå»ºè®®
    lines.append("## 6. Conclusions & Recommendations")
    lines.append("")

    # åŸºäºæŒ‡æ ‡ç»™å‡ºå»ºè®®
    recommendations = []

    if metrics['win_rate'] < 0.45:
        recommendations.append("- **Low Win Rate:** Consider tightening signal filters or adjusting entry criteria.")

    if metrics['max_drawdown_pct'] > 0.20:
        recommendations.append("- **High Drawdown:** Implement stricter position sizing or risk management rules.")

    if metrics['sharpe_ratio'] < 1.0:
        recommendations.append("- **Low Sharpe Ratio:** Focus on improving risk-adjusted returns through better trade selection.")

    if metrics['profit_factor'] < 1.5:
        recommendations.append("- **Low Profit Factor:** Optimize stop-loss and take-profit levels to improve win/loss ratio.")

    if metrics['avg_holding_hours'] > 6:
        recommendations.append("- **Long Holding Time:** Consider implementing tighter TTL or more aggressive profit-taking.")

    if not recommendations:
        recommendations.append("- System performance is within acceptable parameters. Continue monitoring and fine-tuning.")

    for rec in recommendations:
        lines.append(rec)

    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append(f"*Report generated by v7.2 Backtest Verification System*")

    return "\n".join(lines)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Run v7.2 system backtest verification")
    parser.add_argument("--days", type=int, default=None, help="Number of days to backtest (default: all available)")
    parser.add_argument("--capital", type=float, default=10000, help="Initial capital in USDT (default: 10000)")
    parser.add_argument("--min-confidence", type=float, default=0, help="Minimum confidence filter (default: 0)")
    parser.add_argument("--no-save", action="store_true", help="Don't save results to file")

    args = parser.parse_args()

    # ç¡®å®šæ—¶é—´èŒƒå›´
    end_time = datetime.now()
    start_time = None

    if args.days:
        start_time = end_time - timedelta(days=args.days)

    # è¿è¡Œå›æµ‹
    run_backtest_verification(
        start_time=start_time,
        end_time=end_time,
        initial_capital=args.capital,
        min_confidence=args.min_confidence,
        save_results=not args.no_save
    )
